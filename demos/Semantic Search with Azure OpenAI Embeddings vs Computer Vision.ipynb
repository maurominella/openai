{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ec06ef9f",
   "metadata": {},
   "source": [
    "## Azure OpenAI Configuration\n",
    "\n",
    "Add your [Azure Open AI Service key](https://learn.microsoft.com/azure/cognitive-services/openai/quickstart?pivots=programming-language-studio) settings to a `.env` file in the same folder:\n",
    "\n",
    "```\n",
    "AZURE_OPENAI_API_KEY=\"...\"\n",
    "AZURE_OPENAI_ENDPOINT=\"https://...\"\n",
    "AZURE_OPENAI_DEPLOYMENT_NAME=\"...\"\n",
    "```\n",
    "\n",
    "and add Azure OpenAI Text Completion to the kernel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f2cb6c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Bad pipe message: %s [b'tJx\\x92\\xb3S\\x0c\\x06\\xec\"q\\xe9l\\xb1\\xc7\\x08)\\x0e ']\n",
      "Bad pipe message: %s [b'\\xe9 \\x03\\x8d\\x08\\x95s\\xeb\\x907[\\x9c\\xb7\\xdeY4O\\xfa\\x14\\xa9\\x9c\\xf9\\xea\\xf60E\\xb6&Ga\\x00\\x08\\x13\\x02\\x13\\x03\\x13\\x01\\x00\\xff\\x01\\x00\\x00\\x8f\\x00\\x00\\x00\\x0e\\x00\\x0c\\x00\\x00\\t127.0.0.1\\x00\\x0b\\x00\\x04\\x03\\x00\\x01\\x02\\x00\\n\\x00\\x0c\\x00\\n\\x00\\x1d\\x00\\x17\\x00\\x1e\\x00\\x19\\x00\\x18\\x00#\\x00\\x00\\x00\\x16\\x00\\x00\\x00\\x17\\x00\\x00\\x00\\r\\x00\\x1e\\x00\\x1c\\x04\\x03\\x05', b'\\x03\\x08']\n",
      "Bad pipe message: %s [b'\\x08\\x08\\t\\x08\\n\\x08']\n",
      "Bad pipe message: %s [b'\\x04\\x08\\x05\\x08\\x06\\x04\\x01\\x05\\x01\\x06']\n",
      "Bad pipe message: %s [b'']\n",
      "Bad pipe message: %s [b'\\x03\\x02\\x03\\x04\\x00-\\x00\\x02\\x01\\x01\\x003\\x00&\\x00$\\x00\\x1d\\x00 \\xf7x\\xe8r_\\xc1T\\xfd\\xd0Y\\xe6\\x8d][\\xdd\\xa9/0\\x02\\x87\\xfb4']\n",
      "Bad pipe message: %s [b\"1fQ\\xd2\\x82\\xe7\\xb6\\xc6\\xa30\\xd8m.O?\\x96\\xe4\\xe0\\x00\\x00\\xa6\\xc0,\\xc00\\x00\\xa3\\x00\\x9f\\xcc\\xa9\\xcc\\xa8\\xcc\\xaa\\xc0\\xaf\\xc0\\xad\\xc0\\xa3\\xc0\\x9f\\xc0]\\xc0a\\xc0W\\xc0S\\xc0+\\xc0/\\x00\\xa2\\x00\\x9e\\xc0\\xae\\xc0\\xac\\xc0\\xa2\\xc0\\x9e\\xc0\\\\\\xc0`\\xc0V\\xc0R\\xc0$\\xc0(\\x00k\\x00j\\xc0s\\xc0w\\x00\\xc4\\x00\\xc3\\xc0#\\xc0'\\x00g\\x00@\\xc0r\\xc0v\\x00\\xbe\\x00\\xbd\\xc0\\n\\xc0\\x14\\x009\\x008\\x00\\x88\\x00\\x87\\xc0\\t\\xc0\\x13\\x003\\x002\\x00\\x9a\\x00\\x99\\x00E\\x00D\\xc0\\x07\\xc0\\x11\\xc0\\x08\\xc0\\x12\\x00\\x16\\x00\\x13\\x00\\x9d\\xc0\\xa1\\xc0\\x9d\\xc0Q\\x00\\x9c\\xc0\\xa0\\xc0\\x9c\\xc0P\\x00=\\x00\\xc0\\x00<\\x00\\xba\\x005\\x00\\x84\\x00/\\x00\\x96\\x00A\\x00\\x05\\x00\\n\\x00\\xff\\x01\\x00\\x00\", b'\\x00\\x00\\x0e\\x00\\x0c\\x00\\x00\\t127.0.0.1\\x00\\x0b\\x00\\x04\\x03\\x00\\x01\\x02\\x00\\n\\x00\\x0c\\x00\\n\\x00\\x1d\\x00\\x17\\x00\\x1e\\x00\\x19\\x00\\x18\\x00#\\x00\\x00\\x00\\x16\\x00\\x00\\x00\\x17\\x00\\x00\\x00\\r\\x000\\x00.\\x04\\x03\\x05\\x03\\x06\\x03\\x08\\x07\\x08\\x08\\x08\\t\\x08\\n\\x08\\x0b\\x08\\x04\\x08\\x05\\x08\\x06\\x04\\x01\\x05\\x01\\x06\\x01\\x03\\x03\\x02\\x03\\x03\\x01\\x02\\x01\\x03\\x02\\x02\\x02\\x04\\x02\\x05\\x02\\x06\\x02']\n",
      "Bad pipe message: %s [b'K\\x0f\\xbdE\\x84\\x88\\xfdo\\x9d\\x7fj\\xe6Q$\\xd9M\\x93l\\x00\\x00>\\xc0\\x14']\n",
      "Bad pipe message: %s [b'\\x1b\\xc9F\\xf2k\\xda\\x91\\x16\\x17\\xc2S\\x91\\xd8a\\xf1S\\x96\\xee\\x00\\x00\\xa2\\xc0\\x14\\xc0\\n\\x009\\x008\\x007\\x006\\x00\\x88\\x00\\x87\\x00\\x86\\x00\\x85\\xc0\\x19\\x00:\\x00\\x89\\xc0\\x0f\\xc0\\x05\\x005\\x00\\x84\\xc0\\x13\\xc0\\t\\x003\\x002\\x001\\x000\\x00\\x9a\\x00\\x99\\x00\\x98\\x00\\x97\\x00E\\x00D\\x00C\\x00B\\xc0\\x18\\x004\\x00\\x9b\\x00F\\xc0\\x0e\\xc0\\x04\\x00/\\x00\\x96\\x00A\\x00\\x07\\xc0\\x11\\xc0\\x07\\xc0\\x16\\x00\\x18\\xc0\\x0c\\xc0\\x02\\x00\\x05\\x00\\x04\\xc0\\x12\\xc0\\x08\\x00\\x16\\x00\\x13\\x00\\x10\\x00\\r\\xc0\\x17\\x00\\x1b\\xc0\\r\\xc0\\x03\\x00\\n\\x00\\x15\\x00\\x12\\x00\\x0f\\x00\\x0c\\x00\\x1a\\x00\\t\\x00\\x14\\x00\\x11\\x00\\x19\\x00\\x08\\x00\\x06\\x00\\x17\\x00\\x03']\n",
      "Bad pipe message: %s [b'F\\xady\\xfdz\\xd7\\x8bx.\\r']\n",
      "Bad pipe message: %s [b\"\\x8aN\\xd6\\x1c\\xf2\\x90\\xe0\\xff\\xf4\\xefu\\x8d6\\xd8\\xdeo\\xbb\\xa9\\x00\\x00\\x86\\xc00\\xc0,\\xc0(\\xc0$\\xc0\\x14\\xc0\\n\\x00\\xa5\\x00\\xa3\\x00\\xa1\\x00\\x9f\\x00k\\x00j\\x00i\\x00h\\x009\\x008\\x007\\x006\\xc02\\xc0.\\xc0*\\xc0&\\xc0\\x0f\\xc0\\x05\\x00\\x9d\\x00=\\x005\\xc0/\\xc0+\\xc0'\\xc0#\\xc0\\x13\\xc0\\t\\x00\\xa4\\x00\\xa2\\x00\\xa0\\x00\\x9e\\x00g\\x00@\\x00?\\x00>\\x003\\x002\\x001\\x000\\xc01\\xc0-\\xc0)\\xc0%\\xc0\\x0e\\xc0\\x04\\x00\\x9c\\x00<\\x00/\\x00\\x9a\\x00\\x99\\x00\\x98\\x00\\x97\\x00\\x96\\x00\\x07\\xc0\\x11\\xc0\\x07\\xc0\\x0c\\xc0\\x02\\x00\\x05\\x00\\x04\\x00\\xff\\x02\\x01\\x00\\x00g\\x00\\x00\\x00\\x0e\\x00\\x0c\\x00\\x00\\t127.0.0.1\\x00\\x0b\\x00\\x04\\x03\\x00\\x01\\x02\\x00\\n\\x00\\x1c\\x00\\x1a\\x00\\x17\\x00\\x19\\x00\\x1c\\x00\\x1b\\x00\\x18\\x00\\x1a\\x00\\x16\\x00\\x0e\\x00\\r\\x00\", b'\\x0c\\x00\\t\\x00\\n\\x00#\\x00\\x00\\x00']\n",
      "Bad pipe message: %s [b' \\x00\\x1e\\x06\\x01\\x06\\x02\\x06\\x03\\x05\\x01\\x05']\n",
      "Bad pipe message: %s [b'\\x03', b'\\x04\\x02\\x04', b'\\x01\\x03', b'\\x03', b'\\x02', b'\\x03']\n",
      "Bad pipe message: %s [b\"\\xa2\\xf9\\r0+\\xab%G\\xb6\\xe9^\\xf3\\n\\xd5\\xff\\x02\\x9bz\\x00\\x00\\xf4\\xc00\\xc0,\\xc0(\\xc0$\\xc0\\x14\\xc0\\n\\x00\\xa5\\x00\\xa3\\x00\\xa1\\x00\\x9f\\x00k\\x00j\\x00i\\x00h\\x009\\x008\\x007\\x006\\x00\\x88\\x00\\x87\\x00\\x86\\x00\\x85\\xc0\\x19\\x00\\xa7\\x00m\\x00:\\x00\\x89\\xc02\\xc0.\\xc0*\\xc0&\\xc0\\x0f\\xc0\\x05\\x00\\x9d\\x00=\\x005\\x00\\x84\\xc0/\\xc0+\\xc0'\\xc0#\\xc0\\x13\\xc0\\t\\x00\\xa4\\x00\\xa2\\x00\\xa0\\x00\\x9e\\x00g\\x00@\\x00?\\x00>\\x003\\x002\\x001\\x000\\x00\\x9a\\x00\\x99\\x00\\x98\\x00\\x97\\x00E\\x00D\\x00C\\x00B\\xc0\\x18\\x00\\xa6\\x00l\\x004\\x00\\x9b\\x00F\\xc01\\xc0-\\xc0)\\xc0%\\xc0\\x0e\\xc0\\x04\\x00\\x9c\\x00<\\x00/\\x00\\x96\\x00A\\x00\\x07\\xc0\\x11\\xc0\\x07\\xc0\\x16\\x00\\x18\\xc0\\x0c\\xc0\\x02\\x00\\x05\\x00\\x04\\xc0\\x12\\xc0\\x08\\x00\\x16\\x00\\x13\\x00\\x10\\x00\\r\\xc0\\x17\\x00\\x1b\\xc0\\r\\xc0\\x03\\x00\\n\\x00\\x15\\x00\\x12\\x00\\x0f\\x00\\x0c\\x00\\x1a\\x00\\t\\x00\\x14\\x00\\x11\\x00\", b'\\x08\\x00\\x06\\x00\\x17\\x00\\x03\\xc0\\x10\\xc0\\x06\\xc0\\x15\\xc0\\x0b\\xc0\\x01\\x00;\\x00\\x02\\x00\\x01\\x00']\n"
     ]
    }
   ],
   "source": [
    "import os, openai, time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv() # reads from .env file\n",
    "\n",
    "azure_openai_endpoint        = os.getenv('AZURE_OPENAI_ENDPOINT')\n",
    "azure_openai_deployment_name = os.getenv('AZURE_OPENAI_DEPLOYMENT_NAME')\n",
    "azure_openai_api_key         = os.getenv('AZURE_OPENAI_API_KEY')\n",
    "\n",
    "cogSvcsEndpoint              = os.getenv(\"COGNITIVE_SERVICES_ENDPOINT\")\n",
    "cogSvcsApiKey                = os.getenv(\"COGNITIVE_SERVICES_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16e9aa84",
   "metadata": {},
   "source": [
    "# Setup\n",
    "Import Semantic Kernel SDK from pypi.org"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "152be04e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python -m pip install -r requirements.txt\n",
    "\n",
    "import semantic_kernel as sk\n",
    "\n",
    "kernel_emb = sk.Kernel()\n",
    "kernel_prompt = sk.Kernel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1e85193",
   "metadata": {},
   "outputs": [],
   "source": [
    "from semantic_kernel.ai.open_ai import AzureTextCompletion, OpenAITextEmbedding\n",
    "\n",
    "deployment_embeddings, api_key, endpoint = sk.azure_openai_settings_from_dot_env()\n",
    "deployment_embeddings = \"text-embedding-ada-002\"\n",
    "\n",
    "kernel_emb.config.add_embedding_backend(deployment_embeddings, OpenAITextEmbedding(deployment_embeddings, endpoint, api_key))\n",
    "kernel_emb.config.set_default_embedding_backend(deployment_embeddings)\n",
    "\n",
    "# print(f\"deployment:\\t{deployment_embeddings}\\napi_key:\\t{api_key}\\nendpoint:\\t{endpoint}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5e62ae5",
   "metadata": {},
   "source": [
    "# Calculate Word Embeddings\n",
    "To use word embeddings for semantic search, you first compute the embeddings for a corpus of text using a word embedding algorithm. What does this mean? We are going to create a numerical representation of each of these words. To perform this computation, we'll use OpenAI's 'get_embedding' function.\n",
    "\n",
    "Since we have our words in a pandas dataframe, we can use \"apply\" to apply the get_embedding function to each row in the dataframe. We then store the calculated word embeddings in a new text file called \"word_embeddings.csv\" so that we don't have to call OpenAI again to perform these calculations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c228fe49",
   "metadata": {},
   "source": [
    "# Generate text embeddings with Azure Open AI\n",
    "https://learn.microsoft.com/en-us/azure/cognitive-services/openai/how-to/embeddings?tabs=console"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ddbc8e9",
   "metadata": {},
   "source": [
    "## generate a single embedding with Azure Open AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2cdcf11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import time\n",
    "\n",
    "openai.api_type = \"azure\"\n",
    "openai.api_key = api_key\n",
    "openai.api_base = endpoint\n",
    "openai.api_version = \"2022-12-01\"\n",
    "\n",
    "response = openai.Embedding.create(\n",
    "    input=\"coniglio\",\n",
    "    engine=deployment_embeddings\n",
    ")\n",
    "embeddings = response['data'][0]['embedding']\n",
    "embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b93611f0",
   "metadata": {},
   "source": [
    "## operationalize openai embeddings function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0573ad2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_openai_embeddings(text, opeanaiEndpoint, openaiApiKey):\n",
    "    import openai\n",
    "    \n",
    "    openai.api_type = \"azure\"\n",
    "    openai.api_version = \"2022-12-01\"\n",
    "    openai.api_base = opeanaiEndpoint\n",
    "    openai.api_key = openaiApiKey\n",
    "    \n",
    "    response = openai.Embedding.create(\n",
    "        input=text,\n",
    "        engine=deployment_embeddings)    \n",
    "    \n",
    "    return response['data'][0]['embedding']\n",
    "\n",
    "embeddings = generate_openai_embeddings (\"coniglio\", azure_openai_endpoint, azure_openai_api_key)\n",
    "print(f\"embeddings shape: {np.array(embeddings).shape}. Now showing the first 5 elements:\\n{embeddings[:5]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44856ccc",
   "metadata": {},
   "source": [
    "# Generate text embeddings with Azure Computer Vision Image Retrieval\n",
    "https://learn.microsoft.com/en-us/azure/cognitive-services/computer-vision/overview-image-analysis?tabs=4-0#image-retrieval-v40-preview-only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8650d421",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_cv_embeddings(text, cogSvcsEndpoint, cogSvcsApiKey):\n",
    "    import requests\n",
    "    url = f\"{cogSvcsEndpoint}/computervision/retrieval:vectorizeText\"  \n",
    "  \n",
    "    params = {  \n",
    "        \"api-version\": \"2023-02-01-preview\"  \n",
    "    }  \n",
    "  \n",
    "    headers = {  \n",
    "        \"Content-Type\": \"application/json\",  \n",
    "        \"Ocp-Apim-Subscription-Key\": cogSvcsApiKey  \n",
    "    }  \n",
    "  \n",
    "    data = {  \n",
    "        \"text\": text  \n",
    "    }  \n",
    "  \n",
    "    response = requests.post(url, params=params, headers=headers, json=data)  \n",
    "  \n",
    "    if response.status_code == 200:  \n",
    "        embeddings = response.json()[\"vector\"]  \n",
    "        return embeddings  \n",
    "    else:  \n",
    "        print(f\"Error: {response.status_code} - {response.text}\")  \n",
    "        return None  \n",
    "\n",
    "embeddings = generate_cv_embeddings (\"coniglio\", cogSvcsEndpoint, cogSvcsApiKey)\n",
    "print(f\"embeddings shape: {np.array(embeddings).shape}. Now showing the first 5 elements:\\n{embeddings[:5]}\")"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "iVBORw0KGgoAAAANSUhEUgAAAakAAABnCAYAAAC6ub0rAAAa9UlEQVR4nO2dT2jcSPbHv1l8CKxhfQhMDgZXw0IWJpAcDOuBWSxBDjP44IFNIDmElthAWPZgN8Swl9ASe8iCDbYPPgSySE0G4sE+JIewWdjQauwhCeTgAQcS1qBqxgs+5OCDBwIb0O/g36tI3Wr96W67/+R9wNDdkkpV6raeXtX3vXcmCIIADMMwDNOH/KrXHWAYhmGYVrCRYhiGYfqWkV53gGEYZtCRUmJ1dRWHh4coFouQUqJWq6FcLkMI0evuDTTsSTEMw3RIpVLB8vIyXNcFABiGASklpJQ97tngc4aFEwzDMJ0jpYRpmqhWq5BSQtd1+L7f624NPOxJMQzDdIFKpQJN0wAcGyxN09iT6gJspBiGYbrAs2fPMD09DeDYSAkhUKlUetyrwYen+xiGYbqA53nKk4p7z7QHGymGYRimb+HpPoZhGKZv4TgphmGYnJDUPC+apnHcVE7YSDEMw+RASolKpQLP82BZlhJLhDk4OMCHDx8AALVaTRk1TdNQrVbbOq9pmrmDg5NitQZlvYzXpBiGYXIipUShUIAQIlMsFBk213Xbip2ybRuWZaFareYyLq7rKoNqGIYycFJKJexwHCd3f06VgGEYhsmN4zgBgMAwjMzHzM/PB47j5DqP7/sBgABAUK1W83YzmJ+fDwAEW1tbkc+p/+20eZqwcIJhGKYNDMOAYRhwXRelUinTMXNzc7nPY5omLMsCgLaCg1++fImrV6/i66+/jt3e7wHHbKQYhmHahNaIHj9+jO3t7dT9hRAwDCNz+57nQQih1r3q9XruPr58+RKjo6NNn9u2nbs/vYCNFMMwTJsIIVSuvps3b3a9fdu24ThO24pAEmx8+eWXkFJie3sbnuehUCjAMIyByC3I6j6GYZgOEELAsixYlgXTNLsmRHBdFzMzM5HP8k7Nkef16tUrvHr1CgAwOjqKycnJWFViP8LqPoZhmA6hDOie5+VW4LWiUChE5OqFQiFWwm6aJqanp2On7XRdB4CmY5aWlrCwsBDpa79mbmdPimEYpkOEEHAcB4VCoSvtmaYJTdNg23bkc4q9CpPkuZH0vJFz584BOI7hIiNFU5f9BhsphmGYLlCpVOA4TsdelOd5AJqNT1xgruu6EELEnpPWo+Km9Wq1GgBgYmIisn8/BviycIJhGKZDPM/D7u5ux0o5KSVs20a5XG65nSB1nmmasfuSIWo0PJ7nKYNE/TVNE/V6XRnIfoI9KYZhmA5YX1/H/fv3O54qo6wSwLFXFjZUtm1jb28PwLFBKRaLKBaLANCk/PM8T6ViEkJgYWEBFy9eBAA8ePAAIyMjsCxLtS+lRLFYxNraGn796193NIaTgIUTDMMwbSKlxI0bN/DixYvMx8QpAH/88Uf873//U++FEJEURo3TfLQ9TjSRlK8PiM/Z16+iCYCNFMMwTNtcu3YNf/zjH3H9+vVM++u6jmKx2JUAWjIs1Wq1yfPKS1ig0Uk7JwFP9zFMn0FZBrpZ0iEtvobLR+RH13WUy+VMYoNGiXo3IMHE5uZmx4ZlenoatVqNp/sYhkmGsmuH1wy60aau6xFDFTZKUkp1w8tbCuJzxbZt9TCRBGUbJwzD6P+s430GGymG6SNM01TSYd/3u2owXNdVSrBw2+Gn/KylJz53XNfFTz/9BAAYGxtL3Pfw8FC9/v3vf595apA5hqf7GKZPkFJGKr62CsTsNkIIzMzMwPO8SJ0hpjX9npR1mOA4KYbpEyqVSmQtqlKpnNq537x5o17zdB/TT7CRYpg+gdahvvvuOwBQns1JQ8GdADrKuP05Eb5meXBdt+/rN/UbbKQYpg+gwEvDMDA7O6s+PylvStd1FAoFFAoFtU5lWRZPY2WExCZZ8TwPtm035eJjMtCrksAMw3zCMIzAsiz1XgihSob7vp96vOM4qWXMqVx4XJuWZQUAAiFE35cTH2SEEJm+T+YT7EkxTI8hwYTneTBNE6ZpRp7Ss+RTq1QqbU0/EZRih3LHMa2xbRumaappO8rw0OqP6QxW9zFMj1ldXW3KZC2EwN7eHvb391GpVFKn4TpdSyLBhpRS5YhjmrFtG8ViEYVCQcU7JT1EdDso+3OEjRTD9JiVlRU4jhNriCzLUgKKpJtdpzfCsEjj1q1bHbU1zJTL5UgiWIDl6CcNGymm71lfX8f+/j7u3LkTuz18A6cpr0G4cYSnjGq1WsSboowG4X2FEG1nhAifi9onwlkRpqam+i53W78hpcT09LSKJ0uaHp2YmBiI32I/c6oZJ6iGSa/cX3pa7MaPhv6pNU1TEfvUdrf+yU8ih9ug4XmeKibXyPr6OlZXV3H27NlI0k4qu93v161xDSlspFrJz9v5/2lMzdMKvplmo1AoqIeFrEHPUkpsbm5iYWEBjuPg7NmznHkiK6el0Nje3g4ABJqmndYpm9A0LejWkIUQgRAiCIIg8H0/8H0/EEKkKqyyQmorx3Einze+H3ZafV+O46jrX61WI7+r+fl5VlExJ0a1Ws2tgPR9Xx1XrVb5t5mDU/WkbNvGhQsXevYEsb6+jg8fPnTliTGubLOu6xBCdCWBpJQyNv3+mTNncIpfWU+haZTGa0BJWKvVqrr+Z86cwdbWFr7++msAn5522TtgmMGGE8x2kW4aqTjo5vy5fGWkoGqcUrFtG67rqkSocUZraWkJT58+7VpZBIZhekOscILKD0spMTY2hrm5ucg8uG3bar78T3/6k3p6pWOllKjVahgbG8OlS5dgGAZc11WLw+VyWXkKwHEtE+B48Rg4jtlonHcPnzNp8ZjapX3pfDSm3d1dLC4uQggRWfAsFovquLGxMSwvL0f6GO4TtUV9aUVjXxoraNL5JyYmUK/XIaVU7dFxxWIRmqbB8zzouh45jvpUKpVw6dIl1Ot1TE9Pq8Xcw8NDjI2NnehCOI1xd3cXo6OjTWNcX1/Hu3fv1GJzYwXR8PUBoAw8xZg0GigpJSzLiqir6PjwvpOTk1hbW+vuYBmGOXWajNT6+jpu3LiBR48eoVwuo1Ao4OXLl6o8cqFQwL1795ShWVhYwN7eHgzDUKk/6Im2UqmgVqvBMAxlFMhoAMc3Z1ItkeCAghnDT8C6rmNmZgaO46BUKkHXddy7dy922tA0TZTLZdU/mvYZGRlRi5eLi4vq/GSEPM9TN8hCoYD9/X1cvHhRSU7DpZUPDg6UMU4yAKTQ8n1f1fSp1+uR8du2jY8fP+Lhw4d48OABgE+Gz3VdZcAPDg4wPz+PlZUVXLhwAQBUXMulS5eU4aJtwLG0OXwzbyRP8Gfcgn249tHGxgZM04Rt28oQkZikWq0qg/TVV1+p35Ku63AcJ/JdhY1U3IMICQCklCiVShgbG4ut60PXJkm6nVVQQPDUYfvkudZ5BAnMZ0DjIhUaFustywoWFxeDIDhO3dIofKhWq2oB27KsyIK17/uRtq5evdp0PICI2GBxcTGStuXq1atNi+fnz5+PpJBpbC+8Lfy6Wq02pYQhgcLW1pb6TAgR6eejR48CAJHFUhprGE3TImOpVqtN1zLuGBofCTDCYwkfT2lt4iCxQHjfNJFFeCE37S8OTdMi5/R9X13vuGvt+35kTEnfVVgYETdOGh/tFyfISRNPNC5mJ/3xQndn8LVm2iXiScU9WYc9hVZ1ZugpqVgswnVdFAqFiHdEjI6O4v37903Hh590x8fHI9tGR0chhFBJMAHg7NmzLdON0FQQCRuyTnWFpyzT+pQVkqeTl9MqA/LU1FTTOfMyNzeHlZUVuK4LwzBQqVRS12M6fVrd29vDlStX1Pvw9SYPNTwmktNTBoXwdzU5Oak83PD+jezs7KjfFvCpYF8rLyepJlM35f2u68KyLJw5c0Z9FgSBeh/8/zpi0vtBPlYIkfh76+a1tiwrknh30K4VH5t+LIUrAQ3TffQjSpoeafUZrR9Uq1UV22JZFnZ3d7GxsRHbHhGuXHn+/PnY9rOKEcrlMiYmJlCr1ZRRiFt8DxM33qOjI/W6XSNFlVDDpcDjpt9+97vftdV++KGBpkju37+vplfTyJNXLK69/f39lm2Er1+rtq5cuRL5rl6/fh2pCtvq9xY2OlSDKe5hJMv4sl6DtOupaRpqtVpE1BJWYmb5Bx3kY7OUUc9KWluNDyWDdq342PRjJyYm1LGxRqpWq0Vu6nQzJM8gDHlGmqZFyg3QGlXYA2oHTdNgWRa2t7ebBBpxhkfXdVSr1cgaV6+SPJqmicXFxdhMCeTxtIuUEk+ePIlcg3K5DF3Xoet6Jg/S8zzU6/VM54sTs8T9Huj9zMwMNjc3m9aEwvuvrKxgY2NDfVd/+MMf1PdKa0qNNPbhwYMHePjwYdN+YeFMK8LCmDTSMgf0e+BwryExVRbSrnX4BsYMP01GiqZf6KZE/8iapsFxHOi6rm4kUko8ffpUPbnX63U8ffo0kqwyyYOhG8nY2FjTZwRNIT5//lwZKTKGce3Rgvry8rJK0tnOtFZ4WnJzczNxDHGL9PQ6XPGUxua6rjIO7STzpHbCdYeA4+9vamoq85g7FQLcvn0bN27cgG3byiiapqk8VxLPhLeRRF9KidevX0eM0sjIiOo3TRk3GrnLly9jd3cXwLEw5be//W3sWF++fAkgeUozz3Qw0xn0e2CYvDTFSSXJgmm7bdt4+/YtDg4OIutOtPZCx5JiTtM0JZ8Gjm8OxWIxIgEPp4Mhbt++jevXr0NKiT//+c84PDxsSoHT2HfTNKFpGp49exbZ13XdyFNzuVxuGicp+cL9nJ6ejhw3MzODN2/eRI7729/+hrt376r3586dw8bGhlI77u3tYWRkBOVyGffv3wcAvHjxInJN6DoLIZr6Gh6vaZpqnSXuBmvb9qnmC5NS4saNGzg4OFBjoO8y/FsiYxRW79F39fjxYxweHjYF37aKk/rqq6/UFGmraWDXdXH37l38/PPPXR8zwzCnSJqygul/wmoowzCGRh01Pz/fUsWZRmMRwdOkUdVK6thutR1uL67t8LnbSeHTirDyrnGMDHNScBb0IaDR4xiW9ZG5uTmYphm7HpYEeW5hEcZpIqWMTBeHp3xbUSqVsLKyAt/3U8f6yy+/qNevXr1q2k6xidSXcHulUgk7OzuJ7c/MzODq1auxcXHAp99X1vXMfkRKiZs3b+Lnn3/ue7XbxMRErni+OP7617/ihx9+GAh1X+PsCRupIWBqagqVSgU//PAD/vnPf/a6O12DFItxOQyToCDhXvLf//431/4rKysAjgsgLi8vZz5uf38/13lmZ2cxOzurppoNw1BVeQFgbW0NCwsLWFtba8ok//79+6F5AJJSYnJyEt9//33fq926cc1rtRqq1epAqPsax8tGagh48eJFk/pxWCiXyyiVSlhfX8+UmJhEHP20SJ8kxwei67CPHz9uSkOWxNmzZ3Odr/G6xFUEJlVm3oeDQeLJkyeYnZ39LJSCUkp88803A/uAwUZqSBhGA0Xk8Sz65aYaVqymQbFepBBNCkAGonGFTHscHh721YPMSdKrEJxu8ated4BhPmeklHBdNzK1ljV26yQIq1spb+Qw8u9//7vXXTg1arXaQH+XbKQYpoesrq6quMK0qrwnAWVFMU0ThUJBpaPxfX9oPQ0pZSSd17DTKvHBoMBGimF6yMrKipqiDAsYVldXT+X8mqahWCyiWCzCcZxIpphBnyZqxf7+/sCuz7RDOwkD+glek2KYHkGZU4QQTRLjvAKKdmkUTlAmGapf1isZ/0ny/PnzSEmbOCjZNiUCoNeDRhav0fM8vH79GlevXoXneXj//n1sCEKvYE+KYXoEFRal6TZKGwXkr3XVTcJ9GFZvKkkpSmMO10er1Wo9+z46JUvy3zdv3uDGjRswDAO//PILFhYWTql36bCRYpgeQIIJ3/eb/notoAgbpn55mu4mWQwv5ZMMFyAdxHWdSqWS6jVqmoa3b9/i3r176rOLFy+edNcyw9N9DHPKeJ6HtbW1SKZ3Mgae5+H8+fPKk6Kn9zw3yNHR0Zbbtre38fHjR/U+7LFRbBS9b6wPde7cucx96GfSjBTlz4zL2pFU6blfSYsvFELg5cuXEeHO7du3T6NrmWAjxTCnSDh5sBACtm0rY0DJm8+ePatuGLZt48OHD3jx4kVXzv+Pf/wjUp0gXJSToOTFg3YzzsL29nYmgx9O+URFOsPZ/geFrDXVGqd4p6am+ma8bKQY5gRoFXBLtdbiSKtuS+QJFG6k1+mies3e3l7mmKGw6nJ1dbWpNM4gkMVIUbUK4JOQxrbtvvmtsJFimBMmafqtUz58+HBibQ8j9Xo9k0ov7EEIIXJlPekX0ur5EY3Xo1+ME8HCCYZhPhuoGObngOd5A51pgmBPimG6zMHBAS5dunRi7YeTolLxxyS6ubY0MvLpljGIyVnfvn3b6y60hCp2SykxPT3dcVxWVq+xF4QLoh4dHWFxcbHl77SpMi/DMMww0iqzO5WKmJqaijX6R0dHqj5YOFbKMIy2p8aWlpZw586dSN90XVdrkoVCAVtbWx0ljv7222+bSvdQ3bLGIO4w4crqhBCiq4Hdtm1jenoamqap+MBWIg32pBiG+SxoJSJwHAemaWJ8fDzV6JBk37bttoN7Pc/DwsICJicnm7J9hL2Jvb29joxUnNc4NzeHx48fA0AmBSepP13XzZQDUNf1xDg7KqMT9sKnp6eTlYQnUu+XYRimz7AsK6hWqy23AQgsy8rUlu/7gaZpLdtLQtO0AEDLY33fD8bHx3O329hGq7E8evQoABAIITK35zhOoGlapn3pWjZC4/Z9P/L5/Px84nVn4QTDMJ8FSZ5AsVjE1NSU8hjSEELAcZzcWUFc11WKzFaenW3bePjwYa52G0mSnl+/fh2WZUFKiVKplKk9wzBUXsc0PM+L9dDIUwpfX8/zsLOzkxyPldmUMgzDDDBp3onv+7k9jLxcvnw52Nraaum1GYYRVKvVwPf9trw0IslrDIJPniASPLp2SRobQp5UtVoNDMMIgiAItra2WrbHnhTDMENPlmzg5B1R0t9uY5omlpeXMT4+Hru9VCqpci2d5m1MWz+isVK/upVIeH19PfZzWtei4p601lUsFuG6Lu7evduyTRZOMAwz9GTNuWcYBu7fvw/XdbsiAye2t7cBIDJl5nleJIHtzs4OdnZ21DGdpCTKUkOKDBVl4M+S7SSNd+/eATiOR/v2228BHAs4NE1DEBKSU5Z1SskVrqXWRFf9PIZhmD7Esqzg0aNHmfb1fT8QQgRCiKZF/nbRNC3SFoDMQoS8+L6vptGykFc0koSmabHTpZqmNV2DrPB0H8MwnwVp2cCJ8LRfY/LddlhaWlJTiLquQ9d1ANny6rVD3kztxWIRmqZ1pV5Wq2nGcrkMz/Pamsbk6T6GYYaevAaBgl27kcfu6dOnTYGwjfFEYbIYmaR9arUafvOb32TuH7XTacbzxrIzjX0CWideToI9KYZhBp60xf+8RipcQqUTkoJU4/pkmmaqR+N5HjY3NxP3mZ+fz9zHUqmkgmw7gbykuPUly7IwPj4eSdQrpUShUEhtl40UwzADDVU5Ttqe5was63ryQn7GPpmmCcuycHBw0LSNaOy34zipYo2bN2/izZs3iefOyvr6OsbGxjo2UJ7nwXVdCCGwv7+v6lK5rotCoQAhRFPsV9ZUS5y7j2GYgUbXdVUTKe4GH84Tl6WtPF5FK08pLGE/OjrCxsYGgPgik6QipJt80rlt24ZlWdA0raWnF84BmASld8rqMbZab0pba/riiy/w97//PfIZ5VEsFoupU5u8JsUwzMAS9hpqtVpLLySL0aG4nawGynXdxHyAcYTjk8IsLS1hcnISuq4jyW949uxZYuaHrF4jGcusBoo8wzjPR9O03J4YGTXP81I9R57uYxhmYKlUKipAtBW7u7up7Xieh93d3cxxUZ7nwTTNrpVXn5ychBAicRxSSty+fVsFw8YZqkqlklpDql0D1emUYJhisdgyfVIj7EkxDDOwhI1EK+9if38/sQ0yOI7jJIoWpJSo1+sRD6pbtbqoZHuSkRRCqO3Uh7jzpxkTMjhJYz04OMC7d+/w7NkzVSjy0aNHWYaSmaxeHxsphmEGnsnJSWxubjbduH/88Ud88803icdWKhV8/PgRN2/ejBR1bOTjx4/q9fj4eFeLSQJQaYMSy1bgk2F8/fp1000+TTRh2zY+fPiABw8eJIpNgE/jpTROWePMslCpVGAYBkqlEubm5hKvJRsphmEGnpmZmVhZ9n/+85/UY7sRC9UNhBCRVEmtIMMUp/BLqzxcLpe7NkXZCcViUa0BsnCCYZihh250jQvx9Xo9dY2mX8gTl0XrUmG2t7dTvcZ+oZWAJA4WTjAMM/CQkaLMBkSWarJA+ymKTiq1URrkdYXJklQWaL/PrTKcnzRspBiGGXhIGdd4A85yQ85a6JDwPA/Xrl1DoVDoqZECouP76aefMin78pYhuXbtGnRdx7/+9a/8He0CbKQYhhkKGo1UVvWYYRi5SnJomqaCc3vFF198ASBqpHZ2dlLHK4TIne5pY2Ojq/LzvLCRYhhmKDh37lwkfihLolbP87qS/fu0obWnRqOcBHlRvfL+2oWFEwzDDAWk8CPjVKvVcOHChZb7k0Gj7AcUq5REPyjjgE8KP8qyIaVM9QYpeHZ1dRXLy8vwPK9pDS9MFuXdacBGimGYoaAxfkhKmZooVtM03L17V930+8UIZSE8vZnFOzIMQ+UmBNpLZ9QL2EgxDDMUxMUPJXkCQgiUSiXcunVLeV9JntTExETXysl3g7DC78mTJ5idnU3cf3t7G3t7e8qASynZk2IYhjlN4hR+STx+/Bi+76ssD4PmSQHHXtTh4WGqQXn+/Dlu3boF13VhGEZqxvVGjo6OOupvu7BwgmGYoYG8i6wl1P/yl7+kpiFqhHL9aZqGSqXSlRLz7UBycykljo6OUsdbLBYxMTGR2zsiscXo6Ghu+Xo3YE+KYZihgW7AlHInjTt37uQ+R7+s5YQDmEdHRzPt3850Za/TRrEnxTDM0PDll18CyF+NdxCh8Xmeh7GxsR735uRgI8UwzNAwOTkJoHfpik4bmt5ME00MMmykGIYZGsi76AdV2mlA4x1mr5GNFMMwQ8X4+DguX77c626cCmnVfIcBNlIMwwwVV65cwaVLl3rdjVOhHbXeoMHqPoZhhorp6em+Cro9SYZ5mo84EwRB0OtOMAzDMEwc/wdNg4Nw16zj0AAAAABJRU5ErkJggg=="
    }
   },
   "cell_type": "markdown",
   "id": "ff64f0d5",
   "metadata": {},
   "source": [
    "# Cosine similarity\n",
    "https://en.wikipedia.org/wiki/Cosine_similarity\n",
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef3de1f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "v1 = np.array([1,2,3])\n",
    "v2 = np.array([4,5,6])\n",
    "numerator = np.dot(v1,v2) # 4+10+18\n",
    "numerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ec273d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "denominator_1 = np.linalg.norm(v1) # sqrt (1+4+9) = 3.74\n",
    "denominator_2 = np.linalg.norm(v2) # sqrt (16+25+36) = 8.77\n",
    "denominator   = denominator_1 * denominator_2\n",
    "denominator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2203cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(numerator / denominator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8873d66a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(v1,v2):\n",
    "    numerator = np.dot(v1,v2)\n",
    "    denumerator = np.linalg.norm(v1) * np.linalg.norm(v2)\n",
    "    return numerator / denumerator\n",
    "\n",
    "cosine_similarity(np.array([1,2,3]),np.array([-4,5,6]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97a66d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_similarity(np.array([1,2,3,-1,2,3,-1,2,3,-1,2,3]),np.array([-4,5,6,4,5,-6,4,5,-6,4,5,6]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c9446de",
   "metadata": {},
   "source": [
    "## Check distance between two words (AzureOpenAI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a607b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "v1 = generate_openai_embeddings (\"coniglio\", azure_openai_endpoint, azure_openai_api_key)\n",
    "v2 = generate_openai_embeddings (\"elefante\", azure_openai_endpoint, azure_openai_api_key)\n",
    "\n",
    "cosine_similarity(v1,v2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9510dcff",
   "metadata": {},
   "source": [
    "## Check distance between two words (Computer Vision Image Retrieval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35d574dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "v1 = generate_cv_embeddings (\"coniglio\", cogSvcsEndpoint, cogSvcsApiKey)\n",
    "v2 = generate_cv_embeddings (\"elefante\", cogSvcsEndpoint, cogSvcsApiKey)\n",
    "\n",
    "cosine_similarity(v1,v2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3026fd26",
   "metadata": {},
   "source": [
    "# Read Data File Containing Words\n",
    "Now that we have configured OpenAI, let's start with a simple CSV file with familiar words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee6980fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = 'words'\n",
    "openai_df = pd.read_csv(f'{file_name}.csv')\n",
    "cv_df     = openai_df.copy()\n",
    "print(openai_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "874dd9b8",
   "metadata": {},
   "source": [
    "# Check words similarity (Azure Open AI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad01b38c",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:    \n",
    "    openai_df[\"text_embeddings\"] = openai_df[\"text\"].apply(lambda x: generate_openai_embeddings(x, azure_openai_endpoint, azure_openai_api_key))\n",
    "    openai_df.to_pickle(f\"{file_name}_enriched.pkl\") # type(df['embeddings'][0][0]) --> float  \n",
    "except:\n",
    "    print('switching to pickle file...')\n",
    "    openai_df = pd.read_pickle(f\"{file_name}_enriched.pkl\")\n",
    "\n",
    "openai_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a10390bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_term = input ('Insert a search term:\\n') # hot dog\n",
    "\n",
    "search_term_vector = generate_openai_embeddings(search_term, azure_openai_endpoint, azure_openai_api_key)\n",
    "openai_df[\"similarity\"] = openai_df[\"text_embeddings\"].apply(lambda x: cosine_similarity(x,search_term_vector))\n",
    "openai_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdbbe742",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_df.sort_values(\"similarity\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34b7362e",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_term = \"\" # torta\n",
    "search_term_vector = generate_openai_embeddings(search_term, azure_openai_endpoint, azure_openai_api_key)\n",
    "openai_df2 = openai_df.copy()\n",
    "openai_df2[\"similarity\"] = openai_df2[\"text_embeddings\"].apply(lambda x: cosine_similarity(x,search_term_vector))\n",
    "openai_df2 = openai_df2.sort_values(\"similarity\", ascending=False)\n",
    "openai_df2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79b6fa21",
   "metadata": {},
   "source": [
    "# Check words similarity (Computer Vision Image Retrieval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34907772",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:    \n",
    "    cv_df[\"text_embeddings\"] = cv_df[\"text\"].apply(lambda x: generate_cv_embeddings (x, cogSvcsEndpoint, cogSvcsApiKey))\n",
    "    cv_df.to_pickle(f\"{file_name}_cv_enriched.pkl\") # type(df['embeddings'][0][0]) --> float  \n",
    "except:\n",
    "    print('switching to pickle file...')\n",
    "    cv_df = pd.read_pickle(f\"{file_name}_cv_enriched.pkl\")\n",
    "\n",
    "cv_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d60aac11",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_term = input ('Insert a search term:\\n') # hot dog\n",
    "\n",
    "search_term_vector = generate_cv_embeddings(search_term, cogSvcsEndpoint, cogSvcsApiKey)\n",
    "cv_df[\"similarity\"] = cv_df[\"text_embeddings\"].apply(lambda x: cosine_similarity(x,search_term_vector))\n",
    "cv_df.sort_values(\"similarity\", ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6002787f",
   "metadata": {},
   "source": [
    "# Azure Open AI vs. Computer Vision Image Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e0bb36",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([\n",
    "    cv_df.sort_values(\"similarity\", ascending=False).reset_index(drop=True).rename(columns={'text': 'openai'}), \n",
    "    openai_df.sort_values(\"similarity\", ascending=False).reset_index(drop=True).rename(columns={'text': 'cog_svc'})], \n",
    "    axis=1).drop(['similarity', 'text_embeddings'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9bf4161",
   "metadata": {},
   "source": [
    "# Campaign Speeches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48a4c4c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = 'discorso_presidente_del_consiglio'\n",
    "\n",
    "openai_df = pd.read_csv(f'{file_name}.csv')\n",
    "\n",
    "openai_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84f9fdb4",
   "metadata": {},
   "source": [
    "## Embeddings generation for Campaign Speech with Azure Open AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21ad47a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "try:\n",
    "    openai_df[\"text_embeddings\"] = openai_df[\"text\"].apply(lambda x: generate_openai_embeddings(x, azure_openai_endpoint, azure_openai_api_key))\n",
    "    openai_df.to_pickle(f\"{file_name}_openai_enriched.pkl\") # type(df['embeddings'][0][0]) --> float\n",
    "    openai_df.to_csv(f\"{file_name}_openai_enriched.csv\") # type(df['embeddings'][0][0]) --> string\n",
    "\n",
    "except:\n",
    "    print(\"switching to pickle file...\")\n",
    "    openai_df = pd.read_pickle(f\"{file_name}_openai_enriched.pkl\")\n",
    "\n",
    "end = time.time()\n",
    "print(f\"duration: {end - start}\")\n",
    "\n",
    "openai_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77d282be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# accoglienza profughi extracomunitari\n",
    "# a quali gruppi appartiene l'Italia?\n",
    "search_term = input ('Insert a search term:\\n') \n",
    "\n",
    "search_term_vector = generate_openai_embeddings(search_term, azure_openai_endpoint, azure_openai_api_key)\n",
    "openai_df[\"similarity\"] = openai_df[\"text_embeddings\"].apply(lambda x: cosine_similarity(x,search_term_vector))\n",
    "openai_df.sort_values(\"similarity\", ascending=False).head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27b52e6c",
   "metadata": {},
   "source": [
    "## Embeddings generation for Campaign Speech with Computer Vision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7459c47e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_df = openai_df.copy()\n",
    "\n",
    "start = time.time()\n",
    "try:\n",
    "    cv_df[\"text_embeddings\"] = cv_df[\"text\"].apply(lambda x: generate_cv_embeddings (x, cogSvcsEndpoint, cogSvcsApiKey))\n",
    "    cv_df.to_pickle(f\"{file_name}_cv_enriched.pkl\") # type(df['embeddings'][0][0]) --> float\n",
    "    cv_df.to_csv(f\"{file_name}_cv_enriched.csv\") # type(df['embeddings'][0][0]) --> string\n",
    "\n",
    "except:\n",
    "    print(\"switching to pickle file...\")\n",
    "    cv_df = pd.read_pickle(f\"{file_name}_cv_enriched.pkl\")\n",
    "\n",
    "end = time.time()\n",
    "print(f\"duration: {end - start}\")\n",
    "\n",
    "cv_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ac5f334",
   "metadata": {},
   "outputs": [],
   "source": [
    "# accoglienza profughi extracomunitari\n",
    "# a quali gruppi appartiene l'Italia?\n",
    "search_term = input ('Insert a search term:\\n') \n",
    "\n",
    "search_term_vector = generate_cv_embeddings (search_term, cogSvcsEndpoint, cogSvcsApiKey)\n",
    "cv_df[\"similarity\"] = cv_df[\"text_embeddings\"].apply(lambda x: cosine_similarity(x,search_term_vector))\n",
    "cv_df.sort_values(\"similarity\", ascending=False).head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0f8a9a6",
   "metadata": {},
   "source": [
    "## Generalize top paragraphs identification with Azure Open AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81edfaf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_paragraphs_identification (search_term, top_terms=5):\n",
    "    search_term_vector = generate_openai_embeddings(search_term, azure_openai_endpoint, azure_openai_api_key)\n",
    "    openai_df[\"similarity\"] = openai_df[\"text_embeddings\"].apply(lambda x: cosine_similarity(x,search_term_vector))\n",
    "    return openai_df.sort_values(\"similarity\", ascending=False).head(top_terms)\n",
    "\n",
    "question = \"quale strada vuole perseguire il governo?\"\n",
    "best_paragraphs_df = top_paragraphs_identification(question)\n",
    "best_paragraph_nr = best_paragraphs_df.index[0]\n",
    "best_paragraph_text = best_paragraphs_df[\"text\"][best_paragraph_nr]\n",
    "print(f\"The best answer should be in paragraph #{best_paragraph_nr}:\\n{best_paragraph_text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c33af74",
   "metadata": {},
   "source": [
    "# Semantic Kernel in Action!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a328f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "from semantic_kernel.ai.open_ai import AzureTextCompletion\n",
    "\n",
    "deployment, api_key, endpoint = sk.azure_openai_settings_from_dot_env()\n",
    "deployment_completion = \"text-davinci-003\"\n",
    "\n",
    "kernel_prompt.config.add_text_backend(deployment_completion, AzureTextCompletion(deployment_completion, endpoint, api_key))\n",
    "kernel_prompt.config.set_default_text_backend(deployment_completion)\n",
    "\n",
    "print(f\"deployment:\\t{deployment_completion}\\napi_key:\\t******\\nendpoint:\\t{endpoint}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cad07862",
   "metadata": {},
   "outputs": [],
   "source": [
    "# note: using find_and_search_skill\n",
    "skills_directory = \"./skills\"\n",
    "\n",
    "mauromi_skills = kernel_prompt.import_semantic_skill_from_directory(skills_directory, \"mauromi_skills\")\n",
    "\n",
    "#...is equivalent to the following two lines:\n",
    "find_and_search_function = mauromi_skills[\"find_and_search_function\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8345a431",
   "metadata": {},
   "outputs": [],
   "source": [
    "skills_directory = \"./skills\"\n",
    "skills_set       = \"mauromi_skills\"\n",
    "specific_skill   = \"find_and_search_function\"\n",
    "\n",
    "# note: using find_and_search_skill...\n",
    "mauromi_skills = kernel_prompt.import_semantic_skill_from_directory(skills_directory, skills_set)\n",
    "find_and_search_function = mauromi_skills[specific_skill]\n",
    "\n",
    "#...is equivalent to the following lines:\n",
    "with open(os.path.join(skills_directory,skills_set,specific_skill,\"skprompt.txt\")) as f:\n",
    "    prompt = f.read()\n",
    "    f.close()\n",
    "    \n",
    "find_and_search_function = kernel_prompt.create_semantic_function(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c7a6b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A quali gruppi appartiene l'Italia?\n",
    "# Quali sono le grandi sfide dell'Unione Europea?\n",
    "# Che cosa hanno fatto le Forze Armate?\n",
    "# A quali gruppi appartiene la Corea del Nord?\n",
    "question = \"A quali gruppi appartiene la Corea del Nord?\"\n",
    "\n",
    "best_paragraphs_df  = top_paragraphs_identification(question)\n",
    "best_paragraph_nr   = best_paragraphs_df.index[0]\n",
    "best_paragraph_text = best_paragraphs_df[\"text\"][best_paragraph_nr]\n",
    "\n",
    "context_variables = sk.ContextVariables()\n",
    "context_variables[\"question\"] = question\n",
    "# context_variables[\"style\"] = 'se non trovi la risposta nel testo, rispondi NON LO SO'\n",
    "\n",
    "# the <input> variable is passed to the semantic function, rather than to ContextVariables()\n",
    "answer = find_and_search_function(input=best_paragraph_text, variables=context_variables)\n",
    "\n",
    "print(f\"Question: {question}\\n\\nAnswer from paragraph {best_paragraph_nr}:\\n{answer.result.lstrip('.').lstrip()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a774385",
   "metadata": {},
   "source": [
    "## Same test, but this time we use *kernel.run_async* that is useful for chaining\n",
    "**ContextVariables** is the same collection object used above, to which we need to add the \"input\" variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6db396d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A quali gruppi appartiene l'Italia?\n",
    "# Quali sono le grandi sfide dell'Unione Europea?\n",
    "# Che cosa hanno fatto le Forze Armate?\n",
    "# A quali gruppi appartiene la Corea del Nord?\n",
    "question = \"A quali gruppi appartiene la Corea del Nord?\"\n",
    "\n",
    "best_paragraphs_df  = top_paragraphs_identification(question)\n",
    "best_paragraph_nr   = best_paragraphs_df.index[0]\n",
    "best_paragraph_text = best_paragraphs_df[\"text\"][best_paragraph_nr]\n",
    "\n",
    "context_variables = sk.ContextVariables()\n",
    "context_variables[\"input\"]    = best_paragraph_text\n",
    "context_variables[\"question\"] = question\n",
    "# context_variables[\"style\"]    = 'se non trovi la risposta nel testo, rispondi NON LO SO'\n",
    "\n",
    "# run_async receives the semantica function and ContextVariables() which contain the <input> too\n",
    "answer = await kernel_prompt.run_async(find_and_search_function, input_vars=context_variables)\n",
    "\n",
    "print(f\"Question: {question}\\n\\nAnswer from paragraph {best_paragraph_nr}:\\n{answer.result.lstrip('.').lstrip()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4752cb8d",
   "metadata": {},
   "source": [
    "## Chain multiple semantic functions\n",
    "In this case I use the SKILLS.\n",
    "This code still does NOT use either:\n",
    "- PLANNER --> this means that we manually concatenate the functions in the kernel.run_async method()\n",
    "- NATIVE function --> so at the moment we can't concatenate the semantic function with the cosine similarity function. This means that <best_paragraph_text> is the 33th paragraph (#32)\n",
    "\n",
    "https://learn.microsoft.com/en-us/semantic-kernel/howto/chainingfunctions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d54a818b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A quali gruppi appartiene l'Italia?\n",
    "# Quali sono le grandi sfide dell'Unione Europea?\n",
    "# Che cosa hanno fatto le Forze Armate?\n",
    "# A quali gruppi appartiene la Corea del Nord?\n",
    "question = \"A quali gruppi appartiene la Corea del Nord?\"\n",
    "\n",
    "best_paragraphs_df  = top_paragraphs_identification(question)\n",
    "best_paragraph_nr   = best_paragraphs_df.index[0]\n",
    "best_paragraph_text = best_paragraphs_df[\"text\"][best_paragraph_nr]\n",
    "\n",
    "context_variables = sk.ContextVariables()\n",
    "context_variables[\"input\"]    = best_paragraph_text\n",
    "context_variables[\"question\"] = question\n",
    "context_variables[\"style\"]    = 'se non trovi la risposta nel testo, rispondi NON LO SO'\n",
    "\n",
    "mauromi_skills           = kernel_prompt.import_semantic_skill_from_directory(skills_directory, skills_set)\n",
    "find_and_search_function = mauromi_skills[\"find_and_search_function\"]\n",
    "translate_function       = mauromi_skills[\"translate_function\"]\n",
    "\n",
    "\n",
    "# ---------- CHAINED OUTPUT\n",
    "output = await kernel_prompt.run_async(find_and_search_function, translate_function, \n",
    "                                       input_vars=context_variables)\n",
    "print(output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "semantic_kernel",
   "language": "python",
   "name": "semantic_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
