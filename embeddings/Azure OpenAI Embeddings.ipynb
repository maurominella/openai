{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ec06ef9f",
   "metadata": {},
   "source": [
    "# Azure OpenAI Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05dd6139",
   "metadata": {},
   "source": [
    "## Set up environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c3470c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv # pip install python-dotenv\n",
    "from openai import AzureOpenAI # pip install openai\n",
    "\n",
    "load_dotenv(\"./../credentials_my.env\")\n",
    "os.environ[\"AZURE_OPENAI_ENDPOINT\"] =\"https://mmapim02.azure-api.net/aoai\" #  os.environ[\"AZURE_OPENAI_ENDPOINT_04\"]\n",
    "os.environ[\"AZURE_OPENAI_API_KEY\"] = \"dc89792b64404b98b1059b307a62d932\" # os.environ[\"AZURE_OPENAI_API_KEY_04\"]\n",
    "\n",
    "chat_model                     = \"gpt-4o-2024-05-13\" # os.environ[\"GPT-4-32-0613-32k\"]\n",
    "embeddings_model_2_model       = \"embedding_with_apim\" # os.environ[\"TEXT-EMBEDDING-ADA-002\"]\n",
    "embeddings_model_3_small_model = os.environ[\"TEXT-EMBEDDING-3-SMALL\"]\n",
    "embeddings_model_3_large_model = os.environ[\"TEXT-EMBEDDING-3-LARGE\"]\n",
    "\n",
    "client = AzureOpenAI(\n",
    "  api_version = os.getenv(\"AZURE_OPENAI_API_VERSION\")\n",
    "  # api_key = os.getenv(\"AZURE_OPENAI_API_KEY\"),\n",
    "  # azure_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8f98de03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n"
     ]
    }
   ],
   "source": [
    "messages=[\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"You are an AI assistant that helps people find information.\"\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"tell me five good names for my new pizzeria\"\n",
    "    }\n",
    "]\n",
    "\n",
    "for i in range(200):\n",
    "    print(i)\n",
    "    response = client.chat.completions.create(\n",
    "        model    = os.environ['GPT-4O-20240513-128K'],\n",
    "        messages = messages)\n",
    "\n",
    "    response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b51b9aa7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletion(id='chatcmpl-9caKHhfWhXM9d7Xh7z2teTq42xrQA', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='Sure, here are five creative and catchy names for your new pizzeria:\\n\\n1. **Bella Vita Pizzeria**\\n2. **Fired Up Pizza Co.**\\n3. **Twist & Crust Pizzeria**\\n4. **Urban Slice Pizzeria**\\n5. **Molto Bene Pizza House**\\n\\nI hope one of these names resonates with the vibe you want for your pizzeria!', role='assistant', function_call=None, tool_calls=None), content_filter_results={'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}})], created=1718983129, model='gpt-4o-2024-05-13', object='chat.completion', system_fingerprint='fp_abc28019ad', usage=CompletionUsage(completion_tokens=78, prompt_tokens=32, total_tokens=110), prompt_filter_results=[{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c87f67a6",
   "metadata": {},
   "source": [
    "## Test embeddings generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "caa1bc89",
   "metadata": {},
   "outputs": [
    {
     "ename": "NotFoundError",
     "evalue": "Error code: 404 - {'statusCode': 404, 'message': 'Resource not found'}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membeddings\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mRabbit\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43membeddings_model_2_model\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mdata[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39membedding[:\u001b[38;5;241m5\u001b[39m]\n",
      "File \u001b[0;32m/anaconda/envs/openai/lib/python3.11/site-packages/openai/resources/embeddings.py:114\u001b[0m, in \u001b[0;36mEmbeddings.create\u001b[0;34m(self, input, model, dimensions, encoding_format, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    108\u001b[0m         embedding\u001b[38;5;241m.\u001b[39membedding \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mfrombuffer(  \u001b[38;5;66;03m# type: ignore[no-untyped-call]\u001b[39;00m\n\u001b[1;32m    109\u001b[0m             base64\u001b[38;5;241m.\u001b[39mb64decode(data), dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfloat32\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    110\u001b[0m         )\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[1;32m    112\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\n\u001b[0;32m--> 114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    115\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/embeddings\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    116\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEmbeddingCreateParams\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    117\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[43m        \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    119\u001b[0m \u001b[43m        \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    120\u001b[0m \u001b[43m        \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    121\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    122\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpost_parser\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    123\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    124\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mCreateEmbeddingResponse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    125\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/anaconda/envs/openai/lib/python3.11/site-packages/openai/_base_client.py:1240\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1226\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(\n\u001b[1;32m   1227\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1228\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1235\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1236\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[1;32m   1237\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[1;32m   1238\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[1;32m   1239\u001b[0m     )\n\u001b[0;32m-> 1240\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m/anaconda/envs/openai/lib/python3.11/site-packages/openai/_base_client.py:921\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    912\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrequest\u001b[39m(\n\u001b[1;32m    913\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    914\u001b[0m     cast_to: Type[ResponseT],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    919\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    920\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[0;32m--> 921\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    922\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    923\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    924\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    925\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    926\u001b[0m \u001b[43m        \u001b[49m\u001b[43mremaining_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mremaining_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    927\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/anaconda/envs/openai/lib/python3.11/site-packages/openai/_base_client.py:1020\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1017\u001b[0m         err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mread()\n\u001b[1;32m   1019\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRe-raising status error\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1020\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_status_error_from_response(err\u001b[38;5;241m.\u001b[39mresponse) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1022\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_response(\n\u001b[1;32m   1023\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39mcast_to,\n\u001b[1;32m   1024\u001b[0m     options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1027\u001b[0m     stream_cls\u001b[38;5;241m=\u001b[39mstream_cls,\n\u001b[1;32m   1028\u001b[0m )\n",
      "\u001b[0;31mNotFoundError\u001b[0m: Error code: 404 - {'statusCode': 404, 'message': 'Resource not found'}"
     ]
    }
   ],
   "source": [
    "client.embeddings.create(input = [\"Rabbit\"], model=embeddings_model_2_model).data[0].embedding[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f7ffa21",
   "metadata": {},
   "source": [
    "## Create a helper function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53eed5ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_embeddings(text, model=\"text-embedding-ada-002\"): # model = \"deployment_name\"\n",
    "    return client.embeddings.create(input = [text], model=model).data[0].embedding\n",
    "\n",
    "generate_embeddings(\"Rabbit\")[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d2d7a43",
   "metadata": {},
   "source": [
    "# Test different embeddings models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b02839c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for m in (embeddings_model_2_model, embeddings_model_3_small_model, embeddings_model_3_large_model):\n",
    "    embeddings = generate_embeddings(text=\"anatine amigos\", model=m)\n",
    "    print(f\"Embeddings in ({m}): {len(embeddings)}. First elements: {[round(embeddings[i],3) for i in [0,1,2,-1]]}\")    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2b53b0d",
   "metadata": {},
   "source": [
    "# Choose our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b5a240b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = embeddings_model_3_small_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5e62ae5",
   "metadata": {},
   "source": [
    "# Calculate Word Embeddings\n",
    "To use word embeddings for semantic search, you first compute the embeddings for a corpus of text using a word embedding algorithm. What does this mean? We are going to create a numerical representation of each of these words. To perform this computation, we'll use OpenAI's 'get_embedding' function.\n",
    "\n",
    "Since we have our words in a pandas dataframe, we can use \"apply\" to apply the get_embedding function to each row in the dataframe. We then store the calculated word embeddings in a new text file called \"word_embeddings.csv\" so that we don't have to call OpenAI again to perform these calculations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c228fe49",
   "metadata": {},
   "source": [
    "# Learn how to generate embeddings with Azure OpenAI\n",
    "https://learn.microsoft.com/en-us/azure/cognitive-services/openai/how-to/embeddings?tabs=console"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe7f1128-69ab-4715-b4b6-cfdefcde13a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "embeddings = generate_embeddings(\"rabbit\")\n",
    "print(f\"embeddings shape: {np.array(embeddings).shape}. Now showing the first 5 elements:\\n{embeddings[:5]}\")"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "ff64f0d5",
   "metadata": {},
   "source": [
    "# Cosine similarity\n",
    "https://en.wikipedia.org/wiki/Cosine_similarity\n",
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef3de1f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "v1 = np.array([1,2,3])\n",
    "v2 = np.array([4,5,6])\n",
    "numerator = np.dot(v1,v2) # 4+10+18\n",
    "print(numerator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ec273d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "denominator_1 = np.linalg.norm(v1) # sqrt (1+4+9) = 3.74\n",
    "denominator_2 = np.linalg.norm(v2) # sqrt (16+25+36) = 8.77\n",
    "denominator   = denominator_1 * denominator_2\n",
    "print(denominator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2203cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(numerator / denominator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8873d66a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(v1,v2):\n",
    "    numerator = np.dot(v1,v2)\n",
    "    denumerator = np.linalg.norm(v1) * np.linalg.norm(v2)\n",
    "    return numerator / denumerator\n",
    "\n",
    "cs = cosine_similarity(np.array([1,2,3]),np.array([-4,5,6]))\n",
    "print(cs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97a66d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cs = cosine_similarity(np.array([1,2,3,-1,2,3,-1,2,3,-1,2,3]),np.array([-4,5,6,4,5,-6,4,5,-6,4,5,6]))\n",
    "print(cs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffacf883",
   "metadata": {},
   "source": [
    "## Create an embedding for a single word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5005e880",
   "metadata": {},
   "outputs": [],
   "source": [
    "#openai.Embedding.create(input=\"rabbit\", engine=azure_openai_deployment_emb)['data'][0]['embedding']\n",
    "generate_embeddings(\"rabbit\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9510dcff",
   "metadata": {},
   "source": [
    "## Check distance between two words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35d574dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "v1 = generate_embeddings(\"rabbit\")\n",
    "v2 = generate_embeddings(\"space shuttle\") # dog, elephant, car, space shuttle\n",
    "\n",
    "cs = cosine_similarity(v1,v2)\n",
    "print(cs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3026fd26",
   "metadata": {},
   "source": [
    "# Read Data File Containing Words\n",
    "Now that we have configured OpenAI, let's start with a simple CSV file with familiar words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee6980fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "file_name = 'words'\n",
    "df = pd.read_csv(f'{file_name}.csv')\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad01b38c",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:    \n",
    "    #df[\"text_embeddings\"] = df[\"text\"].apply(lambda x: openai.Embedding.create(input=x, engine=azure_openai_deployment_emb)['data'][0]['embedding'])\n",
    "    df[\"text_embeddings\"] = df[\"text\"].apply(lambda x: generate_embeddings(x))\n",
    "    df.to_pickle(f\"{file_name}_enriched.pkl\") # type(df['embeddings'][0][0]) --> float  \n",
    "except:\n",
    "    #print('switching to pickle file...')\n",
    "    df = pd.read_pickle(f\"{file_name}_enriched.pkl\")\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a10390bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_term = input ('Insert a search term:\\n') # \"hot dog\", \"torta\"...\n",
    "\n",
    "#search_term_vector = openai.Embedding.create(input=search_term, engine=azure_openai_deployment_emb)['data'][0]['embedding']\n",
    "search_term_vector = generate_embeddings(search_term)\n",
    "df[\"similarity\"] = df[\"text_embeddings\"].apply(lambda x: cosine_similarity(x,search_term_vector))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdbbe742",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values(\"similarity\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34b7362e",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_term = \"gateau\"\n",
    "#search_term_vector = openai.Embedding.create(input=search_term, engine=azure_openai_deployment_emb)['data'][0]['embedding']\n",
    "search_term_vector = generate_embeddings(search_term)\n",
    "\n",
    "df[\"similarity\"] = df[\"text_embeddings\"].apply(lambda x: cosine_similarity(x,search_term_vector))\n",
    "df = df.sort_values(\"similarity\", ascending=False)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9bf4161",
   "metadata": {},
   "source": [
    "# Campaign Speeches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48a4c4c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = 'discorso_presidente_del_consiglio'\n",
    "\n",
    "df = pd.read_csv(f'{file_name}.csv')\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c4afcb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    df[\"text_embeddings\"] = df[\"text\"].apply(lambda x: \n",
    "       # openai.Embedding.create(input=x, engine=azure_openai_deployment_emb)['data'][0]['embedding'])\n",
    "       generate_embeddings(x))\n",
    "    df.to_pickle(f\"{file_name}_enriched.pkl\") # type(df['embeddings'][0][0]) --> float\n",
    "    df.to_csv(f\"{file_name}_enriched.csv\") # type(df['embeddings'][0][0]) --> string\n",
    "\n",
    "except:\n",
    "    print(\"switching to pickle file...\")\n",
    "    df = pd.read_pickle(f\"{file_name}_enriched.pkl\")\n",
    "    \n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77d282be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# accoglienza profughi extracomunitari --> flussi migratori, traffico di essere umani, immigrazione\n",
    "# a quali gruppi appartiene l'Italia?\n",
    "search_term = input ('Insert a search term:\\n')\n",
    "\n",
    "#search_term_vector = openai.Embedding.create(input=search_term, engine=azure_openai_deployment_emb)['data'][0]['embedding']\n",
    "search_term_vector = model.embed_query(search_term)\n",
    "\n",
    "df[\"similarity\"] = df[\"text_embeddings\"].apply(lambda x: cosine_similarity(x,search_term_vector))\n",
    "df.sort_values(\"similarity\", ascending=False).head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0f8a9a6",
   "metadata": {},
   "source": [
    "## Generalize top paragraphs identification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81edfaf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_paragraphs_identification (search_term, top_terms=5):\n",
    "    # search_term_vector = openai.Embedding.create(input=search_term, engine=azure_openai_deployment_emb)['data'][0]['embedding']\n",
    "    search_term_vector = model.embed_query(search_term)\n",
    "    df[\"similarity\"] = df[\"text_embeddings\"].apply(lambda x: cosine_similarity(x,search_term_vector))\n",
    "    return df.sort_values(\"similarity\", ascending=False).head(top_terms)\n",
    "\n",
    "\n",
    "# possible questions:\n",
    "# \"A quali gruppi appartiene l'Italia?\"\n",
    "# \"Che cosa hanno fatto le Forze Armate?\"\n",
    "# \"Quali sono le donne italiane che hanno dimostrato valore?\"\n",
    "# \"Quali sono le grandi sfide dell'Unione Europea?\"\n",
    "# \"Quale strada vuole perseguire il governo?\"\n",
    "\n",
    "question = \"Quali sono le donne italiane che hanno dimostrato valore?\"\n",
    "best_paragraphs_df = top_paragraphs_identification(question)\n",
    "best_paragraph_nr = best_paragraphs_df.index[0]\n",
    "best_paragraph_text = best_paragraphs_df[\"text\"][best_paragraph_nr]\n",
    "print(f\"The best answer should be in paragraph #{best_paragraph_nr}:\\n{best_paragraph_text}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openai",
   "language": "python",
   "name": "openai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
