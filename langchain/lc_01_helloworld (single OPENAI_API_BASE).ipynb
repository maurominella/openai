{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "88cc2dfe-5194-46ad-bfb8-693d33a9dfa2",
   "metadata": {},
   "source": [
    "# Open AI - Hello World!\n",
    "## Conda Environment creation\n",
    "### Save the following lines into **conda_langchain.yml**:\n",
    "```\n",
    "name: langchain\n",
    "\n",
    "dependencies:\n",
    "  - python=3.10.12\n",
    "  - pip\n",
    "  - pip:\n",
    "    - langchain==0.0.334\n",
    "    - openai==1.2.3\n",
    "    - jupyter==1.0.0\n",
    "    - python-dotenv==1.0.0\n",
    "\n",
    "```\n",
    "\n",
    "### , then run:\n",
    "conda env create -f conda_langchain.yml<br/>\n",
    "conda activate langchain<br/>\n",
    "jupyter kernelspec uninstall langchain<br/>\n",
    "python -m ipykernel install --name langchain --user<br/>\n",
    "jupyter kernelspec list<br/>\n",
    "jupyter notebook<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "641a80ac-84b5-4ae0-ab95-aa7a7b80a498",
   "metadata": {},
   "source": [
    "## This example uses the [langchain.chat_models.azure_openai.AzureChatOpenAI](https://api.python.langchain.com/en/latest/chat_models/langchain.chat_models.azure_openai.AzureChatOpenAI.html) class.\n",
    "\n",
    "To use this class you must have a deployed model on Azure OpenAI. Use deployment_name in the constructor to refer to the “Model deployment name” in the Azure portal.<br/>\r\n",
    "\r\n",
    "In addition, you should have the openai python package installed, and the following environment variables set or passed in constructor in lower cas\n",
    "- AZURE_OPENAI_API_KEY - AZURE_OPENAI_API_ENDPOINT - AZURE_OPENAI_AD_TOKEN - OPENAI_API_VERSION - OPENAI_PRO/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b3e9fdb-22eb-41a6-bf19-91a2f5b84cbb",
   "metadata": {},
   "source": [
    "## Common Environment Variables\n",
    "\n",
    "### **OPENAI_API_BASE** (or **base_url**) and **azure_endpoint** are mutually exclusive\n",
    "\n",
    "## OPTION 1 (base_url):\n",
    "### AzureChatOpenAI object creation with OPENAI_API_BASE environment variable \n",
    "#### This variable cotains the service endpoint plus the deployment name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e8fbfd0-3318-42c8-9c5b-a87c58b3c1d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# Common environment variables\n",
    "os.environ[\"AZURE_OPENAI_API_KEY\"]  = \"bc844e3317c6446092d8cbf95234a811\"\n",
    "os.environ[\"OPENAI_API_VERSION\"]    = \"2023-05-15\"\n",
    "os.environ[\"AZURE_OPENAI_API_TYPE\"] = \"azure\"\n",
    "\n",
    "# This variable cotains the service endpoint plus the deployment name\n",
    "os.environ[\"OPENAI_API_BASE\"] = \"https://mmopenai04.openai.azure.com/openai/deployments/gpt-35-turbo\"\n",
    "\n",
    "# a smart alternative:\n",
    "# load_dotenv(\"./../credentials (my).env\")\n",
    "\n",
    "from langchain.chat_models import AzureChatOpenAI\n",
    "llm = AzureChatOpenAI(temperature=0, max_tokens=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df9e67e4-8913-44f8-ac6d-03573959c2b1",
   "metadata": {},
   "source": [
    "# Now we invoke the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f264eaee-ef37-442a-9d94-ddb6ca1bdf20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer the following question: \"What is CLP?\". Give your response in Italian\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'question': 'What is CLP?',\n",
       " 'language': 'Italian',\n",
       " 'text': \"CLP è l'acronimo di Classification, Labelling and Packaging, che in italiano significa Classificazione, Etichettatura e Imballaggio. Si tratta di un sistema armonizzato a livello europeo per la classificazione, etichettatura e imballaggio delle sostanze chimiche per garantire la sicurezza degli utenti e dell'ambiente.\"}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now we create a simple prompt template\n",
    "QUESTION = \"What is CLP?\" # What are the approaches to Task Decomposition?\n",
    "language = \"Italian\"\n",
    "\n",
    "from langchain.prompts import PromptTemplate\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"question\", \"language\"],\n",
    "    template='Answer the following question: \"{question}\". Give your response in {language}',\n",
    ")\n",
    "\n",
    "# Let's print the question using Langchain prompt\n",
    "print(prompt.format(question=QUESTION, language=language))\n",
    "\n",
    "# And finally we create our first generic chain\n",
    "from langchain.chains import LLMChain\n",
    "chain_chat = LLMChain(llm=llm, prompt=prompt)\n",
    "chain_chat({\"question\": QUESTION, \"language\": language})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "azuremlsdkv2mm",
   "language": "python",
   "name": "azuremlsdkv2mm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
