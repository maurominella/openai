{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4ac07f67",
   "metadata": {},
   "source": [
    "# This sample was inspired by [openai_function_calling.py](https://github.com/microsoft/semantic-kernel/blob/main/python/samples/kernel-syntax-examples/openai_function_calling.py)\n",
    "plus:\n",
    "- https://github.com/microsoft/semantic-kernel/blob/main/dotnet/samples/KernelSyntaxExamples/Example59_OpenAIFunctionCalling.cs\n",
    "- https://youtu.be/1e8GOdTPHC4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d0af18d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"elevation_to_power\",\n",
    "            \"description\": \"calculate the mathematical result of a number elevated to the power of another number\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"base\": {\"type\": \"string\", \"description\": \"the base number\"},\n",
    "                    \"power\": {\"type\": \"string\", \"description\": \"the power to elevate the base number to\"}\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\"base\", \"power\"]\n",
    "        }\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e5dd79f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplateConfig(schema_=1, type='completion', description='', execution_settings=AIRequestSettings(service_id=None, extension_data={'max_tokens': 2000, 'temperature': 0.7, 'top_p': 0.8, 'tool_choice': 'auto', 'tools': [{'type': 'function', 'function': {'name': 'elevation_to_power', 'description': 'calculate the mathematical result of a number elevated to the power of another number', 'parameters': {'type': 'object', 'properties': {'base': {'type': 'string', 'description': 'the base number'}, 'power': {'type': 'string', 'description': 'the power to elevate the base number to'}}}, 'required': ['base', 'power']}}]}), default_services=[], parameters=[])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prompt template config that contains the definition and description of each function\n",
    "\n",
    "import semantic_kernel as sk\n",
    "\n",
    "prompt_config = sk.PromptTemplateConfig.from_execution_settings(\n",
    "    max_tokens=2000,\n",
    "    temperature=0.7,\n",
    "    top_p=0.8,\n",
    "    tool_choice=\"auto\",\n",
    "    tools=tools,\n",
    ")\n",
    "prompt_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0d2e2cbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate[OpenAIChatMessage](template='{{$user_input}}', template_engine=PromptTemplateEngine(), prompt_config=PromptTemplateConfig(schema_=1, type='completion', description='', execution_settings=AIRequestSettings(service_id=None, extension_data={'max_tokens': 2000, 'temperature': 0.7, 'top_p': 0.8, 'tool_choice': 'auto', 'tools': [{'type': 'function', 'function': {'name': 'elevation_to_power', 'description': 'calculate the mathematical result of a number elevated to the power of another number', 'parameters': {'type': 'object', 'properties': {'base': {'type': 'string', 'description': 'the base number'}, 'power': {'type': 'string', 'description': 'the power to elevate the base number to'}}}, 'required': ['base', 'power']}}]}), default_services=[], parameters=[]), messages=[])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import semantic_kernel.connectors.ai.open_ai as sk_oai\n",
    "\n",
    "kernel = sk.Kernel()\n",
    "\n",
    "prompt_template = sk.ChatPromptTemplate[sk_oai.models.chat.open_ai_chat_message.OpenAIChatMessage](\n",
    "    \"{{$user_input}}\", kernel.prompt_template_engine, prompt_config\n",
    ")\n",
    "prompt_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fedb5e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template.add_system_message(\"\"\"\n",
    "You are a chat bot. Your name is Mosscap and\n",
    "you have one goal: figure out what people need.\n",
    "Your full name, should you need to know it, is\n",
    "Splendid Speckled Mosscap. You communicate\n",
    "effectively, but you tend to answer with long\n",
    "flowery prose. You are also a math wizard, \n",
    "especially for adding and subtracting.\n",
    "You also excel at joke telling, where your tone is often sarcastic.\n",
    "Once you have the answer I am looking for, \n",
    "you will return a full answer to me as soon as possible.\n",
    "\"\"\")\n",
    "\n",
    "prompt_template.add_user_message(\"Hi there, who are you?\")\n",
    "\n",
    "prompt_template.add_assistant_message(\"I am Mosscap, a chat bot. I'm trying to figure out what people need.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9db1e9f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate[OpenAIChatMessage](template='{{$user_input}}', template_engine=PromptTemplateEngine(), prompt_config=PromptTemplateConfig(schema_=1, type='completion', description='', execution_settings=AIRequestSettings(service_id=None, extension_data={'max_tokens': 2000, 'temperature': 0.7, 'top_p': 0.8, 'tool_choice': 'auto', 'tools': [{'type': 'function', 'function': {'name': 'elevation_to_power', 'description': 'calculate the mathematical result of a number elevated to the power of another number', 'parameters': {'type': 'object', 'properties': {'base': {'type': 'string', 'description': 'the base number'}, 'power': {'type': 'string', 'description': 'the power to elevate the base number to'}}}, 'required': ['base', 'power']}}]}), default_services=[], parameters=[]), messages=[OpenAIChatMessage(role='system', fixed_content=None, name=None, function_call=None), OpenAIChatMessage(role='user', fixed_content=None, name=None, function_call=None), OpenAIChatMessage(role='assistant', fixed_content=None, name=None, function_call=None)])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a7a715f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "function_config = sk.SemanticFunctionConfig(prompt_config, prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ff1fb70c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is my AzureChatCompletion connector:\n",
      "ai_model_id='gpt35turbo-0613-4k' client=<openai.lib.azure.AsyncAzureOpenAI object at 0x7f2bac86db50> ai_model_type=<OpenAIModelTypes.CHAT: 'chat'> prompt_tokens=0 completion_tokens=0 total_tokens=0\n"
     ]
    }
   ],
   "source": [
    "# We haven't used OpenAI yet\n",
    "# So we create the SK \"chat completion connector\" to the Azure OpenAI service\n",
    "import semantic_kernel as sk\n",
    "\n",
    "# kernel = sk.Kernel()\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(\"credentials_my.env\")\n",
    "\n",
    "import semantic_kernel.connectors.ai.open_ai as sk_oai\n",
    "\n",
    "chat_connector = sk_oai.AzureChatCompletion(\n",
    "    api_key=os.environ['AZURE_OPENAI_API_KEY'],\n",
    "    api_version=os.environ['AZURE_OPENAI_API_VERSION'],\n",
    "    deployment_name=os.environ['GPT35TURBO-0613-4k'], # ['GPT4-1106-128k'],\n",
    "    endpoint=os.environ['AZURE_OPENAI_ENDPOINT']\n",
    ")\n",
    "print(f\"This is my AzureChatCompletion connector:\\n{chat_connector}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "57bbde73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are all chat services registered with this kernel: ['mauromi_chatgpt']\n"
     ]
    }
   ],
   "source": [
    "# add the openAI completion connector to the kernel, choosing a name to identify it within the kernel\n",
    "# after this instruction, the kernel has got it service_id that you can get with kernel.all_chat_services()\n",
    "\n",
    "kernel.add_chat_service(\n",
    "    \"mauromi_chatgpt\", # unique name to be registered with the kernel\n",
    "    chat_connector\n",
    ")\n",
    "print(f\"Here are all chat services registered with this kernel: {kernel.all_chat_services()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "15a20eed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are my plugins imported into the kernel:\n",
      "data={'chatbot': {'chat': KernelFunction()}}\n"
     ]
    }
   ],
   "source": [
    "chat_function = kernel.register_semantic_function(\"ChatBot\", \"Chat\", function_config)\n",
    "print(f\"Here are my plugins imported into the kernel:\\n{kernel.plugins}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e1d6b25b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Add': KernelFunction(), 'Subtract': KernelFunction()}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from semantic_kernel.core_plugins import MathPlugin\n",
    "kernel.import_plugin(MathPlugin(), plugin_name=\"math\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8f1c673d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Context Variable (before):\n",
      "<<<>>>\n",
      "Result:\n",
      "\n",
      "\n",
      "Input Context Variable (after):\n",
      "<<<>>>\n"
     ]
    }
   ],
   "source": [
    "context = kernel.create_new_context()\n",
    "context.variables[\"user_input\"] = \"Calculate 72^0.43\"\n",
    "print(f\"Input Context Variable (before):\\n<<<{context.variables.input}>>>\")\n",
    "#response = chat_function.invoke(context=context)\n",
    "response = await chat_function.invoke_async(context=context)\n",
    "print(f\"Result:\\n{response}\")\n",
    "print(f\"\\nInput Context Variable (after):\\n<<<{context.variables.input}>>>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3f838427",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'function_call': FunctionCall(name='elevation_to_power', arguments='{\\n  \"base\": \"72\",\\n  \"power\": \"0.43\"\\n}', id='call_K19JMdrc9IW1kYLYciCtCZQj')}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0d9ff504",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function to be called: elevation_to_power\n",
      "Function id: call_K19JMdrc9IW1kYLYciCtCZQj\n",
      "Function parameters: {'base': '72', 'power': '0.43'}\n"
     ]
    }
   ],
   "source": [
    "for m in response.objects:\n",
    "    if m==\"function_call\":\n",
    "        fc = response.objects[m]\n",
    "        print(f\"Function to be called: {fc.name}\")\n",
    "        print(f\"Function id: {fc.id}\")\n",
    "        print(f\"Function parameters: {fc.parse_arguments()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5cb9c2e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'memory': FieldInfo(annotation=TypeVar, required=True),\n",
       " 'variables': FieldInfo(annotation=ContextVariables, required=True),\n",
       " 'plugin_collection': FieldInfo(annotation=ReadOnlyPluginCollection, required=False, default_factory=ReadOnlyPluginCollection)}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.model_fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d0ba84d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sk.connectors.ai.open_ai.utils.get_function_calling_object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "376be47e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ff48d9a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cb8c4e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e0c76ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d33f6fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create \"Native\" (aka \"Core\") Plugins that contain \"Native\" Functions\n",
    "\n",
    "from semantic_kernel import KernelContext\n",
    "from semantic_kernel.plugin_definition import kernel_function, kernel_function_context_parameter\n",
    "\n",
    "\n",
    "\n",
    "# --------------- CatClass\n",
    "\n",
    "class CatClass:\n",
    "    \"\"\"\n",
    "    Description: Given a cat name, returns some information.\n",
    "    \"\"\"    \n",
    "    @kernel_function(\n",
    "        description=\"Given a cat name, returns its age.\",\n",
    "        name=\"CatAge\",\n",
    "    )\n",
    "    @kernel_function_context_parameter(name=\"cat_name\", description=\"The cat name\", default_value=\"AA\")\n",
    "    def cat_age(self, cat_name: str = \"AA\") -> str:\n",
    "        \"\"\"\n",
    "        Given a cat name, returns its age.\n",
    "        \"\"\"\n",
    "        # print(f\"cat_name: {cat_name}\")\n",
    "        try:\n",
    "            \n",
    "            return str(len(cat_name))\n",
    "        except ValueError as e:\n",
    "            print(f\"Invalid input {cat_name}\")\n",
    "            raise e\n",
    "            \n",
    "    @kernel_function(\n",
    "        description=\"Given a cat name, returns its birthday.\",\n",
    "        name=\"CatBirthday\",\n",
    "    )\n",
    "    @kernel_function_context_parameter(name=\"cat_name\", description=\"The cat name\", default_value=\"AA\")\n",
    "    def cat_birthday(self, cat_name: str = \"AA\") -> str:\n",
    "        \"\"\"\n",
    "        Given a cat name, returns its birthday.\n",
    "        \"\"\"\n",
    "        # print(f\"cat_name: {cat_name}\")\n",
    "        from datetime import datetime\n",
    "        from dateutil.relativedelta import relativedelta\n",
    "        \n",
    "        today_str  = datetime.today().strftime(\"%Y-%m-%d\")\n",
    "        today_date = datetime.strptime(today_str,\"%Y-%m-%d\")\n",
    "\n",
    "        try:\n",
    "            cat_birthday_str = today_date.strftime(f\"{2000+len(cat_name)}-%m-%d\")\n",
    "            cat_birthday_date = datetime.strptime(cat_birthday_str,\"%Y-%m-%d\") # error raised when 29/2 in non-leap years\n",
    "        except ValueError as e:\n",
    "            cat_birthday_str = (today_date + relativedelta(days=1)).strftime(f\"{2000+len(cat_name)}-%m-%d\") # take March 1st\n",
    "\n",
    "        return cat_birthday_str\n",
    "\n",
    "    \n",
    "# --------------- RandomNumberClass\n",
    "\n",
    "    \n",
    "class RandomNumberClass:\n",
    "    \"\"\"\n",
    "    Description: Generate some random numbers.\n",
    "    \"\"\"\n",
    "\n",
    "    @kernel_function(\n",
    "        description=\"Generate a random number between 3 and x\",\n",
    "        name=\"GenerateNumberThreeOrHigher\",\n",
    "    )\n",
    "    def generate_number_three_or_higher(self, input: str) -> str:\n",
    "        \"\"\"\n",
    "        Generate a number between 3 and <input>\n",
    "        Example:\n",
    "            \"8\" => rand(3,8)\n",
    "        Args:\n",
    "            input -- The upper limit for the random number generation\n",
    "        Returns:\n",
    "            int value\n",
    "        \"\"\"\n",
    "        import random\n",
    "\n",
    "        try:\n",
    "            return str(random.randint(3, int(input)))\n",
    "        except ValueError as e:\n",
    "            print(f\"Invalid input {input}\")\n",
    "            raise e\n",
    "\n",
    "    @kernel_function(\n",
    "        description=\"Generate a random number between x and three\",\n",
    "        name=\"GenerateNumberThreeOrLower\",\n",
    "    )\n",
    "    def generate_number_three_or_lower(self, input: str) -> str:\n",
    "        \"\"\"\n",
    "        Generate a number between <input> and 3\n",
    "        Example:\n",
    "            \"-4\" => rand(-4,3)\n",
    "        Args:\n",
    "            input -- The lower limit for the random number generation\n",
    "        Returns:\n",
    "            int value\n",
    "        \"\"\"\n",
    "        import random\n",
    "        \n",
    "        try:\n",
    "            return str(random.randint(int(input),3))\n",
    "        except ValueError as e:\n",
    "            print(f\"Invalid input {input}\")\n",
    "            raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7c44198",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test the classes (NOT the plugin!)\n",
    "\n",
    "my_cat_object = CatClass()  # Create an instance\n",
    "my_cat_age = my_cat_object.cat_age() # Call the method\n",
    "print(f\"my_cat_age: {my_cat_age}\") # Assert the result\n",
    "\n",
    "print (my_cat_object.cat_age(\"Molly\"))\n",
    "print (my_cat_object.cat_birthday(\"Molly\"))\n",
    "\n",
    "print(RandomNumberClass().generate_number_three_or_lower(-30))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16f2176c",
   "metadata": {},
   "source": [
    "# Create the Semantic Kernel to load classes as plugins into it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "016d9c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import semantic_kernel as sk\n",
    "kernel = sk.Kernel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f7afeb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import plugins into the kernel, together with all their (native) functions\n",
    "kernel.import_plugin(plugin_instance=CatClass(), plugin_name=\"CatPlugin\")\n",
    "kernel.import_plugin(plugin_instance=RandomNumberClass(), plugin_name=\"RandomNumberPlugin\")\n",
    "print(f\"Here are my plugins imported into the kernel:\\n{kernel.plugins}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcb090e7",
   "metadata": {},
   "source": [
    "# Call Native Functions using plugins imported into the Kernel\n",
    "## Note that we don't need any connection to Open AI to do this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "230dbf37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test plugin functions after extracting them from the kernel\n",
    "\n",
    "print(kernel.plugins.get_function(plugin_name=\"RandomNumberPlugin\", function_name=\"GenerateNumberThreeOrHigher\")(\"20\"))\n",
    "print(kernel.plugins.get_function(plugin_name=\"RandomNumberPlugin\", function_name=\"GenerateNumberThreeOrLower\")(\"-20\"))\n",
    "print(kernel.plugins.get_function(plugin_name=\"CatPlugin\", function_name=\"CatBirthday\")(\"Tom\"))\n",
    "print(kernel.plugins.get_function(plugin_name=\"CatPlugin\", function_name=\"CatBirthday\")(\"Cleopatra\"))\n",
    "print(kernel.plugins.get_function(plugin_name=\"CatPlugin\", function_name=\"CatAge\")(\"Cleopatra\"))\n",
    "print(kernel.plugins.get_function(plugin_name=\"CatPlugin\", function_name=\"CatAge\")(\"Molly\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "834c5213",
   "metadata": {},
   "outputs": [],
   "source": [
    "# another way to test Cats_Birthday function after extracting it from the kenel\n",
    "\n",
    "cb_function = kernel.plugins.get_function(plugin_name=\"CatPlugin\", function_name=\"CatBirthday\")\n",
    "answer = cb_function.invoke(\"Molly\")\n",
    "print (answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5182018",
   "metadata": {},
   "source": [
    "## Add Open AI Chat Completion \"Connector\" to allow Kernel call Semantic Functions.\n",
    "### Otherwise we get the error `<TextCompletionClientBase service with service_id 'None' not found>`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b032960",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We haven't used OpenAI yet\n",
    "# So we create the SK \"chat completion connector\" to the Azure OpenAI service\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(\"credentials_my.env\")\n",
    "\n",
    "import semantic_kernel.connectors.ai.open_ai as sk_oai\n",
    "\n",
    "chat_connector = sk_oai.AzureChatCompletion(\n",
    "    api_key=os.environ['AZURE_OPENAI_API_KEY'],\n",
    "    api_version=os.environ['AZURE_OPENAI_API_VERSION'],\n",
    "    deployment_name=os.environ['GPT35TURBO-0613-4k'], # ['GPT4-1106-128k'],\n",
    "    endpoint=os.environ['AZURE_OPENAI_ENDPOINT']\n",
    ")\n",
    "print(f\"This is my AzureChatCompletion connector:\\n{chat_connector}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40b6ec23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the openAI completion connector to the kernel, choosing a name to identify it within the kernel\n",
    "# after this instruction, the kernel has got it service_id that you can get with kernel.all_chat_services()\n",
    "\n",
    "kernel.add_chat_service(\n",
    "    \"mauromi_chatgpt\", # unique name to be registered with the kernel\n",
    "    chat_connector\n",
    ")\n",
    "print(f\"Here are all chat services registered with this kernel: {kernel.all_chat_services()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d86d0718",
   "metadata": {},
   "source": [
    "# Create and Call Stand-Alone Semantic Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79e97836",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now that we have the chat service registered with the kernel, we can create and run a semantic function IN-LINE\n",
    "# The semantic function is added to the list of kernel semantic functions\n",
    "# We may also add an existing SEMANTIC plugin with kernel.import_semantic_plugin_from_directory(plugins_directory, \"FunPlugin\")\n",
    "# We may also add an existing NATIVE plugin with import_native_plugin_from_directory(plugins_directory, \"FunPlugin\")\n",
    "# https://github.com/microsoft/semantic-kernel/blob/main/python/samples/kernel-syntax-examples/openai_function_calling.py\n",
    "\n",
    "sk_prompt = \"Give exactly 3 answers to the following question: {{$input}}\"\n",
    "\n",
    "# The following instruction adds a semantic function to the kernel. It requires that the kernel contains the chat or \n",
    "# text completion service, otherwise we get the error <TextCompletionClientBase service with service_id 'None' not found>\n",
    "my_semantic_function = kernel.create_semantic_function(\n",
    "    prompt_template=sk_prompt,\n",
    "    plugin_name=\"GenericSemanticPlugin\",\n",
    "    function_name=\"GenericSemanticFunction\",\n",
    "    description=\"Generic Semantic Function in a Generic Semantic Plugin\",\n",
    "    max_tokens=500,\n",
    "    temperature=0.5,\n",
    "    top_p=0.5,\n",
    ")\n",
    "\n",
    "print(f\"Here are my plugins imported into the kernel:\\n{kernel.plugins}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b168c683",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the semantic function directly, without extracting it from the kernel\n",
    "# Note: the value of the \"input\" variable is replaced with the answer that we get from the semantic function\n",
    "\n",
    "context = kernel.create_new_context()\n",
    "context.variables[\"input\"] = \"Give me a wild animal\"\n",
    "print(f\"Input Context Variable (before):\\n<<<{context.variables.input}>>>\")\n",
    "print(f\"Result:\\n{my_semantic_function.invoke(context=context)}\")\n",
    "print(f\"\\nInput Context Variable (after):\\n<<<{context.variables.input}>>>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5634e2d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same result as previous cell, but in this case we extract the semantic function from the kernel and THEN we invoke it\n",
    "\n",
    "sf = kernel.plugins.get_function(plugin_name=\"GenericSemanticPlugin\", function_name=\"GenericSemanticFunction\")\n",
    "\n",
    "context = kernel.create_new_context()\n",
    "context.variables[\"input\"] = \"Who is Joe Biden's Wife?\"\n",
    "\n",
    "print(f\"Input Context Variable (before):\\n<<<{context.variables.input}>>>\")\n",
    "print(f\"Result:\\n{my_semantic_function.invoke(context=context)}\")\n",
    "print(f\"\\nInput Context Variable (after):\\n<<<{context.variables.input}>>>\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a712bbd",
   "metadata": {},
   "source": [
    "## Recap: which plugins and functions do we have of which type (native / semantic)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d19c82b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "all_functions = kernel.plugins.get_functions_view()\n",
    "json_object = json.loads(all_functions.json())\n",
    "json_formatted_str = json.dumps(json_object, indent=2)\n",
    "\n",
    "print(json_formatted_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b57584da",
   "metadata": {},
   "source": [
    "# Calling Native Functions from within a Semantic Function\n",
    "One neat thing about the Semantic Kernel is that you can also call native functions from within Semantic Functions!\n",
    "\n",
    "We will make our CorgiStory semantic function call a native function GenerateNames which will return names for our Corgi characters.\n",
    "\n",
    "We do this using the syntax `{{plugin_name.function_name}}` or `{{plugin_name.function_name $param_name}}` or `{{plugin_name.function_name \"param_value\"}}`.You can read more about our prompte templating syntax [here](https://learn.microsoft.com/en-us/semantic-kernel/prompts/prompt-template-syntax)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6936886e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now that we have the chat service registered with the kernel, we can create and run a semantic function IN-LINE\n",
    "# The semantic function is added to the list of kernel semantic functions\n",
    "# We may also add an existing SEMANTIC plugin with kernel.import_semantic_plugin_from_directory(plugins_directory, \"FunPlugin\")\n",
    "# We may also add an existing NATIVE plugin with import_native_plugin_from_directory(plugins_directory, \"FunPlugin\")\n",
    "# https://github.com/microsoft/semantic-kernel/blob/main/python/samples/kernel-syntax-examples/openai_function_calling.py\n",
    "\n",
    "# sk_prompt = 'Give exactly {\"function\": \"CatPlugin.CatAge\", \"args\": {\"cat_name\": \"Molly\"}} answers to the following question: {{$input}}'\n",
    "sk_prompt_nested = 'Give exactly {{CatPlugin.CatAge $cat_name}} answers to the following question: {{$input}}'\n",
    "\n",
    "# The following instruction adds a semantic function to the kernel. It requires that the kernel contains the chat or \n",
    "# text completion service, otherwise we get the error <TextCompletionClientBase service with service_id 'None' not found>\n",
    "my_semantic_function_nested = kernel.create_semantic_function(\n",
    "    prompt_template=sk_prompt_nested,\n",
    "    plugin_name=\"GenericSemanticPluginNested\",\n",
    "    function_name=\"GenericSemanticFunctionNested\",\n",
    "    description=\"Generic Semantic FunctionNested in a Generic Semantic Plugin\",\n",
    "    max_tokens=500,\n",
    "    temperature=0.5,\n",
    "    top_p=0.5,\n",
    ")\n",
    "\n",
    "print(f\"Here are my plugins imported into the kernel:\\n{kernel.plugins}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f8387f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sf_nested = kernel.plugins.get_function(\n",
    "    plugin_name=\"GenericSemanticPluginNested\", \n",
    "    function_name=\"GenericSemanticFunctionNested\"\n",
    ")\n",
    "\n",
    "context = kernel.create_new_context()\n",
    "context.variables[\"input\"] = \"Tell me a kind or mammal\"\n",
    "context.variables[\"cat_name\"] = \"Molly\"\n",
    "\n",
    "print(f\"Input Context Variable (before):\\n<<<{context.variables.input}>>>\")\n",
    "print(f\"Result:\\n{sf_nested.invoke(context=context)}\")\n",
    "print(f\"\\nInput Context Variable (after):\\n<<<{context.variables.input}>>>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f73c7d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "all_functions = kernel.plugins.get_functions_view()\n",
    "json_object = json.loads(all_functions.json())\n",
    "json_formatted_str = json.dumps(json_object, indent=2)\n",
    "\n",
    "print(json_formatted_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a8abaf6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10b6b6c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7211f0d4",
   "metadata": {},
   "source": [
    "# https://youtu.be/1e8GOdTPHC4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "024d77c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f8f34f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "843ddd1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"get_flights\",            \n",
    "            \"description\": \"returns the number of flights between two dates\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"date_1\": {\"type\": \"string\", \"description\": \"the first date\"},\n",
    "                    \"date_2\": {\"type\": \"string\", \"description\": \"the second date\"}\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\"date_1\", \"date_2\"]\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"get_days_difference\",            \n",
    "            \"description\": \"useful when you need to calculate the absolute number of days between two dates\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"date_1\": {\"type\": \"string\", \"description\": \"the first date\"},\n",
    "                    \"date_2\": {\"type\": \"string\", \"description\": \"the second date\"}\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\"date_1\", \"date_2\"]\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"elevation_to_power\",\n",
    "            \"description\": \"calculate the mathematical result of a number elevated to the power of another number\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"base\": {\"type\": \"string\", \"description\": \"the base number\"},\n",
    "                    \"power\": {\"type\": \"string\", \"description\": \"the power to elevate the base number to\"}\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\"base\", \"power\"]\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"web_search\",            \n",
    "            \"description\": \"useful for when you need to answer questions about current events\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"question\": {\"type\": \"string\", \"description\": \"the text string to search on the WEB\"}\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\"question\"]\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"current_year\",            \n",
    "            \"description\": \"returns the current year\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {                    \n",
    "                }\n",
    "            },\n",
    "            \"required\": []\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"current_date\",            \n",
    "            \"description\": \"returns the current date\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \n",
    "                }\n",
    "            },\n",
    "            \"required\": []\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"my_cat_born_date\",            \n",
    "            \"description\": \"returns my cat's born date\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \n",
    "                }\n",
    "            },\n",
    "            \"required\": []\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"custom_calculator\",            \n",
    "            \"description\": \"useful for when you need to answer questions about math\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"mathematical_question\": {\"type\": \"string\", \"description\": \"the text string to search on the WEB\"}\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\"mathematical_question\"]\n",
    "        }\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a883982",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt template config that contains the definition and description of each function\n",
    "\n",
    "prompt_config = sk.PromptTemplateConfig.from_execution_settings(\n",
    "    max_tokens=2000,\n",
    "    temperature=0.7,\n",
    "    top_p=0.8,\n",
    "    tool_choice=\"auto\",\n",
    "    tools=tools,\n",
    ")\n",
    "prompt_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3051f8ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's check that we have the chat completion service\n",
    "\n",
    "kernel.get_chat_service_service_id()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "887e1f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = sk.ChatPromptTemplate[sk_oai.models.chat.open_ai_chat_message.OpenAIChatMessage](\n",
    "    \"{{$user_input}}\", kernel.prompt_template_engine, prompt_config\n",
    ")\n",
    "prompt_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9de5f0f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template.add_user_message(\"Hi there, who are you?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b54847d",
   "metadata": {},
   "outputs": [],
   "source": [
    "function_config = sk.SemanticFunctionConfig(prompt_config, prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46fe017e",
   "metadata": {},
   "outputs": [],
   "source": [
    "function_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f608a8d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Test:\n",
    "    @kernel_function(\n",
    "        description=\"Get light status\",\n",
    "        name=\"getlightstatus\",\n",
    "    )\n",
    "    def getlightstatus(self) -> str:\n",
    "        return \"off\"\n",
    "    \n",
    "chat_function = kernel.register_native_function(plugin_name=\"Testzzzz\", kernel_function=\"getLightStatus\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "843c3525",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "all_functions = kernel.plugins.get_functions_view()\n",
    "json_object = json.loads(all_functions.json())\n",
    "json_formatted_str = json.dumps(json_object, indent=2)\n",
    "\n",
    "print(json_formatted_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12f4e639",
   "metadata": {},
   "outputs": [],
   "source": [
    "context = kernel.create_new_context()\n",
    "context.variables[\"user_input\"] = \"How many flights are there between Christmas 2020 and Easter 2021?\"\n",
    "\n",
    "    \n",
    "response = chat_function.invoke_async(context=context, functions=tools)\n",
    "response = chat_function.invoke()\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4eef62b",
   "metadata": {},
   "outputs": [],
   "source": [
    "context.objects"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "semantic_kernel",
   "language": "python",
   "name": "semantic_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
