{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa1fe9f7-7753-481e-8b78-01d8d817650e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools, operator, requests, os, json\n",
    "from bs4 import BeautifulSoup\n",
    "from duckduckgo_search import DDGS\n",
    "from langchain.agents import AgentExecutor, create_openai_tools_agent\n",
    "from langchain_core.messages import BaseMessage, HumanMessage\n",
    "from langchain.output_parsers.openai_functions import JsonOutputFunctionsParser\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langchain.tools import tool\n",
    "from langchain_openai import ChatOpenAI, AzureChatOpenAI\n",
    "from typing import Annotated, Any, Dict, List, Optional, Sequence, TypedDict\n",
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "899372e7-e08c-4d6a-a9b1-009bc09e2712",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set environment variables\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(\"./../credentials_my.env\")\n",
    "\n",
    "os.environ[\"AZURE_OPENAI_ENDPOINT\"] = os.environ[\"AZURE_OPENAI_ENDPOINT_SCUS\"]\n",
    "os.environ[\"AZURE_OPENAI_API_KEY\"]  = os.environ[\"AZURE_OPENAI_API_KEY_SCUS\"]\n",
    "os.environ[\"OPENAI_API_VERSION\"]    = os.environ[\"AZURE_OPENAI_API_VERSION\"]\n",
    "os.environ[\"AZURE_OPENAI_API_TYPE\"] = os.environ[\"OPENAI_API_TYPE\"]\n",
    "\n",
    "MODEL = os.environ[\"GPT4-0125PREVIEW-128k\"]\n",
    "\n",
    "# https://smith.langchain.com/\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"]  = \"true\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"]     = \"LangGraph Research Agents\"\n",
    "os.environ[\"LANGCHAIN_API_KEY\"]     = os.environ[\"LANGCHAIN_API_KEY\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1c3f2253-8def-4378-bee7-81ec277b643a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model\n",
    "\n",
    "llm = AzureChatOpenAI(deployment_name=MODEL, temperature=0, max_tokens=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "62a6878d-394b-4017-9bb2-70bbc8b46bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Define custom tools\n",
    "@tool(\"internet_search_tool\", return_direct=False) # this is the name tracked in LangSmith\n",
    "def internet_search_function(query: str) -> str:\n",
    "    \"\"\"Searches the internet using DuckDuckGo.\"\"\"\n",
    "    with DDGS() as ddgs:\n",
    "        results = [r for r in ddgs.text(query, max_results=5)]\n",
    "        return results if results else \"No results found.\"\n",
    "\n",
    "@tool(\"process_content\", return_direct=False)\n",
    "def process_content_function(url: str) -> str:\n",
    "    \"\"\"Processes content from a webpage.\"\"\"\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    return soup.get_text()\n",
    "\n",
    "tools = [internet_search_function, process_content_function]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc207d64",
   "metadata": {},
   "source": [
    "# AGENTS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e4e168b",
   "metadata": {},
   "source": [
    "## Create an Agent step by step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "31720e1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('system', 'You are a web searcher. Search the internet for information.')\n",
      "variable_name='messages'\n",
      "variable_name='agent_scratchpad'\n"
     ]
    }
   ],
   "source": [
    "system_prompt = (\n",
    "    \"system\",\n",
    "    \"You are a web searcher. Search the internet for information.\")\n",
    "\n",
    "mp1 = MessagesPlaceholder(variable_name=\"messages\")\n",
    "\n",
    "mp2 = MessagesPlaceholder(variable_name=\"agent_scratchpad\")\n",
    "\n",
    "print(system_prompt, mp1, mp2, sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c0eb65c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['agent_scratchpad', 'messages'], input_types={'messages': typing.List[typing.Union[langchain_core.messages.ai.AIMessage, langchain_core.messages.human.HumanMessage, langchain_core.messages.chat.ChatMessage, langchain_core.messages.system.SystemMessage, langchain_core.messages.function.FunctionMessage, langchain_core.messages.tool.ToolMessage]], 'agent_scratchpad': typing.List[typing.Union[langchain_core.messages.ai.AIMessage, langchain_core.messages.human.HumanMessage, langchain_core.messages.chat.ChatMessage, langchain_core.messages.system.SystemMessage, langchain_core.messages.function.FunctionMessage, langchain_core.messages.tool.ToolMessage]]}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='You are a web searcher. Search the internet for information.')), MessagesPlaceholder(variable_name='messages'), MessagesPlaceholder(variable_name='agent_scratchpad')])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cpt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", system_prompt),\n",
    "        mp1,\n",
    "        mp2\n",
    "    ])\n",
    "\n",
    "cpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "787b6468",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunnableAssign(mapper={\n",
       "  agent_scratchpad: RunnableLambda(lambda x: format_to_openai_tool_messages(x['intermediate_steps']))\n",
       "})\n",
       "| ChatPromptTemplate(input_variables=['agent_scratchpad', 'messages'], input_types={'messages': typing.List[typing.Union[langchain_core.messages.ai.AIMessage, langchain_core.messages.human.HumanMessage, langchain_core.messages.chat.ChatMessage, langchain_core.messages.system.SystemMessage, langchain_core.messages.function.FunctionMessage, langchain_core.messages.tool.ToolMessage]], 'agent_scratchpad': typing.List[typing.Union[langchain_core.messages.ai.AIMessage, langchain_core.messages.human.HumanMessage, langchain_core.messages.chat.ChatMessage, langchain_core.messages.system.SystemMessage, langchain_core.messages.function.FunctionMessage, langchain_core.messages.tool.ToolMessage]]}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='You are a web searcher. Search the internet for information.')), MessagesPlaceholder(variable_name='messages'), MessagesPlaceholder(variable_name='agent_scratchpad')])\n",
       "| RunnableBinding(bound=AzureChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x7f9fc5a9aa90>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x7f9fc5b10650>, temperature=0.0, openai_api_key=SecretStr('**********'), openai_proxy='', max_tokens=1000, azure_endpoint='https://mmopenaiscus.openai.azure.com/', deployment_name='gpt4-0125preview-128k', openai_api_version='2024-02-15-preview', openai_api_type='azure'), kwargs={'tools': [{'type': 'function', 'function': {'name': 'internet_search_tool', 'description': 'internet_search_tool(query: str) -> str - Searches the internet using DuckDuckGo.', 'parameters': {'type': 'object', 'properties': {'query': {'type': 'string'}}, 'required': ['query']}}}, {'type': 'function', 'function': {'name': 'process_content', 'description': 'process_content(url: str) -> str - Processes content from a webpage.', 'parameters': {'type': 'object', 'properties': {'url': {'type': 'string'}}, 'required': ['url']}}}]})\n",
       "| OpenAIToolsAgentOutputParser()"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent = create_openai_tools_agent(llm, tools, cpt)\n",
    "agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "04580297",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AgentExecutor(agent=RunnableMultiActionAgent(runnable=RunnableAssign(mapper={\n",
       "  agent_scratchpad: RunnableLambda(lambda x: format_to_openai_tool_messages(x['intermediate_steps']))\n",
       "})\n",
       "| ChatPromptTemplate(input_variables=['agent_scratchpad', 'messages'], input_types={'messages': typing.List[typing.Union[langchain_core.messages.ai.AIMessage, langchain_core.messages.human.HumanMessage, langchain_core.messages.chat.ChatMessage, langchain_core.messages.system.SystemMessage, langchain_core.messages.function.FunctionMessage, langchain_core.messages.tool.ToolMessage]], 'agent_scratchpad': typing.List[typing.Union[langchain_core.messages.ai.AIMessage, langchain_core.messages.human.HumanMessage, langchain_core.messages.chat.ChatMessage, langchain_core.messages.system.SystemMessage, langchain_core.messages.function.FunctionMessage, langchain_core.messages.tool.ToolMessage]]}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='You are a web searcher. Search the internet for information.')), MessagesPlaceholder(variable_name='messages'), MessagesPlaceholder(variable_name='agent_scratchpad')])\n",
       "| RunnableBinding(bound=AzureChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x7f9fc5a9aa90>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x7f9fc5b10650>, temperature=0.0, openai_api_key=SecretStr('**********'), openai_proxy='', max_tokens=1000, azure_endpoint='https://mmopenaiscus.openai.azure.com/', deployment_name='gpt4-0125preview-128k', openai_api_version='2024-02-15-preview', openai_api_type='azure'), kwargs={'tools': [{'type': 'function', 'function': {'name': 'internet_search_tool', 'description': 'internet_search_tool(query: str) -> str - Searches the internet using DuckDuckGo.', 'parameters': {'type': 'object', 'properties': {'query': {'type': 'string'}}, 'required': ['query']}}}, {'type': 'function', 'function': {'name': 'process_content', 'description': 'process_content(url: str) -> str - Processes content from a webpage.', 'parameters': {'type': 'object', 'properties': {'url': {'type': 'string'}}, 'required': ['url']}}}]})\n",
       "| OpenAIToolsAgentOutputParser(), input_keys_arg=[], return_keys_arg=[], stream_runnable=True), tools=[StructuredTool(name='internet_search_tool', description='internet_search_tool(query: str) -> str - Searches the internet using DuckDuckGo.', args_schema=<class 'pydantic.v1.main.internet_search_toolSchema'>, func=<function internet_search_function at 0x7f9fc58a7240>), StructuredTool(name='process_content', description='process_content(url: str) -> str - Processes content from a webpage.', args_schema=<class 'pydantic.v1.main.process_contentSchema'>, func=<function process_content at 0x7f9fc58a72e0>)])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "executor = AgentExecutor(agent=agent, tools=tools)\n",
    "executor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a32824da",
   "metadata": {},
   "source": [
    "## Create an Agent Executor with a Helper Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "a5886a8b-a290-4830-8689-3fffd856d9f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function for creating agents\n",
    "def create_agent_executor(llm: ChatOpenAI, tools: list, system_prompt: str):\n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", system_prompt),\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "        MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n",
    "    ])\n",
    "    agent = create_openai_tools_agent(llm, tools, prompt)\n",
    "    executor = AgentExecutor(agent=agent, tools=tools)\n",
    "    return executor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "2c37f240",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AgentExecutor(agent=RunnableMultiActionAgent(runnable=RunnableAssign(mapper={\n",
       "  agent_scratchpad: RunnableLambda(lambda x: format_to_openai_tool_messages(x['intermediate_steps']))\n",
       "})\n",
       "| ChatPromptTemplate(input_variables=['agent_scratchpad', 'messages'], input_types={'messages': typing.List[typing.Union[langchain_core.messages.ai.AIMessage, langchain_core.messages.human.HumanMessage, langchain_core.messages.chat.ChatMessage, langchain_core.messages.system.SystemMessage, langchain_core.messages.function.FunctionMessage, langchain_core.messages.tool.ToolMessage]], 'agent_scratchpad': typing.List[typing.Union[langchain_core.messages.ai.AIMessage, langchain_core.messages.human.HumanMessage, langchain_core.messages.chat.ChatMessage, langchain_core.messages.system.SystemMessage, langchain_core.messages.function.FunctionMessage, langchain_core.messages.tool.ToolMessage]]}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='You are a web searcher. Search the internet for information.')), MessagesPlaceholder(variable_name='messages'), MessagesPlaceholder(variable_name='agent_scratchpad')])\n",
       "| RunnableBinding(bound=AzureChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x7f9fc5a9aa90>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x7f9fc5b10650>, temperature=0.0, openai_api_key=SecretStr('**********'), openai_proxy='', max_tokens=1000, azure_endpoint='https://mmopenaiscus.openai.azure.com/', deployment_name='gpt4-0125preview-128k', openai_api_version='2024-02-15-preview', openai_api_type='azure'), kwargs={'tools': [{'type': 'function', 'function': {'name': 'internet_search_tool', 'description': 'internet_search_tool(query: str) -> str - Searches the internet using DuckDuckGo.', 'parameters': {'type': 'object', 'properties': {'query': {'type': 'string'}}, 'required': ['query']}}}, {'type': 'function', 'function': {'name': 'process_content', 'description': 'process_content(url: str) -> str - Processes content from a webpage.', 'parameters': {'type': 'object', 'properties': {'url': {'type': 'string'}}, 'required': ['url']}}}]})\n",
       "| OpenAIToolsAgentOutputParser(), input_keys_arg=[], return_keys_arg=[], stream_runnable=True), tools=[StructuredTool(name='internet_search_tool', description='internet_search_tool(query: str) -> str - Searches the internet using DuckDuckGo.', args_schema=<class 'pydantic.v1.main.internet_search_toolSchema'>, func=<function internet_search_function at 0x7f9fc58a7240>), StructuredTool(name='process_content', description='process_content(url: str) -> str - Processes content from a webpage.', args_schema=<class 'pydantic.v1.main.process_contentSchema'>, func=<function process_content at 0x7f9fc58a72e0>)])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the Search Agent Executor\n",
    "\n",
    "search_agent_exec = create_agent_executor(\n",
    "    llm=llm,\n",
    "    tools=tools,\n",
    "    system_prompt=\"You are a web searcher. Search the internet for information.\",\n",
    "    )\n",
    "\n",
    "search_agent_exec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1c84387",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Search Agent Executor\n",
    "\n",
    "insightresearch_agent_exec = create_agent_executor(\n",
    "    llm           = llm,\n",
    "    tools         = tools,\n",
    "    system_prompt = \"You are a web searcher. Search the internet for information.\",\n",
    "    )\n",
    "\n",
    "insightresearch_agent_exec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ab14504",
   "metadata": {},
   "source": [
    "# NODES"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13423743",
   "metadata": {},
   "source": [
    "# GRAPH"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abfe621f",
   "metadata": {},
   "source": [
    "## Create a Node for Researcher and Coder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01838aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function facilitates creating nodes in the graph:\n",
    "# it takes care of converting the agent response to a human message. \n",
    "# This is important because that is how we will add it the global state of the graph\n",
    "\n",
    "def agent_node(state, agent, name):\n",
    "    result = agent.invoke(state)\n",
    "    return {\"messages\": [HumanMessage(content=result[\"output\"], name=name)]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b5a7a5aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HumanMessage(content='This is the result', name='Node name')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "HumanMessage(content=\"This is the result\", name=\"Node name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "79ea7131",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['FINISH', 'Researcher', 'Coder']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "members = [\"Researcher\", \"Coder\"]\n",
    "options = [\"FINISH\"] + members\n",
    "options"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f1cf6a26",
   "metadata": {},
   "source": [
    "## Create a Node for the Supervisor Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6c79eb7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using openai function calling can make output parsing easier for us\n",
    "\n",
    "function_def = {\n",
    "    \"name\": \"route\",\n",
    "    \"description\": \"Select the next role.\",\n",
    "    \"parameters\": {\n",
    "        \"title\": \"routeSchema\",\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"next\": {\n",
    "                \"title\": \"Next\",\n",
    "                \"anyOf\": [\n",
    "                    {\"enum\": options},\n",
    "                ],\n",
    "            }\n",
    "        },\n",
    "        \"required\": [\"next\"],\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "c0349fe2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunnableBinding(bound=AzureChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x7f9fc5a9aa90>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x7f9fc5b10650>, temperature=0.0, openai_api_key=SecretStr('**********'), openai_proxy='', max_tokens=1000, azure_endpoint='https://mmopenaiscus.openai.azure.com/', deployment_name='gpt4-0125preview-128k', openai_api_version='2024-02-15-preview', openai_api_type='azure'), kwargs={'functions': [{'name': 'route', 'description': 'Select the next role.', 'parameters': {'title': 'routeSchema', 'type': 'object', 'properties': {'next': {'title': 'Next', 'anyOf': [{'enum': ['FINISH', 'Researcher', 'Coder']}]}}, 'required': ['next']}}], 'function_call': {'name': 'route'}})"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rb = llm.bind_functions(functions=[function_def], function_call=\"route\")\n",
    "rb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94e27ce7",
   "metadata": {},
   "source": [
    "### Partial Functions and functools.partial\n",
    "\n",
    "A **partial function*** is a function that is created by fixing a certain number of arguments of an existing function. This is achieved using the functools.partial function, which allows you to set default values for one or more arguments of a function, effectively creating a new function with those default values already set.\n",
    "The functools.partial function is used to create partial functions in Python. It allows you to fix a certain number of arguments of an existing function, effectively creating a new function with those fixed arguments. This can be useful when you want to create a simplified version of a function with some arguments pre-filled, or when you need to adapt a function to be used as a callback with a different signature.\n",
    "\n",
    "By using **functools.partial**, you can create specialized functions from more general ones, making your code more modular and easier to maintain. This can be especially handy when working with libraries or frameworks that require functions with specific signatures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "2f3293ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['messages'], input_types={'messages': typing.List[typing.Union[langchain_core.messages.ai.AIMessage, langchain_core.messages.human.HumanMessage, langchain_core.messages.chat.ChatMessage, langchain_core.messages.system.SystemMessage, langchain_core.messages.function.FunctionMessage, langchain_core.messages.tool.ToolMessage]]}, partial_variables={'options': \"['FINISH', 'Researcher', 'Coder']\", 'members': 'Researcher, Coder'}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['members'], template='You are a supervisor tasked with managing a conversation between the following workers:  {members}. Given the following user request, respond with the worker to act next. Each worker will perform a task and respond with their results and status. When finished, respond with FINISH.')), MessagesPlaceholder(variable_name='messages'), SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['options'], template='Given the conversation above, who should act next? Or should we FINISH? Select one of: {options}'))])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "system_prompt_supervisor = (\n",
    "    \"You are a supervisor tasked with managing a conversation between the\"\n",
    "    \" following workers:  {members}. Given the following user request,\"\n",
    "    \" respond with the worker to act next. Each worker will perform a\"\n",
    "    \" task and respond with their results and status. When finished,\"\n",
    "    \" respond with FINISH.\"\n",
    ")\n",
    "\n",
    "mp1 = MessagesPlaceholder(variable_name=\"messages\")\n",
    "mp2 = (\n",
    "    \"system\",\n",
    "    \"Given the conversation above, who should act next?\"\n",
    "    \" Or should we FINISH? Select one of: {options}\")\n",
    "\n",
    "cpt_supervisor = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system_prompt_supervisor),\n",
    "        mp1,\n",
    "        mp2\n",
    "    ]\n",
    ").partial(options=str(options), members=\", \".join(members))\n",
    "\n",
    "cpt_supervisor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "6a9945ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['messages'], input_types={'messages': typing.List[typing.Union[langchain_core.messages.ai.AIMessage, langchain_core.messages.human.HumanMessage, langchain_core.messages.chat.ChatMessage, langchain_core.messages.system.SystemMessage, langchain_core.messages.function.FunctionMessage, langchain_core.messages.tool.ToolMessage]]}, partial_variables={'options': \"['FINISH', 'Researcher', 'Coder']\", 'members': 'Researcher, Coder'}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['members'], template='You are a supervisor tasked with managing a conversation between the following workers:  {members}. Given the following user request, respond with the worker to act next. Each worker will perform a task and respond with their results and status. When finished, respond with FINISH.')), MessagesPlaceholder(variable_name='messages'), SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['options'], template='Given the conversation above, who should act next? Or should we FINISH? Select one of: {options}'))])\n",
       "| RunnableBinding(bound=AzureChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x7f9fc5a9aa90>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x7f9fc5b10650>, temperature=0.0, openai_api_key=SecretStr('**********'), openai_proxy='', max_tokens=1000, azure_endpoint='https://mmopenaiscus.openai.azure.com/', deployment_name='gpt4-0125preview-128k', openai_api_version='2024-02-15-preview', openai_api_type='azure'), kwargs={'functions': [{'name': 'route', 'description': 'Select the next role.', 'parameters': {'title': 'routeSchema', 'type': 'object', 'properties': {'next': {'title': 'Next', 'anyOf': [{'enum': ['FINISH', 'Researcher', 'Coder']}]}}, 'required': ['next']}}], 'function_call': {'name': 'route'}})\n",
       "| JsonOutputFunctionsParser()"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "supervisor_chain = (\n",
    "    cpt_supervisor\n",
    "    | rb\n",
    "    | JsonOutputFunctionsParser()\n",
    "   \n",
    ")\n",
    "\n",
    "supervisor_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "267ee384",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Invalid input type <class 'langchain_core.runnables.base.RunnableSequence'>. Must be a PromptValue, str, or list of BaseMessages.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[46], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mrb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43msupervisor_chain\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/anaconda/envs/langgraph/lib/python3.11/site-packages/langchain_core/runnables/base.py:4511\u001b[0m, in \u001b[0;36mRunnableBindingBase.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   4505\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minvoke\u001b[39m(\n\u001b[1;32m   4506\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   4507\u001b[0m     \u001b[38;5;28minput\u001b[39m: Input,\n\u001b[1;32m   4508\u001b[0m     config: Optional[RunnableConfig] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   4509\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Optional[Any],\n\u001b[1;32m   4510\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Output:\n\u001b[0;32m-> 4511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbound\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   4512\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4513\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_merge_configs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4514\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4515\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/anaconda/envs/langgraph/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py:155\u001b[0m, in \u001b[0;36mBaseChatModel.invoke\u001b[0;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minvoke\u001b[39m(\n\u001b[1;32m    144\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    145\u001b[0m     \u001b[38;5;28minput\u001b[39m: LanguageModelInput,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    150\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m BaseMessage:\n\u001b[1;32m    151\u001b[0m     config \u001b[38;5;241m=\u001b[39m ensure_config(config)\n\u001b[1;32m    152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[1;32m    153\u001b[0m         ChatGeneration,\n\u001b[1;32m    154\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenerate_prompt(\n\u001b[0;32m--> 155\u001b[0m             [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_convert_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m],\n\u001b[1;32m    156\u001b[0m             stop\u001b[38;5;241m=\u001b[39mstop,\n\u001b[1;32m    157\u001b[0m             callbacks\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallbacks\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m    158\u001b[0m             tags\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtags\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m    159\u001b[0m             metadata\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m    160\u001b[0m             run_name\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_name\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m    161\u001b[0m             \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    162\u001b[0m         )\u001b[38;5;241m.\u001b[39mgenerations[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m    163\u001b[0m     )\u001b[38;5;241m.\u001b[39mmessage\n",
      "File \u001b[0;32m/anaconda/envs/langgraph/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py:138\u001b[0m, in \u001b[0;36mBaseChatModel._convert_input\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ChatPromptValue(messages\u001b[38;5;241m=\u001b[39mconvert_to_messages(\u001b[38;5;28minput\u001b[39m))\n\u001b[1;32m    137\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 138\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    139\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid input type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28minput\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    140\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMust be a PromptValue, str, or list of BaseMessages.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    141\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Invalid input type <class 'langchain_core.runnables.base.RunnableSequence'>. Must be a PromptValue, str, or list of BaseMessages."
     ]
    }
   ],
   "source": [
    "rb.invoke(supervisor_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4ef16888",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['messages'], input_types={'messages': typing.List[typing.Union[langchain_core.messages.ai.AIMessage, langchain_core.messages.human.HumanMessage, langchain_core.messages.chat.ChatMessage, langchain_core.messages.system.SystemMessage, langchain_core.messages.function.FunctionMessage, langchain_core.messages.tool.ToolMessage]]}, partial_variables={'options': \"['FINISH', 'Researcher', 'Coder']\", 'members': 'Researcher, Coder'}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['members'], template='You are a supervisor tasked with managing a conversation between the following workers:  {members}. Given the following user request, respond with the worker to act next. Each worker will perform a task and respond with their results and status. When finished, respond with FINISH.')), MessagesPlaceholder(variable_name='messages'), SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['options'], template='Given the conversation above, who should act next? Or should we FINISH? Select one of: {options}'))])\n",
       "| RunnableBinding(bound=AzureChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x7f9fc5a9aa90>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x7f9fc5b10650>, temperature=0.0, openai_api_key=SecretStr('**********'), openai_proxy='', max_tokens=1000, azure_endpoint='https://mmopenaiscus.openai.azure.com/', deployment_name='gpt4-0125preview-128k', openai_api_version='2024-02-15-preview', openai_api_type='azure'), kwargs={'functions': [{'name': 'route', 'description': 'Select the next role.', 'parameters': {'title': 'routeSchema', 'type': 'object', 'properties': {'next': {'title': 'Next', 'anyOf': [{'enum': ['FINISH', 'Researcher', 'Coder']}]}}, 'required': ['next']}}], 'function_call': {'name': 'route'}})\n",
       "| JsonOutputFunctionsParser()"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "supervisor_chain | JsonOutputFunctionsParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "204f2f22",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[63], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m double_by_triple_chain \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m----> 2\u001b[0m     \u001b[43mx\u001b[49m\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;241m|\u001b[39mdouble\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;241m|\u001b[39m triple\n\u001b[1;32m      5\u001b[0m )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'x' is not defined"
     ]
    }
   ],
   "source": [
    "double_by_triple_chain = (\n",
    "    x\n",
    "    | double\n",
    "    | triple\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0581aee5",
   "metadata": {},
   "source": [
    "# GRAPH!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a608223",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "7e4d31fe",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'workflow' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[73], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m member \u001b[38;5;129;01min\u001b[39;00m members:\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;66;03m# We want our workers to ALWAYS \"report back\" to the supervisor when done\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m     \u001b[43mworkflow\u001b[49m\u001b[38;5;241m.\u001b[39madd_edge(member, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msupervisor\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# The supervisor populates the \"next\" field in the graph state\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# which routes to a node or finishes\u001b[39;00m\n\u001b[1;32m      6\u001b[0m conditional_map \u001b[38;5;241m=\u001b[39m {k: k \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m members}\n",
      "\u001b[0;31mNameError\u001b[0m: name 'workflow' is not defined"
     ]
    }
   ],
   "source": [
    "for member in members:\n",
    "    # We want our workers to ALWAYS \"report back\" to the supervisor when done\n",
    "    workflow.add_edge(member, \"supervisor\")\n",
    "# The supervisor populates the \"next\" field in the graph state\n",
    "# which routes to a node or finishes\n",
    "conditional_map = {k: k for k in members}\n",
    "conditional_map[\"FINISH\"] = END\n",
    "workflow.add_conditional_edges(\"supervisor\", lambda x: x[\"next\"], conditional_map)\n",
    "# Finally, add entrypoint\n",
    "workflow.set_entry_point(\"supervisor\")\n",
    "\n",
    "graph = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "662b0ce2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd2cad3e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed7da011",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91f5cd1e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4a9c9b84-23d6-4560-b01e-0287a30293f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Commercial Learner's Permit - How To Get a CLP - CDLTraining.org\",\n",
       " '7 Best Gun Oil, CLP, and Grease [Tested] - Pew Pew Tactical',\n",
       " \"What is a Commercial Learner's Permit and how do you get one?\",\n",
       " \"What is a CLP? | How to Get a Commercial Learner's Permit | ACV Auctions\",\n",
       " 'CLP Prep Guide: How to Study for Your Permit Test']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[element[\"title\"] for element in internet_search_function(\"What is a CLP?\")]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langgraph",
   "language": "python",
   "name": "langgraph"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
