{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bbc84e5c-ad82-4b47-880f-c39861ac1a13",
   "metadata": {},
   "source": [
    "# [Assistants migration guide](https://platform.openai.com/docs/assistants/migration)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60b13b70-83c3-4f35-b8f8-c0b18a0134b6",
   "metadata": {},
   "source": [
    "# Constants and Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af4e67f1-5f84-4524-a283-cd7c4e8a2ba3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment variables have been loaded ;-)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv # requires python-dotenv\n",
    "\n",
    "if not load_dotenv(\"./../../config/credentials_my.env\"):\n",
    "    print(\"Environment variables not loaded, cell execution stopped\")\n",
    "    sys.exit()\n",
    "print(\"Environment variables have been loaded ;-)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09853b2c-7409-4e6f-a405-9fbb13cc4e5a",
   "metadata": {},
   "source": [
    "# Create a client to connecto Azure OpenAI service and deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f4f982b2-460e-4342-a1b4-68575d34236a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "client.base_url: https://mmoaiswc-01.openai.azure.com/openai/\n"
     ]
    }
   ],
   "source": [
    "from openai import AzureOpenAI\n",
    "\n",
    "# Create the client\n",
    "client = AzureOpenAI(\n",
    "    # api_key        = os.getenv(\"AZURE_OPENAI_API_KEY\"),  \n",
    "    # api_version    = os.getenv(\"AZURE_OPENAI_API_VERSION\"), # at least 2024-02-15-preview\n",
    "    # azure_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    ")\n",
    "print(f\"client.base_url: {client.base_url}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45b52996-d4b6-4a73-a1df-56a53af0f3a3",
   "metadata": {},
   "source": [
    "# Check all files already uploaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6daee676-d6d5-4cfd-b184-61d4d8120f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_uploaded_files (client:AzureOpenAI, delete:bool=False):\n",
    "    i = 0\n",
    "    for file in client.files.list().data:\n",
    "        i += 1\n",
    "        if delete:\n",
    "            print(f\"File {i}: {file.filename} (id={file.id}) is being deleted...\")\n",
    "            client.files.delete(file.id) # un-comment this line if you want to delete it\n",
    "        else:\n",
    "            print(f\"File {i}: {file.filename} (id={file.id})\")\n",
    "\n",
    "list_uploaded_files(client=client, delete=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ce47dca-dbec-44b7-ad58-4cd6b6853d31",
   "metadata": {},
   "source": [
    "# Upload the Assistant file(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a83cbae6-5317-4f9b-8f5b-9858f4001e8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading ./data/turbines.csv...\n",
      "file_ids: ['assistant-G7uoAv5vy8eZ3XC5YVrjYm']\n",
      "File 1: turbines.csv (id=assistant-G7uoAv5vy8eZ3XC5YVrjYm)\n"
     ]
    }
   ],
   "source": [
    "from openai.types import FileObject\n",
    "from pathlib import Path\n",
    "\n",
    "DATA_FOLDER = \"./data/\"\n",
    "\n",
    "def upload_file(client: AzureOpenAI, path: str) -> FileObject:\n",
    "    with Path(path).open(\"rb\") as f:\n",
    "        return client.files.create(file=f, purpose=\"assistants\")\n",
    "\n",
    "arr = os.listdir(DATA_FOLDER)\n",
    "assistant_files = []\n",
    "for file in arr:\n",
    "    filePath = DATA_FOLDER + file\n",
    "    print(f\"Uploading {filePath}...\")\n",
    "    assistant_files.append(upload_file(client, filePath))\n",
    "\n",
    "file_ids = [file.id for file in assistant_files]\n",
    "\n",
    "print(f\"file_ids: {file_ids}\")\n",
    "\n",
    "list_uploaded_files(client=client, delete=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99790e83-6846-4697-a740-f861ebe0ad58",
   "metadata": {},
   "source": [
    "# Create an assistant with `code_interpreter` and `file_ids`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3959614c-ca3b-42f8-bb56-b2bc53e661d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Assistant(id='asst_1MPGsRUkZcO9nKmXiRC1cxjS', created_at=1745506845, description='You are a helpful AI assistant who helps answering questions', instructions=\"\\n        You are an assistant that can help manage wind turbine farm.\\n        The turbines operating ranges are output voltages of 33kv-35kv and RPM of 15-25. Wind speed is measured in miles per hour.\\n        Maintenance should occur every 12 months. Greet the user by saying, 'Welcome Turbine Management Assistant.\\n        \", metadata={}, model='gpt-4o', name='Turbines Assistant', object='assistant', tools=[CodeInterpreterTool(type='code_interpreter')], response_format='auto', temperature=1.0, tool_resources=ToolResources(code_interpreter=ToolResourcesCodeInterpreter(file_ids=['assistant-G7uoAv5vy8eZ3XC5YVrjYm']), file_search=None), top_p=1.0)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assistant = client.beta.assistants.create(\n",
    "    name=\"Turbines Assistant\",\n",
    "    description=\"You are a helpful AI assistant who helps answering questions\",\n",
    "    instructions = \"\"\"\n",
    "        You are an assistant that can help manage wind turbine farm.\n",
    "        The turbines operating ranges are output voltages of 33kv-35kv and RPM of 15-25. Wind speed is measured in miles per hour.\n",
    "        Maintenance should occur every 12 months. Greet the user by saying, 'Welcome Turbine Management Assistant.\n",
    "        \"\"\",\n",
    "    model = \"gpt-4o\", # gpt-4.1 still not supported by Assistants API's\n",
    "    tools = [{\"type\": \"code_interpreter\"}],\n",
    "    tool_resources = {\n",
    "        \"code_interpreter\": {\"file_ids\": file_ids}\n",
    "    }\n",
    ")\n",
    "\n",
    "assistant"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76fa4a89-5b46-4827-886d-e9c4de63d6db",
   "metadata": {},
   "source": [
    "# Create a conversation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "882859a2-5fff-48e2-a0ad-660cf9114563",
   "metadata": {},
   "source": [
    "## First, create a thread...\n",
    "Note that `code_interpreter` and `file_search` are empty, because they are associated with the `assistant`, not to the `thread`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "315555f6-73bf-4354-ab2e-8fde04c6bef8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thread(id='thread_ieSZorkOblp5krBvFMXuqQIL', created_at=1745506845, metadata={}, object='thread', tool_resources=ToolResources(code_interpreter=None, file_search=None))\n"
     ]
    }
   ],
   "source": [
    "thread = client.beta.threads.create()\n",
    "print(thread)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "959fd89f-120a-463c-89c4-73354ae86e41",
   "metadata": {},
   "source": [
    "## ...then, add a message to the thread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ca3e1a29-4bd0-4dd3-8c36-47545c4fea20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a user question to the thread\n",
    "message = client.beta.threads.messages.create(\n",
    "    thread_id=thread.id,\n",
    "    role=\"user\",\n",
    "    content=\"What is the status of turbine 1001 and 1003\"\n",
    ")\n",
    "\n",
    "thread_messages = client.beta.threads.messages.list(thread.id)\n",
    "\n",
    "# print(thread_messages.model_dump_json(indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "056efd30-c771-41d8-9b26-2c0119f22a1a",
   "metadata": {},
   "source": [
    "# Create a Run and check its status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "900ab038-56dd-49f8-ba60-1b7fde34a3cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run status: queued\n",
      "Run status: queued\n",
      "Final run status: completed\n",
      "\n",
      "\n",
      ">>> MESSAGE 1:\n",
      "What is the status of turbine 1001 and 1003\n",
      "\n",
      "\n",
      ">>> MESSAGE 2:\n",
      "Welcome to the Turbine Management Assistant.\n",
      "\n",
      "First, I will examine the uploaded file to determine its contents and check the status of turbines 1001 and 1003.\n",
      "\n",
      "\n",
      ">>> MESSAGE 3:\n",
      "The dataset provides information on various turbines including their ID, wind speed, RPM, voltage, and last maintenance date. Let's check the operational status of turbines 1001 and 1003 based on the provided data. These turbines need to be within the voltage range of 33kv-35kv and have an RPM between 15-25 in order to operate efficiently.\n",
      "\n",
      "\n",
      ">>> MESSAGE 4:\n",
      "Turbine 1001 is currently operational, as it meets the required RPM and voltage conditions. However, turbine 1003 has a voltage of 32, which is below the acceptable range for efficient operation, meaning it needs attention.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import time, json\n",
    "\n",
    "run              = client.beta.threads.runs.create(\n",
    "    thread_id    = thread.id,\n",
    "    assistant_id = assistant.id,\n",
    ")\n",
    "\n",
    "while client.beta.threads.runs.retrieve(thread_id=thread.id, run_id=run.id).status in [\"queued\", \"in_progress\"]:\n",
    "    print(f\"Run status: {run.status}\")\n",
    "    time.sleep(5)\n",
    "\n",
    "print(f\"Final run status: {client.beta.threads.runs.retrieve(thread_id=thread.id, run_id=run.id).status}\\n\\n\")\n",
    "\n",
    "# extract the result from the run, if successfull\n",
    "for m in enumerate(reversed(client.beta.threads.messages.list(thread_id=thread.id).data),1):\n",
    "    print(f\">>> MESSAGE {m[0]}:\\n{m[1].content[0].text.value}\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbfe9ef2-0a43-4232-88f8-4f646c490469",
   "metadata": {},
   "source": [
    "# Follow-up question below, then run the cell above to calculate and show it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a05f7e3b-a46b-401e-8ca6-ccaf9e849324",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a user question to the thread\n",
    "message = client.beta.threads.messages.create(\n",
    "    thread_id=thread.id,\n",
    "    role=\"user\",\n",
    "    content=\"Show me the code you used to provide the previous answer\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be3aa366-c518-422f-b48d-b7252990d3c7",
   "metadata": {},
   "source": [
    "# START teardown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "016bf385-710d-4099-b4dc-fc869e5f8648",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File 1: turbines.csv (id=assistant-G7uoAv5vy8eZ3XC5YVrjYm) is being deleted...\n"
     ]
    }
   ],
   "source": [
    "# delete files\n",
    "\n",
    "list_uploaded_files(client=client, delete=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "54ffa831-6661-4c7c-9669-ff0f331c1e25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleting message id = <msg_4xV4QbMaexXLiAe33jo5IZ6f>... of thread <thread_ieSZorkOblp5krBvFMXuqQIL>...\n",
      "Deleting message id = <msg_7m6leeWIzEYOoSGTz44yn511>... of thread <thread_ieSZorkOblp5krBvFMXuqQIL>...\n",
      "Deleting message id = <msg_mmjG5EGQAWy277u2k3gVTzC7>... of thread <thread_ieSZorkOblp5krBvFMXuqQIL>...\n",
      "Deleting message id = <msg_xBYHYnhKjTgJDKoN4QqZcrBs>... of thread <thread_ieSZorkOblp5krBvFMXuqQIL>...\n",
      "Deleting message id = <msg_8iE3ECXrwZ2ElNy35u76PZi0>... of thread <thread_ieSZorkOblp5krBvFMXuqQIL>...\n",
      "\n",
      "Deleting thread thread_ieSZorkOblp5krBvFMXuqQIL...\n",
      "\n",
      "Deleting assistant asst_1MPGsRUkZcO9nKmXiRC1cxjS (Turbines Assistant)...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AssistantDeleted(id='asst_1MPGsRUkZcO9nKmXiRC1cxjS', deleted=True, object='assistant.deleted')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for message in client.beta.threads.messages.list(thread.id):\n",
    "    print (f\"Deleting message id = <{message.id}>... of thread <{thread.id}>...\")\n",
    "    client.beta.threads.messages.delete(message_id=message.id, thread_id=thread.id)\n",
    "\n",
    "print(f\"\\nDeleting thread {thread.id}...\")\n",
    "client.beta.threads.delete(thread_id=thread.id)\n",
    "\n",
    "print(f\"\\nDeleting assistant {assistant.id} ({assistant.name})...\")\n",
    "client.beta.assistants.delete(assistant.id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c00ade1-06e1-406d-80da-a4c1d911ef12",
   "metadata": {},
   "source": [
    "# Teardown for *all** assistants and messages [(but **NOT** threads!)](https://learn.microsoft.com/en-us/answers/questions/2153170/assistants-api-where-and-how-long-are-entities-sav)\n",
    "When creating a new thread with the Assistants API, thereby creating a stateful entity of: Threads, messages, where is this data stored, can I access the resource that stores these? Or is the resource managed entirely by Microsoft, and inaccessible to me?\n",
    "When you create a new thread with the Assistants API, the data (threads, messages, etc.) is stored in a secure, Microsoft-managed storage account. This storage is logically separated to ensure data security. As a user, you do not have direct access to the underlying storage resources. Instead, you interact with the data through the API endpoints provided by Microsoft.\n",
    "\n",
    "If a thread with messages is created via the API, and the ID is lost, is there then no route to access and delete this thread? As in, would there be a way to somehow fetch all threads related to a specific OpenAI Azure resource?\n",
    "If you lose the thread ID, there is no direct way to retrieve or delete the thread through the API. The Assistants API does not currently provide a method to list all threads associated with a specific OpenAI Azure resource. Therefore, it's crucial to manage and store thread IDs securely within your application to ensure you can access and manage them as needed.\n",
    "\n",
    "Is stateful entities stored INDEFINITELY unless deleted? Or is the a time to live if not used?\n",
    "All used data persists in this system unless you explicitly delete this data. Use the delete function with the thread ID of the thread you want to delete. Clearing the Run in the Assistants Playground does not delete threads, however deleting them using delete function will not list them in the thread page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e11746c7-990a-42fb-9c74-70a192802288",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0 assistants have been successfully deleted.\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "assistants = client.beta.assistants.list(limit=100).data\n",
    "i=0\n",
    "while len(assistants) > 0:\n",
    "    for assistant in assistants: \n",
    "        i=i+1\n",
    "        print(f\"Deleting assistant {i}: {assistant.id} ({assistant.name}) created at {datetime.fromtimestamp(assistant.created_at).strftime('%Y-%m-%d %H:%M:%S')}...\")\n",
    "        client.beta.assistants.delete(assistant.id)\n",
    "    assistants = client.beta.assistants.list(limit=100).data\n",
    "\n",
    "print (f\"\\n{i} assistants have been successfully deleted.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openai",
   "language": "python",
   "name": "openai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
