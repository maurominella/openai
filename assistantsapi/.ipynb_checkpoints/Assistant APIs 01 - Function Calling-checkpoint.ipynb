{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d11960c6-989b-401e-9565-31b8115afb51",
   "metadata": {},
   "source": [
    "[Assistants migration guide](https://platform.openai.com/docs/assistants/migration)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e680592a-910e-4b79-84c1-0b506f9b69a2",
   "metadata": {},
   "source": [
    "# Constants and Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a14bcb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv # requires python-dotenv\n",
    "\n",
    "load_dotenv(\"./../../config/credentials_my.env\")\n",
    "QUESTION=\"How many flights do we have between my cat born date and Easter 2021?\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "213cb3fe-3e79-4507-8ea6-7719c97b9ed7",
   "metadata": {},
   "source": [
    "# Create a client to connecto Azure OpenAI service and deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b79a34ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "client.base_url: https://mmoaiswc-01.openai.azure.com/openai/\n"
     ]
    }
   ],
   "source": [
    "from openai import AzureOpenAI\n",
    "\n",
    "# Create the client\n",
    "client = AzureOpenAI(\n",
    "    # api_key        = os.getenv(\"AZURE_OPENAI_API_KEY\"),  \n",
    "    # api_version    = os.getenv(\"AZURE_OPENAI_API_VERSION\"), # at least 2024-02-15-preview\n",
    "    # azure_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    ")\n",
    "print(f\"client.base_url: {client.base_url}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e4b8c90-b3d6-4ec6-9128-13f05b01db62",
   "metadata": {},
   "source": [
    "# Define custom functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0094dfce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get_flights(\"2025-01-15\", \"2025-02-15\") --> {\"flights\": 31}\n",
      "my_cat_born_date --> {\"cat_born_date\": \"2015-01-26\"}\n"
     ]
    }
   ],
   "source": [
    "def get_flights(date_1:str, date_2:str) -> dict:\n",
    "    \"\"\" Returns the number of flights in a date interval  \"\"\"\n",
    "    import json\n",
    "    from dateutil.parser import parse\n",
    "    flights = {\n",
    "        \"flights\": abs((parse(date_2) - parse(date_1)).days) \n",
    "    }\n",
    "    return json.dumps(flights)\n",
    "\n",
    "def my_cat_born_date() -> dict:\n",
    "    \"\"\" Returns my cat's born date \"\"\"\n",
    "    import datetime, random, json\n",
    "    from dateutil.relativedelta import relativedelta\n",
    "    \n",
    "    # Calculate the date as ten years ago  \n",
    "    ten_years_ago = datetime.date.today() - relativedelta(years=10) \n",
    "    \n",
    "    cat_born_date = {\n",
    "        \"cat_born_date\": ten_years_ago.strftime(\"%Y-%m-%d\")\n",
    "    }\n",
    "    return json.dumps(cat_born_date)\n",
    "\n",
    "print(f'get_flights(\"2025-01-15\", \"2025-02-15\") --> {get_flights(\"2025-01-15\", \"2025-02-15\")}')\n",
    "print(f'my_cat_born_date --> {my_cat_born_date()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6b6b82e-38b6-4c7c-a64d-f0edadc545ff",
   "metadata": {},
   "source": [
    "# Wrap the functions into their tools list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c8284e5d-28e6-4122-9612-e78ec42f3727",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [\n",
    "  {\n",
    "    \"type\": \"function\",\n",
    "    \"function\": {\n",
    "      \"name\": \"get_flights\",\n",
    "      \"description\": \"returns the number of flights between two dates\",\n",
    "      \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "          \"date_1\": {\n",
    "            \"type\": \"string\",\n",
    "            \"description\": \"the first date\"\n",
    "          },\n",
    "          \"date_2\": {\n",
    "            \"type\": \"string\",\n",
    "            \"description\": \"the second date\"\n",
    "          }\n",
    "        },\n",
    "        \"required\": [\n",
    "          \"date_1\",\n",
    "          \"date_2\"\n",
    "        ]\n",
    "      }\n",
    "    }\n",
    "  },\n",
    "  {\n",
    "    \"type\": \"function\",\n",
    "    \"function\": {\n",
    "      \"name\": \"my_cat_born_date\",\n",
    "      \"description\": \"returns my cat's born date\",\n",
    "      \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {},\n",
    "        \"required\": []\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b16077c-ac46-4b23-a17d-8c54f768404f",
   "metadata": {},
   "source": [
    "# Create an Assistant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a3857b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "assistant = client.beta.assistants.create(\n",
    "    name=\"Smart Assistant\",\n",
    "    description=\"You are a helpful AI assistant who helps answering questions\",\n",
    "    tools = tools,\n",
    "    model = os.getenv(\"AZURE_OPENAI_CHAT_DEPLOYMENT_NAME\")\n",
    ")\n",
    "\n",
    "# print(assistant.model_dump_json(indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4454e74-656b-4f4e-bfcc-9e70f9905369",
   "metadata": {},
   "source": [
    "# Create a conversation\n",
    "Note that `code_interpreter` and `file_search` are empty in this case, because `code_interpreter` was not created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d2924b7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thread(id='thread_ubw79nxi2ReREDfjWp8zAM63', created_at=1737901962, metadata={}, object='thread', tool_resources=ToolResources(code_interpreter=None, file_search=None))\n"
     ]
    }
   ],
   "source": [
    "# Create a thread\n",
    "thread = client.beta.threads.create()\n",
    "print(thread)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38b802b9",
   "metadata": {},
   "source": [
    "# Add a message to the conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e7c35fe4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"data\": [\n",
      "    {\n",
      "      \"id\": \"msg_8lJ8hrKzmPLr19MWcBq7qiUA\",\n",
      "      \"assistant_id\": null,\n",
      "      \"attachments\": [],\n",
      "      \"completed_at\": null,\n",
      "      \"content\": [\n",
      "        {\n",
      "          \"text\": {\n",
      "            \"annotations\": [],\n",
      "            \"value\": \"How many flights do we have between my cat born date and Easter 2021?\"\n",
      "          },\n",
      "          \"type\": \"text\"\n",
      "        }\n",
      "      ],\n",
      "      \"created_at\": 1737901963,\n",
      "      \"incomplete_at\": null,\n",
      "      \"incomplete_details\": null,\n",
      "      \"metadata\": {},\n",
      "      \"object\": \"thread.message\",\n",
      "      \"role\": \"user\",\n",
      "      \"run_id\": null,\n",
      "      \"status\": null,\n",
      "      \"thread_id\": \"thread_ubw79nxi2ReREDfjWp8zAM63\"\n",
      "    }\n",
      "  ],\n",
      "  \"object\": \"list\",\n",
      "  \"first_id\": \"msg_8lJ8hrKzmPLr19MWcBq7qiUA\",\n",
      "  \"last_id\": \"msg_8lJ8hrKzmPLr19MWcBq7qiUA\",\n",
      "  \"has_more\": false\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Add a user question to the thread\n",
    "message = client.beta.threads.messages.create(\n",
    "    thread_id=thread.id,\n",
    "    role=\"user\",\n",
    "    content=QUESTION\n",
    ")\n",
    "\n",
    "thread_messages = client.beta.threads.messages.list(thread.id)\n",
    "\n",
    "print(thread_messages.model_dump_json(indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acfa5680-b462-4291-a2ef-28c331330fa4",
   "metadata": {},
   "source": [
    "# Create a Run and check its status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6a99a52f",
   "metadata": {},
   "outputs": [
    {
     "ename": "BadRequestError",
     "evalue": "Error code: 400 - {'error': {'message': 'Thread thread_ubw79nxi2ReREDfjWp8zAM63 already has an active run run_UCIwg7AHag7S4f7Q6R7IMdk8.', 'type': 'invalid_request_error', 'param': None, 'code': None}}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mBadRequestError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtime\u001b[39;00m\u001b[38;5;241m,\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mjson\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m run            \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbeta\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mthreads\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mruns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m  \u001b[49m\u001b[43mthread_id\u001b[49m\u001b[43m    \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mthread\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mid\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m  \u001b[49m\u001b[43massistant_id\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43massistant\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mid\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m  \u001b[49m\u001b[38;5;66;43;03m#instructions=\"New instructions\" #You can optionally provide new instructions but these will override the default instructions\u001b[39;49;00m\n\u001b[0;32m      7\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m client\u001b[38;5;241m.\u001b[39mbeta\u001b[38;5;241m.\u001b[39mthreads\u001b[38;5;241m.\u001b[39mruns\u001b[38;5;241m.\u001b[39mretrieve(thread_id\u001b[38;5;241m=\u001b[39mthread\u001b[38;5;241m.\u001b[39mid, run_id\u001b[38;5;241m=\u001b[39mrun\u001b[38;5;241m.\u001b[39mid)\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mqueued\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124min_progress\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRun status: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrun\u001b[38;5;241m.\u001b[39mstatus\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mD:\\ProgramData\\miniconda3\\envs\\openai\\Lib\\site-packages\\openai\\_utils\\_utils.py:279\u001b[0m, in \u001b[0;36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    277\u001b[0m             msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    278\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[1;32m--> 279\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\ProgramData\\miniconda3\\envs\\openai\\Lib\\site-packages\\openai\\resources\\beta\\threads\\runs\\runs.py:535\u001b[0m, in \u001b[0;36mRuns.create\u001b[1;34m(self, thread_id, assistant_id, include, additional_instructions, additional_messages, instructions, max_completion_tokens, max_prompt_tokens, metadata, model, parallel_tool_calls, response_format, stream, temperature, tool_choice, tools, top_p, truncation_strategy, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[0;32m    533\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected a non-empty value for `thread_id` but received \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mthread_id\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    534\u001b[0m extra_headers \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOpenAI-Beta\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124massistants=v2\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m(extra_headers \u001b[38;5;129;01mor\u001b[39;00m {})}\n\u001b[1;32m--> 535\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    536\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/threads/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mthread_id\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/runs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    537\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    538\u001b[0m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\n\u001b[0;32m    539\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43massistant_id\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43massistant_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    540\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43madditional_instructions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43madditional_instructions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    541\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43madditional_messages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43madditional_messages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    542\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minstructions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43minstructions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    543\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_completion_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_completion_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    544\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_prompt_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_prompt_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    545\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmetadata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    546\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    547\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mparallel_tool_calls\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    548\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mresponse_format\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    549\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    550\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtemperature\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    551\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtool_choice\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    552\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtools\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    553\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_p\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    554\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtruncation_strategy\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtruncation_strategy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    555\u001b[0m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    556\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrun_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mRunCreateParams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    557\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    558\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    559\u001b[0m \u001b[43m        \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    560\u001b[0m \u001b[43m        \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    561\u001b[0m \u001b[43m        \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    562\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    563\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquery\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minclude\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43minclude\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mRunCreateParams\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    564\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    565\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mRun\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    566\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    567\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mAssistantStreamEvent\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    568\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\ProgramData\\miniconda3\\envs\\openai\\Lib\\site-packages\\openai\\_base_client.py:1283\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[1;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1269\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mpost\u001b[39m(\n\u001b[0;32m   1270\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1271\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1278\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1279\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[0;32m   1280\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[0;32m   1281\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[0;32m   1282\u001b[0m     )\n\u001b[1;32m-> 1283\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32mD:\\ProgramData\\miniconda3\\envs\\openai\\Lib\\site-packages\\openai\\_base_client.py:960\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[1;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[0;32m    957\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    958\u001b[0m     retries_taken \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m--> 960\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    961\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    962\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    963\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    964\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    965\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries_taken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    966\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\ProgramData\\miniconda3\\envs\\openai\\Lib\\site-packages\\openai\\_base_client.py:1064\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[1;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1061\u001b[0m         err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mread()\n\u001b[0;32m   1063\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRe-raising status error\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 1064\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_status_error_from_response(err\u001b[38;5;241m.\u001b[39mresponse) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1066\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_response(\n\u001b[0;32m   1067\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39mcast_to,\n\u001b[0;32m   1068\u001b[0m     options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1072\u001b[0m     retries_taken\u001b[38;5;241m=\u001b[39mretries_taken,\n\u001b[0;32m   1073\u001b[0m )\n",
      "\u001b[1;31mBadRequestError\u001b[0m: Error code: 400 - {'error': {'message': 'Thread thread_ubw79nxi2ReREDfjWp8zAM63 already has an active run run_UCIwg7AHag7S4f7Q6R7IMdk8.', 'type': 'invalid_request_error', 'param': None, 'code': None}}"
     ]
    }
   ],
   "source": [
    "import time, json\n",
    "\n",
    "run            = client.beta.threads.runs.create(\n",
    "  thread_id    = thread.id,\n",
    "  assistant_id = assistant.id,\n",
    "  #instructions=\"New instructions\" #You can optionally provide new instructions but these will override the default instructions\n",
    ")\n",
    "\n",
    "while client.beta.threads.runs.retrieve(thread_id=thread.id, run_id=run.id).status in [\"queued\", \"in_progress\"]:\n",
    "    print(f\"Run status: {run.status}\")\n",
    "    time.sleep(5)\n",
    "\n",
    "print(f\"Final run status: {client.beta.threads.runs.retrieve(thread_id=thread.id, run_id=run.id).status}\")\n",
    "\n",
    "json.loads(client.beta.threads.runs.retrieve(thread_id=thread.id, run_id=run.id).to_json())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92ebe041-c0f5-4ea5-8b80-c9b2b1f931c2",
   "metadata": {},
   "source": [
    "# If `status` == `requires_action`, run the function(s) required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "138252a3-0f31-418f-9a49-acd4f8df31b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calling get_flights({\"date_1\":\"2015-01-26\",\"date_2\":\"2021-04-04\"}) --> {\"flights\": 2260}\n",
      "tool_outputs: [{'tool_call_id': 'call_PPGqoIJXDgKggFiyu9dT2VSy', 'output': '{\"flights\": 2260}'}]\n"
     ]
    }
   ],
   "source": [
    "run_json = json.loads(client.beta.threads.runs.retrieve(thread_id=thread.id, run_id=run.id).to_json())\n",
    "if run_json[\"status\"]==\"requires_action\":\n",
    "    tool_outputs = []\n",
    "    for tc in run_json['required_action']['submit_tool_outputs']['tool_calls']:\n",
    "        tc_id = tc['id']\n",
    "        tc_function_name = tc['function']['name']\n",
    "        tc_args = tc['function']['arguments']\n",
    "        tool_output = eval(tc_function_name)(**json.loads(tc_args))\n",
    "        print(f\"Calling {tc_function_name}({tc_args}) --> {tool_output}\")\n",
    "        tool_outputs.append({\"tool_call_id\": tc_id, \"output\": tool_output})\n",
    "    print(f\"tool_outputs: {tool_outputs}\")\n",
    "else:\n",
    "    print(f'No more actions required. Run status: {run_json[\"status\"]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c810c3e0-434c-4945-be57-ccb49b060e49",
   "metadata": {},
   "source": [
    "# Pass result(s) of the executed function(s) back to the model via `tool_outputs`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "563d36aa-d559-425d-b4f9-441e544dd5ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run status: queued\n",
      "Final run status: completed\n",
      "The run status is completed, you can move on and retrieve the final result ;-)\n"
     ]
    }
   ],
   "source": [
    "if client.beta.threads.runs.retrieve(thread_id=thread.id, run_id=run.id).status == \"completed\":\n",
    "    print(\"The run status is completed, you can move on and retrieve the final result ;-)\")\n",
    "\n",
    "else:\n",
    "    run = client.beta.threads.runs.submit_tool_outputs(\n",
    "        thread_id=thread.id,\n",
    "        tool_outputs=tool_outputs,\n",
    "        run_id=run.id\n",
    "    )\n",
    "    \n",
    "    while client.beta.threads.runs.retrieve(thread_id=thread.id, run_id=run.id).status in [\"queued\", \"in_progress\"]:\n",
    "        print(f\"Run status: {run.status}\")\n",
    "        time.sleep(5)\n",
    "    \n",
    "    run_status = client.beta.threads.runs.retrieve(thread_id=thread.id, run_id=run.id).status\n",
    "    \n",
    "    print(f\"Final run status: {run_status}\")\n",
    "    \n",
    "    if run_status == \"requires_action\":\n",
    "        print(\"Please run again the required function(s) in the above cell and then the current cell, until the run is completed.\")\n",
    "    elif run_status == \"completed\":\n",
    "        print(\"The run status is completed, you can move on and retrieve the final result ;-)\")\n",
    "    else:\n",
    "        print(f\"Please check why we have this run <{run_status}> status\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d9f8f73-ebc4-4731-947e-35ad730ce571",
   "metadata": {},
   "source": [
    "# Extract the final result from the run\n",
    "## Run the next cells **ONLY IF** `run.status = completed`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "447d3591-d04a-449d-952c-78461b62634a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have 2,260 flights between my cat's birth date, January 26, 2015, and Easter 2021, which fell on April 4, 2021.\n"
     ]
    }
   ],
   "source": [
    "messages = client.beta.threads.messages.list(thread_id=thread.id)\n",
    "print(json.loads(messages.to_json())[\"data\"][0][\"content\"][0][\"text\"][\"value\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e89ee13",
   "metadata": {},
   "source": [
    "# Final implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3ee1a7c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: How many flights do we have between my cat born date and Easter 2021?\n",
      "Run status: queued after 0 minutes 0 seconds\n",
      "Run status: queued after 0 minutes 5 seconds\n",
      "Run status: requires_action after 0 minutes 10 seconds\n",
      "Calling my_cat_born_date(**{}) --> {\"cat_born_date\": \"2015-01-26\"}\n",
      "Run status: queued after 0 minutes 15 seconds\n",
      "Run status: requires_action after 0 minutes 21 seconds\n",
      "Calling get_flights(**{\"date_1\":\"2015-01-26\",\"date_2\":\"2021-04-04\"}) --> {\"flights\": 2260}\n",
      "Run status: queued after 0 minutes 26 seconds\n",
      "\n",
      "Run status: completed after 0 minutes 31 seconds\n",
      "We have 2260 flights between your cat's birth date, January 26, 2015, and Easter 2021, which was on April 4, 2021.\n"
     ]
    }
   ],
   "source": [
    "import time, json\n",
    "\n",
    "# Create a thread\n",
    "thread = client.beta.threads.create()\n",
    "\n",
    "print (f\"Question: {QUESTION}\")\n",
    "\n",
    "message       = client.beta.threads.messages.create(\n",
    "    thread_id = thread.id,\n",
    "    role      = \"user\",\n",
    "    content   = QUESTION\n",
    ")\n",
    "\n",
    "run            = client.beta.threads.runs.create(\n",
    "  thread_id    = thread.id,\n",
    "  assistant_id = assistant.id,\n",
    "  #instructions=\"New instructions\" #You can optionally provide new instructions but these will override the default instructions\n",
    ")\n",
    "\n",
    "start_time = time.time()\n",
    "status = run.status\n",
    "\n",
    "while status not in [\"completed\", \"cancelled\", \"expired\", \"failed\"]:\n",
    "    run = client.beta.threads.runs.retrieve(thread_id=thread.id,run_id=run.id)\n",
    "    print( f\"Run status: {status} after {int((time.time() - start_time) // 60)} minutes {int((time.time() - start_time) % 60)} seconds\")\n",
    "    \n",
    "    if status == \"requires_action\":\n",
    "        tool_calls = run.required_action.submit_tool_outputs.tool_calls\n",
    "        tool_outputs = []\n",
    "        for tc in tool_calls:\n",
    "            function_to_call = tc.function.name\n",
    "            function_args    = tc.function.arguments\n",
    "            tool_output      = eval(function_to_call)(**json.loads(function_args))\n",
    "            tool_outputs.append({\"tool_call_id\": tc.id, \"output\": tool_output})\n",
    "\n",
    "            print(f\"Calling {tc.function.name}(**{tc.function.arguments}) --> {tool_output}\")\n",
    "\n",
    "        run = client.beta.threads.runs.submit_tool_outputs(\n",
    "            thread_id=thread.id, run_id=run.id, tool_outputs=tool_outputs)\n",
    "\n",
    "    time.sleep(5)\n",
    "    status = run.status\n",
    "        \n",
    "print( f\"\\nRun status: {status} after {int((time.time() - start_time) // 60)} minutes {int((time.time() - start_time) % 60)} seconds\")\n",
    "messages = client.beta.threads.messages.list(thread_id=thread.id)\n",
    "print(json.loads(messages.to_json())[\"data\"][0][\"content\"][0][\"text\"][\"value\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openai",
   "language": "python",
   "name": "openai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
