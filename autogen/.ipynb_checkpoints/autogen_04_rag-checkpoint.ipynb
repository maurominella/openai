{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c7d0c306-0d4f-46cf-97ed-cc9bcd04419a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries, Variables and Constants\n",
    "\n",
    "import autogen, os\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "cache_seed = 41 # default seed is 41"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7f1a8783-225e-4eb4-a5d3-5952da7dc102",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'model': 'gpt4-0125preview-128k',\n",
       "  'api_key': '5948e5b2b4a146cba9940adb3308d731',\n",
       "  'base_url': 'https://mmopenaiscus.openai.azure.com/',\n",
       "  'api_type': 'azure',\n",
       "  'api_version': '2024-02-15-preview'},\n",
       " {'model': 'gpt-4',\n",
       "  'api_key': 'sk-XoMik5CKuntOhvEJH5QgT3BlbkFjeoQoffxGuvWBf3G3EFKn'}]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setting configurations for autogen\n",
    "config_list = autogen.config_list_from_json(\n",
    "    env_or_file='models_list.json',\n",
    "    filter_dict={ \"model\": {\"gpt4-0125preview-128k\", \"gpt-4\"} }\n",
    ")\n",
    "\n",
    "config_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7d5924d5-ae66-4e9f-8bbb-d9603bda0c68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cache_seed': 41,\n",
       " 'config_list': [{'model': 'gpt4-0125preview-128k',\n",
       "   'api_key': '5948e5b2b4a146cba9940adb3308d731',\n",
       "   'base_url': 'https://mmopenaiscus.openai.azure.com/',\n",
       "   'api_type': 'azure',\n",
       "   'api_version': '2024-02-15-preview'},\n",
       "  {'model': 'gpt-4',\n",
       "   'api_key': 'sk-XoMik5CKuntOhvEJH5QgT3BlbkFjeoQoffxGuvWBf3G3EFKn'}],\n",
       " 'temperature': 0}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_config={\n",
    "        \"cache_seed\": cache_seed,  # seed for caching and reproducibility\n",
    "        \"config_list\": config_list,  # a list of OpenAI API configurations\n",
    "        \"temperature\": 0  # temperature for sampling        \n",
    "    }\n",
    "\n",
    "llm_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ad62c9d6-3dc7-458c-b2d0-15a5479dedc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import agents\n",
    "\n",
    "from autogen.agentchat.contrib.retrieve_assistant_agent import RetrieveAssistantAgent\n",
    "from autogen.agentchat.contrib.retrieve_user_proxy_agent import RetrieveUserProxyAgent # requires pypdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f768a69d-17da-49d7-be77-dcf524da7d2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<autogen.agentchat.contrib.retrieve_user_proxy_agent.RetrieveUserProxyAgent at 0x7fa8ec5ca5d0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create 'RetrieveUserProxyAgent' instance\n",
    "\n",
    "retrieve_userproxy = RetrieveUserProxyAgent(\n",
    "    name=\"ragproxyagent\",\n",
    "    retrieve_config={\n",
    "        \"task\": \"qa\",\n",
    "        \"docs_path\": \"https://raw.githubusercontent.com/microsoft/autogen/main/README.md\",\n",
    "    },\n",
    "    code_execution_config = {\n",
    "        \"use_docker\": False\n",
    "    },    \n",
    "    llm_config=llm_config\n",
    ")\n",
    "\n",
    "retrieve_userproxy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9a0773d2-34aa-4092-a9b7-093ce7e7fa6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<autogen.agentchat.contrib.retrieve_assistant_agent.RetrieveAssistantAgent at 0x7fa97e9d9fd0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create an 'RetrieveAssistantAgent' instance\n",
    "\n",
    "retrieve_assistant = RetrieveAssistantAgent(\n",
    "    name=\"assistant\",\n",
    "    system_message=\"You are a helpful assistant.\",\n",
    "    llm_config=llm_config\n",
    ")\n",
    "\n",
    "retrieve_assistant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "91733277-2869-4c85-9d51-9fd6a3c2a001",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "> What is autogen?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mragproxyagent\u001b[0m (to assistant):\n",
      "\n",
      "What is autogen?\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33massistant\u001b[0m (to ragproxyagent):\n",
      "\n",
      "\"Autogen\" can refer to different things depending on the context in which it's used. Here are a few possibilities:\n",
      "\n",
      "1. **Autogen in Software Development**: In the context of programming and software development, \"autogen\" typically refers to the process of automatically generating code or documentation. This can be done through tools or scripts that create necessary code structures, configuration files, or documentation based on a set of inputs or predefined templates. This automation helps in reducing manual coding errors and saves time, especially in large projects or projects with repetitive tasks.\n",
      "\n",
      "2. **Autogen in Geographic Information Systems (GIS)**: In GIS, \"Autogen\" can refer to automatically generated graphical content or features on maps. This might include the automatic generation of textures, trees, buildings, and other features in virtual landscapes or simulations based on geographic data.\n",
      "\n",
      "3. **Autogen in Aviation**: The term can also be found in the context of flight simulation software, where it refers to the automatic generation of scenery objects like buildings, vegetation, and other environmental features. This helps in creating more realistic environments for flight simulation enthusiasts and professionals.\n",
      "\n",
      "4. **Autogen as a Product or Brand Name**: It's also possible that \"Autogen\" could be a brand name or a specific product name in various industries, ranging from healthcare to automotive.\n",
      "\n",
      "Without more specific context, it's challenging to provide a detailed explanation tailored to your needs. If you have a particular area of interest in mind regarding \"autogen,\" please provide more details for a more focused answer.\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Initialize Chat and ask a question\u001b[39;00m\n\u001b[1;32m      3\u001b[0m retrieve_assistant\u001b[38;5;241m.\u001b[39mreset()\n\u001b[0;32m----> 4\u001b[0m \u001b[43mretrieve_userproxy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minitiate_chat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretrieve_assistant\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproblem\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mWhat is autogen?\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/autogen/lib/python3.11/site-packages/autogen/agentchat/conversable_agent.py:987\u001b[0m, in \u001b[0;36mConversableAgent.initiate_chat\u001b[0;34m(self, recipient, clear_history, silent, cache, max_turns, summary_method, summary_args, message, **context)\u001b[0m\n\u001b[1;32m    985\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    986\u001b[0m         msg2send \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenerate_init_message(message, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcontext)\n\u001b[0;32m--> 987\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmsg2send\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrecipient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msilent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msilent\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    988\u001b[0m summary \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_summarize_chat(\n\u001b[1;32m    989\u001b[0m     summary_method,\n\u001b[1;32m    990\u001b[0m     summary_args,\n\u001b[1;32m    991\u001b[0m     recipient,\n\u001b[1;32m    992\u001b[0m     cache\u001b[38;5;241m=\u001b[39mcache,\n\u001b[1;32m    993\u001b[0m )\n\u001b[1;32m    994\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m agent \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;28mself\u001b[39m, recipient]:\n",
      "File \u001b[0;32m~/miniconda3/envs/autogen/lib/python3.11/site-packages/autogen/agentchat/conversable_agent.py:629\u001b[0m, in \u001b[0;36mConversableAgent.send\u001b[0;34m(self, message, recipient, request_reply, silent)\u001b[0m\n\u001b[1;32m    627\u001b[0m valid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_append_oai_message(message, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124massistant\u001b[39m\u001b[38;5;124m\"\u001b[39m, recipient)\n\u001b[1;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m valid:\n\u001b[0;32m--> 629\u001b[0m     \u001b[43mrecipient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreceive\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest_reply\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msilent\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    630\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    631\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    632\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMessage can\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt be converted into a valid ChatCompletion message. Either content or function_call must be provided.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    633\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/autogen/lib/python3.11/site-packages/autogen/agentchat/conversable_agent.py:790\u001b[0m, in \u001b[0;36mConversableAgent.receive\u001b[0;34m(self, message, sender, request_reply, silent)\u001b[0m\n\u001b[1;32m    788\u001b[0m reply \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenerate_reply(messages\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchat_messages[sender], sender\u001b[38;5;241m=\u001b[39msender)\n\u001b[1;32m    789\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m reply \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 790\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreply\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msender\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msilent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msilent\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/autogen/lib/python3.11/site-packages/autogen/agentchat/conversable_agent.py:629\u001b[0m, in \u001b[0;36mConversableAgent.send\u001b[0;34m(self, message, recipient, request_reply, silent)\u001b[0m\n\u001b[1;32m    627\u001b[0m valid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_append_oai_message(message, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124massistant\u001b[39m\u001b[38;5;124m\"\u001b[39m, recipient)\n\u001b[1;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m valid:\n\u001b[0;32m--> 629\u001b[0m     \u001b[43mrecipient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreceive\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest_reply\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msilent\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    630\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    631\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    632\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMessage can\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt be converted into a valid ChatCompletion message. Either content or function_call must be provided.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    633\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/autogen/lib/python3.11/site-packages/autogen/agentchat/conversable_agent.py:788\u001b[0m, in \u001b[0;36mConversableAgent.receive\u001b[0;34m(self, message, sender, request_reply, silent)\u001b[0m\n\u001b[1;32m    786\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m request_reply \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m request_reply \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreply_at_receive[sender] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[1;32m    787\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m--> 788\u001b[0m reply \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_reply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchat_messages\u001b[49m\u001b[43m[\u001b[49m\u001b[43msender\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msender\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msender\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    789\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m reply \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    790\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msend(reply, sender, silent\u001b[38;5;241m=\u001b[39msilent)\n",
      "File \u001b[0;32m~/miniconda3/envs/autogen/lib/python3.11/site-packages/autogen/agentchat/conversable_agent.py:1876\u001b[0m, in \u001b[0;36mConversableAgent.generate_reply\u001b[0;34m(self, messages, sender, **kwargs)\u001b[0m\n\u001b[1;32m   1874\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m   1875\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_match_trigger(reply_func_tuple[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrigger\u001b[39m\u001b[38;5;124m\"\u001b[39m], sender):\n\u001b[0;32m-> 1876\u001b[0m     final, reply \u001b[38;5;241m=\u001b[39m \u001b[43mreply_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msender\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msender\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreply_func_tuple\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mconfig\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1877\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m final:\n\u001b[1;32m   1878\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m reply\n",
      "File \u001b[0;32m~/miniconda3/envs/autogen/lib/python3.11/site-packages/autogen/agentchat/conversable_agent.py:1630\u001b[0m, in \u001b[0;36mConversableAgent.check_termination_and_human_reply\u001b[0;34m(self, messages, sender, config)\u001b[0m\n\u001b[1;32m   1628\u001b[0m sender_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthe sender\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m sender \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m sender\u001b[38;5;241m.\u001b[39mname\n\u001b[1;32m   1629\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhuman_input_mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mALWAYS\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m-> 1630\u001b[0m     reply \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_human_input\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1631\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mProvide feedback to \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43msender_name\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m. Press enter to skip and use auto-reply, or type \u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mexit\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m to end the conversation: \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m   1632\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1633\u001b[0m     no_human_input_msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNO HUMAN INPUT RECEIVED.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m reply \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1634\u001b[0m     \u001b[38;5;66;03m# if the human input is empty, and the message is a termination message, then we will terminate the conversation\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/autogen/lib/python3.11/site-packages/autogen/agentchat/conversable_agent.py:1991\u001b[0m, in \u001b[0;36mConversableAgent.get_human_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m   1980\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_human_input\u001b[39m(\u001b[38;5;28mself\u001b[39m, prompt: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[1;32m   1981\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Get human input.\u001b[39;00m\n\u001b[1;32m   1982\u001b[0m \n\u001b[1;32m   1983\u001b[0m \u001b[38;5;124;03m    Override this method to customize the way to get human input.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1989\u001b[0m \u001b[38;5;124;03m        str: human input.\u001b[39;00m\n\u001b[1;32m   1990\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1991\u001b[0m     reply \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43minput\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1992\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_human_input\u001b[38;5;241m.\u001b[39mappend(reply)\n\u001b[1;32m   1993\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m reply\n",
      "File \u001b[0;32m~/miniconda3/envs/autogen/lib/python3.11/site-packages/ipykernel/kernelbase.py:1282\u001b[0m, in \u001b[0;36mKernel.raw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m   1280\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw_input was called, but this frontend does not support input requests.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1281\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m StdinNotImplementedError(msg)\n\u001b[0;32m-> 1282\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_input_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1283\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1284\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parent_ident\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshell\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1285\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_parent\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshell\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1286\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpassword\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1287\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/autogen/lib/python3.11/site-packages/ipykernel/kernelbase.py:1325\u001b[0m, in \u001b[0;36mKernel._input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m   1322\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[1;32m   1323\u001b[0m     \u001b[38;5;66;03m# re-raise KeyboardInterrupt, to truncate traceback\u001b[39;00m\n\u001b[1;32m   1324\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInterrupted by user\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1325\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1326\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m   1327\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid Message:\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "# Initialize Chat and ask a question\n",
    "\n",
    "retrieve_assistant.reset()\n",
    "retrieve_userproxy.initiate_chat(retrieve_assistant, problem=\"What is autogen?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec257da2-4a68-42a0-9aa6-fc02a083cd55",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8754b1b-cec2-4d44-8015-6e6687d9d71f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42250153-afb2-4d04-9872-d9224a69a53f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2db9bfc7-0bcc-44eb-9254-7409783071bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a938904-b1b9-4b62-a923-13d31cb43513",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14c6c8c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a UserProxyAgent instance named \"user_proxy\"\n",
    "\n",
    "from autogen.agentchat.contrib.retrieve_assistant_agent import RetrieveAssistantAgent\n",
    "from autogen.agentchat.contrib.retrieve_user_proxy_agent import RetrieveUserProxyAgent\n",
    "\n",
    "user_proxy = autogen.UserProxyAgent(\n",
    "    name                       = \"user_proxy\",\n",
    "    human_input_mode           = \"NEVER\", # NEVER / ALWAYS / TERMINATE\n",
    "    max_consecutive_auto_reply = 10,\n",
    "\n",
    "    # if the x[\"content\"] ends by \"TERMINATE\", is_termination_msg-->True; otherwise, is_termination_msg--> False\n",
    "    is_termination_msg         = lambda x: x.get(\"content\", \"\").rstrip().endswith(\"TERMINATE\"),\n",
    "    \n",
    "    code_execution_config = {\n",
    "        \"work_dir\": \"coding\",\n",
    "        \n",
    "        # Using docker is safer than running the generated code directly.\n",
    "        # set use_docker=True if docker is available to run the generated code. \n",
    "        \"use_docker\": False\n",
    "    },\n",
    "    \n",
    "    llm_config=llm_config\n",
    ")\n",
    "\n",
    "user_proxy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00bf4dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an AssistantAgent named \"assistant\"\n",
    "\n",
    "assistant = autogen.AssistantAgent(\n",
    "    name       = \"assistant\",\n",
    "    llm_config = llm_config\n",
    ")\n",
    "\n",
    "assistant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "144644e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# the assistant receives a message from the user_proxy, which contains the task description in the \"message\" field\n",
    "\n",
    "chat_res = user_proxy.initiate_chat(\n",
    "    assistant,\n",
    "    message = \"\"\"What date is today? Compare the year-to-date gain for META and TESLA.\"\"\",\n",
    "    summary_method = \"reflection_with_llm\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52f47deb-1965-4405-9baa-abbcd5e5eb80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# followup of the previous question, if needed\n",
    "user_proxy.send(\n",
    "    recipient=assistant,\n",
    "    message=\"\"\"Please use another way to gather the stock price. For example, use yfinance.\"\"\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72e3b143",
   "metadata": {},
   "outputs": [],
   "source": [
    "# autogen.Completion.clear_cache(seed=cache_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2fda647-042b-454a-ad78-bf921c63857a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "i=1\n",
    "for cr in chat_res.chat_history:\n",
    "    print(f'Step {i} --> {cr[\"content\"].rstrip()[-9:]}')\n",
    "    i=i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "728d55c9-2180-4148-8278-0b4d411eef0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the content of the cache\n",
    "\n",
    "import sqlite3\n",
    "\n",
    "# Connect to the SQLite database\n",
    "conn = sqlite3.connect(f'./.cache/{cache_seed}/cache.db')\n",
    "\n",
    "# Create a cursor object\n",
    "cur = conn.cursor()\n",
    "\n",
    "# List all tables in the database\n",
    "cur.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n",
    "print(f\"Tables in this DB: {cur.fetchall()}\\n\")\n",
    "\n",
    "# Execute a query\n",
    "cur.execute(\"SELECT * FROM Cache\")\n",
    "\n",
    "# Fetch and print the results\n",
    "for row in cur.fetchall():\n",
    "    print(row)\n",
    "\n",
    "# Close the connection\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d6215b3-9bb9-4db9-81fb-bfae1a97ae14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# followup of the previous question\n",
    "user_proxy.send(\n",
    "    recipient=assistant,\n",
    "    message=\"\"\"Plot a chart of their stock price change YTD. Save the data to stock_price_ytd.csv, and save the plot to stock_price_ytd.png.\"\"\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38b49710-fbb7-4196-9392-fdfdc7877d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Image\n",
    "\n",
    "try:\n",
    "    image = Image(filename=\"coding/stock_price_ytd.png\")\n",
    "    display(image)\n",
    "except FileNotFoundError:\n",
    "    print(\"Image not found. Please check the file name and modify if necessary.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "autogen",
   "language": "python",
   "name": "autogen"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
