{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "587a9880",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, Union\n",
    "\n",
    "from IPython import get_ipython\n",
    "from IPython.display import display, Image\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f36d8da",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "partially initialized module 'autogen' has no attribute 'config_list_from_json' (most likely due to a circular import)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mautogen\u001b[39;00m\n",
      "File \u001b[0;32m/mnt/batch/tasks/shared/LS_root/mounts/clusters/dsvm-generalpurpose01/code/Users/mauro.minella/git_repos/openai/autogen/autogen.py:27\u001b[0m\n\u001b[1;32m     24\u001b[0m os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodels_var\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mdumps(my_models)\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m# Setting configurations for autogen\u001b[39;00m\n\u001b[0;32m---> 27\u001b[0m config_list \u001b[38;5;241m=\u001b[39m \u001b[43mautogen\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig_list_from_json\u001b[49m(\n\u001b[1;32m     28\u001b[0m     env_or_file\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodels_var\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     29\u001b[0m     filter_dict\u001b[38;5;241m=\u001b[39m{\n\u001b[1;32m     30\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m: {\n\u001b[1;32m     31\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgpt4-1106-128k\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     32\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgpt4-0613-32k\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     33\u001b[0m         }\n\u001b[1;32m     34\u001b[0m     }\n\u001b[1;32m     35\u001b[0m )\n\u001b[1;32m     37\u001b[0m config_list\n\u001b[1;32m     39\u001b[0m \u001b[38;5;66;03m# create a UserProxyAgent instance named \"user_proxy\"\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: partially initialized module 'autogen' has no attribute 'config_list_from_json' (most likely due to a circular import)"
     ]
    }
   ],
   "source": [
    "import autogen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d71f17c",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "partially initialized module 'autogen' has no attribute 'config_list_from_json' (most likely due to a circular import)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mautogen\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mjson\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdotenv\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_dotenv\n",
      "File \u001b[0;32m/mnt/batch/tasks/shared/LS_root/mounts/clusters/dsvm-generalpurpose01/code/Users/mauro.minella/git_repos/openai/autogen/autogen.py:27\u001b[0m\n\u001b[1;32m     24\u001b[0m os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodels_var\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mdumps(my_models)\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m# Setting configurations for autogen\u001b[39;00m\n\u001b[0;32m---> 27\u001b[0m config_list \u001b[38;5;241m=\u001b[39m \u001b[43mautogen\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig_list_from_json\u001b[49m(\n\u001b[1;32m     28\u001b[0m     env_or_file\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodels_var\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     29\u001b[0m     filter_dict\u001b[38;5;241m=\u001b[39m{\n\u001b[1;32m     30\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m: {\n\u001b[1;32m     31\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgpt4-1106-128k\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     32\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgpt4-0613-32k\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     33\u001b[0m         }\n\u001b[1;32m     34\u001b[0m     }\n\u001b[1;32m     35\u001b[0m )\n\u001b[1;32m     37\u001b[0m config_list\n\u001b[1;32m     39\u001b[0m \u001b[38;5;66;03m# create a UserProxyAgent instance named \"user_proxy\"\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: partially initialized module 'autogen' has no attribute 'config_list_from_json' (most likely due to a circular import)"
     ]
    }
   ],
   "source": [
    "import autogen\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(\"./../credentials_my.env\")\n",
    "\n",
    "my_models = [\n",
    "    {\n",
    "        'model': os.environ['GPT4-1106-128k'],\n",
    "        'api_key': os.environ['AZURE_OPENAI_API_KEY'],\n",
    "        \"base_url\": os.environ['AZURE_OPENAI_ENDPOINT'],\n",
    "        \"api_type\": os.environ['OPENAI_API_TYPE'],\n",
    "        \"api_version\": os.environ['AZURE_OPENAI_API_VERSION']\n",
    "    },\n",
    "    {\n",
    "        'model': os.environ['GPT432-0613-32k'],\n",
    "        'api_key': os.environ['AZURE_OPENAI_API_KEY'],\n",
    "        \"base_url\": os.environ['AZURE_OPENAI_ENDPOINT'],\n",
    "        \"api_type\": os.environ['OPENAI_API_TYPE'],\n",
    "        \"api_version\": os.environ['AZURE_OPENAI_API_VERSION']\n",
    "    }\n",
    "]\n",
    "\n",
    "# need for converting to string\n",
    "os.environ['models_var'] = json.dumps(my_models)\n",
    "\n",
    "# Setting configurations for autogen\n",
    "config_list = autogen.config_list_from_json(\n",
    "    env_or_file='models_var',\n",
    "    filter_dict={\n",
    "        \"model\": {\n",
    "            \"gpt4-1106-128k\",\n",
    "            \"gpt4-0613-32k\"\n",
    "        }\n",
    "    }\n",
    ")\n",
    "\n",
    "config_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cff6da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import autogen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14c6c8c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a UserProxyAgent instance named \"user_proxy\"\n",
    "\n",
    "user_proxy = autogen.UserProxyAgent(\n",
    "    name=\"user_proxy\",\n",
    "    human_input_mode=\"NEVER\",\n",
    "    max_consecutive_auto_reply=10,\n",
    "\n",
    "    # if the x[\"content\"] ends by \"TERMINATE\", is_termination_msg-->True; otherwise, is_termination_msg--> False\n",
    "    is_termination_msg=lambda x: x.get(\"content\", \"\").rstrip().endswith(\"TERMINATE\"),\n",
    "    \n",
    "    code_execution_config={\n",
    "        \"work_dir\": \"coding\",\n",
    "        \n",
    "        # Using docker is safer than running the generated code directly.\n",
    "        # set use_docker=True if docker is available to run the generated code. \n",
    "        \"use_docker\": False,  \n",
    "        \n",
    "    }\n",
    ")\n",
    "\n",
    "user_proxy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00bf4dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an AssistantAgent named \"assistant\"\n",
    "\n",
    "assistant = autogen.AssistantAgent(\n",
    "    name=\"assistant\",\n",
    "    llm_config={\n",
    "        \"cache_seed\": 44,  # seed for caching and reproducibility\n",
    "        \"config_list\": config_list,  # a list of OpenAI API configurations\n",
    "        \"temperature\": 0,  # temperature for sampling\n",
    "    },  # configuration for autogen's enhanced inference API which is compatible with OpenAI API\n",
    ")\n",
    "\n",
    "assistant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "144644e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the assistant receives a message from the user_proxy, which contains the task description\n",
    "\n",
    "chat_res = user_proxy.initiate_chat(\n",
    "    assistant,\n",
    "    message=\"\"\"What date is today? Compare the year-to-date gain for META and TESLA.\"\"\",\n",
    "    summary_method=\"reflection_with_llm\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72e3b143",
   "metadata": {},
   "outputs": [],
   "source": [
    "autogen.Completion.clear_cache(seed=43)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "autogen",
   "language": "python",
   "name": "autogen"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
