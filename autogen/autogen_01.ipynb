{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4bf095b2-d1c5-4d01-a4fd-154153f7fbfc",
   "metadata": {},
   "source": [
    "# [Autogen 0.5.5 (stable) setup](https://microsoft.github.io/autogen/stable/user-guide/agentchat-user-guide/installation.html)\n",
    "## Install OpenAI for Model Client\n",
    "- To use the OpenAI and Azure OpenAI models, you need to install the following extensions: `pip install \"autogen-ext[openai]\"`\n",
    "- If you are using Azure OpenAI with AAD authentication, you need to install the following: `pip install \"autogen-ext[azure]\"`\n",
    "- If you want to install both libraries, you maysimply install the following: `pip install \"autogen-ext[openai,azure]\"`\n",
    "\n",
    "\n",
    "## Full setup\n",
    "```\n",
    "conda env remove -n autogen -y\n",
    "conda create -n autogen python=3.13 -y\n",
    "conda activate autogen\n",
    "pip install -U \"autogen-agentchat\" \"autogen-ext[azure]\" \"autogen-ext[openai]\" python-dotenv jupyter\n",
    "jupyter kernelspec list\n",
    "jupyter kernelspec uninstall autogen -y\n",
    "jupyter kernelspec list\n",
    "python -m ipykernel install --name autogen --user\n",
    "```\n",
    "Other possible libraries: *pyautogen markdownify openai chroma apify-client duckduckgo-search langchain langchain-community*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26ee300c-d06e-4c90-ae53-bb14343cb298",
   "metadata": {},
   "source": [
    "# Libaries and Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a741c7bd-4656-49e3-9297-2ddb7d377736",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !az login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b959a62f-b99b-421f-950b-42819e2cb839",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment variables have been loaded ;-)\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "from autogen_agentchat.agents import AssistantAgent\n",
    "from autogen_agentchat.ui import Console\n",
    "from autogen_ext.models.openai import AzureOpenAIChatCompletionClient\n",
    "from dotenv import load_dotenv # requires python-dotenv\n",
    "\n",
    "if not load_dotenv(\"./../../../config/credentials_my.env\"):\n",
    "    print(\"Environment variables not loaded, cell execution stopped\")\n",
    "else:    \n",
    "    print(\"Environment variables have been loaded ;-)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "194bcabc-4608-44fc-853d-6fc1a01fd826",
   "metadata": {},
   "source": [
    "# Define a model client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "78b5a974-0dbe-4d5c-b9e9-a26f7bce8282",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ComponentModel(provider='autogen_ext.models.openai.AzureOpenAIChatCompletionClient', component_type='model', version=1, component_version=1, description='Chat completion client for Azure OpenAI hosted models.', label='AzureOpenAIChatCompletionClient', config={'model': 'gpt-4o', 'azure_endpoint': 'https://mmoaiswc-01.openai.azure.com/', 'azure_deployment': 'gpt-4o', 'api_version': '2025-03-01-preview', 'azure_ad_token_provider': {'provider': 'autogen_ext.auth.azure.AzureTokenProvider', 'component_type': 'token_provider', 'version': 1, 'component_version': 1, 'label': 'AzureTokenProvider', 'config': {'provider_kind': 'DefaultAzureCredential', 'scopes': ['https://cognitiveservices.azure.com/.default']}}})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_model_client(aad:bool=True):\n",
    "    if aad:\n",
    "        from autogen_ext.auth.azure import AzureTokenProvider\n",
    "        from azure.identity import DefaultAzureCredential\n",
    "        \n",
    "        token_provider = AzureTokenProvider(\n",
    "            DefaultAzureCredential(), \n",
    "            \"https://cognitiveservices.azure.com/.default\")\n",
    "        \n",
    "        model_client = AzureOpenAIChatCompletionClient(\n",
    "            azure_endpoint = os.environ[\"AZURE_OPENAI_ENDPOINT\"],\n",
    "            azure_deployment = os.environ[\"MODEL_DEPLOYMENT_NAME\"],\n",
    "            model = os.environ[\"MODEL_DEPLOYMENT_NAME\"], # this is the model of the deployment\n",
    "            api_version = os.environ[\"OPENAI_API_VERSION\"],            \n",
    "            azure_ad_token_provider=token_provider,\n",
    "        )\n",
    "    else:\n",
    "        model_client = AzureOpenAIChatCompletionClient(\n",
    "            azure_endpoint = os.environ[\"AZURE_OPENAI_ENDPOINT\"],\n",
    "            model = os.environ[\"MODEL_DEPLOYMENT_NAME\"], # this is the model of the deployment\n",
    "            api_version = os.environ[\"OPENAI_API_VERSION\"],\n",
    "            api_key=os.environ[\"AZURE_OPENAI_API_KEY\"],\n",
    "        )\n",
    "\n",
    "    return model_client\n",
    "    \n",
    "model_client = create_model_client(aad=True)\n",
    "model_client.dump_component()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c11f065-5c07-4286-8ea3-a195028ee50a",
   "metadata": {},
   "source": [
    "# Define a simple function tool that the agent can use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1d27e15e-5743-42ce-8805-982322bfc0f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The weather in non-existing city is 23 Celsius degrees and Sunny'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For this example, we use a fake weather tool for demonstration purposes\n",
    "\n",
    "async def get_weather(city: str) -> str:\n",
    "    \"\"\"Get the weather for a given city.\"\"\"\n",
    "    return f\"The weather in {city} is 23 Celsius degrees and Sunny\"\n",
    "\n",
    "\n",
    "await get_weather(\"non-existing city\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "774df992-f5af-476b-84b2-7920b8722acf",
   "metadata": {},
   "source": [
    "# Define an AssistantAgent with:\n",
    "- model\n",
    "- tool\n",
    "- system message\n",
    "- reflection enabled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "794bf589-f196-4558-b133-666583e19aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The system message instructs the agent via natural language\n",
    "agent = AssistantAgent(\n",
    "    name=\"weather_agent\",\n",
    "    model_client=model_client,\n",
    "    tools=[get_weather],\n",
    "    system_message=\"You are a helpful assistant.\",\n",
    "    reflect_on_tool_use=True,\n",
    "    model_client_stream=True,  # Enable streaming tokens from the model client.\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4de8bda-5dbb-46e4-b7fd-b6d2e380338a",
   "metadata": {},
   "source": [
    "# Run the agent and stream the messages to the console"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "25a8975f-b5e0-4ec2-bd73-3d1a65a72b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def main(question:str, terminate:bool=False) -> None:\n",
    "    await Console(agent.run_stream(task=question))\n",
    "    if terminate: # Close the connection to the model client.\n",
    "        await model_client.close()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fbd68684-d7d1-4012-8240-4c63f85f0ef1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- TextMessage (user) ----------\n",
      "Che tempo fa nel più grande comune di Milano, esclusa Milano?\n",
      "---------- ModelClientStreamingChunkEvent (weather_agent) ----------\n",
      "Il più grande comune della provincia di Milano, escluso Milano, è Sesto San Giovanni. Procedo a controllare il meteo.\n",
      "---------- ToolCallRequestEvent (weather_agent) ----------\n",
      "[FunctionCall(id='call_DODb4FniuGp3Kddm6SsmUSNO', arguments='{\"city\":\"Sesto San Giovanni\"}', name='get_weather')]\n",
      "---------- ToolCallExecutionEvent (weather_agent) ----------\n",
      "[FunctionExecutionResult(content='The weather in Sesto San Giovanni is 23 Celsius degrees and Sunny', name='get_weather', call_id='call_DODb4FniuGp3Kddm6SsmUSNO', is_error=False)]\n",
      "---------- ModelClientStreamingChunkEvent (weather_agent) ----------\n",
      "A Sesto San Giovanni ci sono 23 gradi Celsius ed è soleggiato.\n"
     ]
    }
   ],
   "source": [
    "# NOTE: if running this inside a Python script you'll need to use asyncio.run(main()).\n",
    "await main(question = \"Che tempo fa nel più grande comune di Milano, esclusa Milano?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "autogen",
   "language": "python",
   "name": "autogen"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
