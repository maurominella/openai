{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "71db7891-8eee-4175-970b-70c16f714293",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from IPython.display import Markdown, display\n",
    "from dotenv import load_dotenv\n",
    "from openai import AzureOpenAI # https://github.com/openai/openai-python\n",
    "\n",
    "load_dotenv(\"./../../config/credentials_my.env\")\n",
    "\n",
    "client = AzureOpenAI(\n",
    "    azure_endpoint = os.environ['openai_endpoint'],\n",
    "    api_key        = os.environ['openai_api_key'],\n",
    "    api_version    = os.environ['openai_api_version']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c1163c9d-0c8c-4a05-a9cf-e91707eb4f3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'As a Microsoft employee I have to formally fill a form where a Customer of ours is asking a series of questions to compare multiple cloud vendors\\' (such as Microsoft, Google, AWS and others) AI Platforms.\\nEach question consists of three points: 1) Area 2) Requirements 3) Description.\\nThe answer must include three points (A-B-C) to be filled as follows: \\nA) Supported, which can be **EXCLUSIVELY** \\n- Fully supported \\n- Partially supported\\n- Not supported (to be) \\n- Not supported (never)\\n\\nB) How integration occurs, that must be a brief explanation of max 30 words\\nC) Notes, that is a comment to A and B, mainly if A is not \"fully supported\"\\n\\nAs said, my answer must specifically cover the Microsoft offer of the Azure AI Data Platform, which today consists of AI Foundry and all the Agents / Multi-Agents offering.\\n**IMPORTANT** the answers will have to maximize Microsoft chance of winning this tender. You don\\'t have to lie, of course, but please be **VERY** optimistic.\\n\\nI will now pass you the question in json format, on at a time. Please provide the answers in json format too. Thanks for your help, I really count on you!'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Open the system message\n",
    "with open('isp_system_message.txt', 'r') as file:\n",
    "    # Read the contents of the file\n",
    "    system_message = file.read()\n",
    "\n",
    "# Print the content\n",
    "print(system_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ea10ba91-2843-48a0-8054-72da97a6e12a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 0: {'Area': 'Provider Service Isolation', 'Requirement': 'Single Endpoint for Provider Services', 'Description': 'The product must expose a single endpoint for equivalent services across different providers, ensuring consistent syntax regardless of the underlying provider.'}\n",
      "Row 1: {'Area': 'Provider Service Isolation', 'Requirement': 'Transparent Provider Integration', 'Description': 'The product must allow new providers to be added without requiring SDK and library installations on the client side.'}\n",
      "Row 2: {'Area': 'Provider Service Isolation', 'Requirement': 'SDK Changes Absorption', 'Description': 'The product must absorb provider SDK changes and hide them from service client, unless major incompatibilities or new features are introduced.'}\n",
      "Row 3: {'Area': 'Provider Service Isolation', 'Requirement': 'Input Unification', 'Description': 'The product must unify equivalent input data from different providers into a common structure, maintaining provider-specific data separately.'}\n",
      "Row 4: {'Area': 'Provider Service Isolation', 'Requirement': 'Output Unification', 'Description': 'The product must unify provider service output data with equivalent meanings into a provider-independent structure, maintaining provider-specific data separately with clear provider attribution.'}\n",
      "Row 5: {'Area': 'Support for synchronous and asynchronous services', 'Requirement': 'Synchronous Service Support', 'Description': 'The product must support synchronous service invocation with appropriate timeout handling.'}\n",
      "Row 6: {'Area': 'Support for synchronous and asynchronous services', 'Requirement': 'Massive Task Support', 'Description': 'The product must support independent processing of massive tasks with status verification and result retrieval capabilities.'}\n",
      "Row 7: {'Area': 'Support for synchronous and asynchronous services', 'Requirement': 'Sync/Async Conversion', 'Description': 'The product must be capable of exposing synchronous provider services as asynchronous and vice versa, particularly for long-running operations.'}\n",
      "Row 8: {'Area': 'Support for synchronous and asynchronous services', 'Requirement': 'Consistent Input Interface', 'Description': 'The product must maintain identical payload structure and parameter meanings regardless of synchronous or asynchronous invocation mode.'}\n",
      "Row 9: {'Area': 'Support for synchronous and asynchronous services', 'Requirement': 'Consistent Output Interface', 'Description': 'The product must ensure output consistency regardless of invocation mode, with asynchronous results matching synchronous payload content.'}\n",
      "Row 10: {'Area': 'Support for synchronous and asynchronous services', 'Requirement': 'Endpoint Consistency', 'Description': 'The product must expose consistent endpoint syntax across all platform functionalities for both synchronous and asynchronous operations.'}\n",
      "Row 11: {'Area': 'Support for synchronous and asynchronous services', 'Requirement': 'Asynchronous Execution Guarantee', 'Description': 'The product must guarantee asynchronous request handling through queue management, ensuring FIFO processing unless provider or infrastructure errors occur.'}\n",
      "Row 12: {'Area': 'Support for synchronous and asynchronous services', 'Requirement': 'Standard Async Workflow', 'Description': 'The product must implement a standard asynchronous workflow including process initialization, file loading, service activation, execution status verification, and result retrieval.'}\n",
      "Row 13: {'Area': 'Error Management', 'Requirement': 'Unified Error Messages', 'Description': 'The product must provide unified error message format across all services using a consistent JSON structure.'}\n",
      "Row 14: {'Area': 'Error Management', 'Requirement': 'Unified Error Codes', 'Description': 'The product must unify common service error codes across all providers.'}\n",
      "Row 15: {'Area': 'Error Management', 'Requirement': 'Provider Error Isolation', 'Description': 'The product must absorb and manage provider errors, returning simplified and unified messages to consumers.'}\n",
      "Row 16: {'Area': 'Error Management', 'Requirement': 'Platform Error Standardization', 'Description': 'The product must implement standardized error handling processes across all services, ensuring consistent error messages for similar issues.'}\n",
      "Row 17: {'Area': 'Error Management', 'Requirement': 'Automatic Retry', 'Description': 'The product must support automatic retry functionality for communication errors.'}\n",
      "Row 18: {'Area': 'Centralized status management', 'Requirement': 'Centralized State Management', 'Description': 'The product must implement a centralized state management system for both synchronous and asynchronous services with codified states and shared base workflow.'}\n",
      "Row 19: {'Area': 'Centralized status management', 'Requirement': 'Unified API Lifecycle (sync)', 'Description': 'The product must implement unified API startup and shutdown structures.'}\n",
      "Row 20: {'Area': 'Centralized status management', 'Requirement': 'Unified Consumer State Management (async)', 'Description': 'The product must implement unified consumer startup and shutdown structures with state codification and storage.'}\n",
      "Row 21: {'Area': 'Centralized status management', 'Requirement': 'State Change History', 'Description': 'The product must maintain a record of all state changes for debugging, security, and monitoring purposes.'}\n",
      "Row 22: {'Area': 'Centralized status management', 'Requirement': 'Shared Status Manager', 'Description': 'The product must provide internal APIs for service state management.'}\n",
      "Row 23: {'Area': 'Centralized status management', 'Requirement': 'Configurable State System', 'Description': 'The product must support state system extension for service-specific workflows beyond standard platform states.'}\n",
      "Row 24: {'Area': 'Centralized status management', 'Requirement': 'Status Verification API', 'Description': 'The product must provide APIs for client applications to verify asynchronous process execution status.'}\n",
      "Row 25: {'Area': 'Centralized Storage Management', 'Requirement': 'Centralized Storage Management', 'Description': 'The product must implement centralized cloud storage management for service file operations.'}\n",
      "Row 26: {'Area': 'Centralized Storage Management', 'Requirement': 'Storage Provider Independence', 'Description': 'The product must provide uniform file storage and retrieval endpoints regardless of the underlying storage provider.'}\n",
      "Row 27: {'Area': 'Centralized Storage Management', 'Requirement': 'File Upload API', 'Description': 'The product must provide APIs for client applications to upload files for service processing.'}\n",
      "Row 28: {'Area': 'Centralized Storage Management', 'Requirement': 'Result Download API', 'Description': 'The product must provide APIs for client applications to download service result files.'}\n",
      "Row 29: {'Area': 'Centralized Storage Management', 'Requirement': 'Internal Storage API', 'Description': 'The product must provide internal APIs for services to list, upload, and download files from storage.'}\n",
      "Row 30: {'Area': 'Centralized Credential Management', 'Requirement': 'Provider-Independent Authentication', 'Description': 'The product must implement provider-independent authentication using OAuth2 tokens (or equivalent).'}\n",
      "Row 31: {'Area': 'Centralized Credential Management', 'Requirement': 'Credential Mapping', 'Description': 'The product must automatically map client applications tokens to appropriate provider credentials.'}\n",
      "Row 32: {'Area': 'Centralized Credential Management', 'Requirement': 'Authentication Tracking', 'Description': 'The product must log authentication operations for monitoring, security, and debugging purposes.'}\n",
      "Row 33: {'Area': 'Centralized Credential Management', 'Requirement': 'Use Case Based Authentication', 'Description': 'The product must generate tokens based on use case and identifier of area for client application tracking.'}\n",
      "Row 34: {'Area': 'Centralized Configuration Management', 'Requirement': 'Centralized Configuration', 'Description': 'The product must implement centralized management of access configurations, endpoints, and credentials.'}\n",
      "Row 35: {'Area': 'Centralized Configuration Management', 'Requirement': 'Use Case Configuration', 'Description': 'The product must manage configurations based on client area identifier and use case.'}\n",
      "Row 36: {'Area': 'Centralized Configuration Management', 'Requirement': 'Provider-Specific Configuration', 'Description': 'The product must maintain different configurations per provider and functionality for each use case.'}\n",
      "Row 37: {'Area': 'Centralized Configuration Management', 'Requirement': 'Environment Configuration', 'Description': 'The product must manage configurations for different execution environments.'}\n",
      "Row 38: {'Area': 'Centralized Configuration Management', 'Requirement': 'Service Endpoint Registry', 'Description': 'The product must maintain a registry of provider service endpoints.'}\n",
      "Row 39: {'Area': 'Centralized Configuration Management', 'Requirement': 'Resource Registry', 'Description': 'The product must maintain a registry of use case-specific resources required for service execution.'}\n",
      "Row 40: {'Area': 'Centralized Configuration Management', 'Requirement': 'Provider Change Isolation', 'Description': 'The product must isolate consumers from provider endpoint or resource name changes through configuration management.'}\n",
      "Row 41: {'Area': 'Protocols, file formats and integration', 'Requirement': 'Internal HTTP Communication', 'Description': 'The product must use unencrypted HTTP for internal  layer communication to optimize performance.'}\n",
      "Row 42: {'Area': 'Protocols, file formats and integration', 'Requirement': 'Internal Async Communication', 'Description': 'The product must implement queue-based asynchronous communication for long-running operations.'}\n",
      "Row 43: {'Area': 'Protocols, file formats and integration', 'Requirement': 'Queue System Isolation', 'Description': 'The product must hide queue system complexity from consumers through REST APIs.'}\n",
      "Row 44: {'Area': 'Protocols, file formats and integration', 'Requirement': 'Secure External Communication', 'Description': 'The product must expose services via HTTPS to prevent token interception and man-in-the-middle attacks.'}\n",
      "Row 45: {'Area': 'Protocols, file formats and integration', 'Requirement': 'HTTP Streaming Support', 'Description': 'The product must support standard HTTP streaming for real-time data delivery.'}\n",
      "Row 46: {'Area': 'Protocols, file formats and integration', 'Requirement': 'WebSocket Support', 'Description': 'The product must support bidirectional communication via WebSocket protocol.'}\n",
      "Row 47: {'Area': 'Protocols, file formats and integration', 'Requirement': 'Binary Attachment Support', 'Description': 'The product must support binary file attachments in standard formats (PDF, Office, JPG, PNG) with MIME type verification.'}\n",
      "Row 48: {'Area': 'Protocols, file formats and integration', 'Requirement': 'RESTful API Standard', 'Description': 'The product must expose services through RESTful APIs with JSON payload support.'}\n",
      "Row 49: {'Area': 'Protocols, file formats and integration', 'Requirement': 'Framework Integration', 'Description': 'The product must provide integration capabilities with standard AI frameworks.'}\n",
      "Row 50: {'Area': 'Protocols, file formats and integration', 'Requirement': 'Token-Based Authentication', 'Description': 'The product must implement token-based authentication for service access.'}\n",
      "Row 51: {'Area': 'Protocols, file formats and integration', 'Requirement': 'Secure Key Management', 'Description': 'The product must implement secure provider access key management.'}\n",
      "Row 52: {'Area': 'Protocols, file formats and integration', 'Requirement': 'Microservice Architecture', 'Description': 'The product must be implemented using microservice architecture principles.'}\n",
      "Row 53: {'Area': 'Protocols, file formats and integration', 'Requirement': 'Queue-Based Async Management', 'Description': 'The product must implement queue-based asynchronous service management.'}\n",
      "Row 54: {'Area': 'Protocols, file formats and integration', 'Requirement': 'Standard Logging', 'Description': 'The product must implement standardized logging practices.'}\n",
      "Row 55: {'Area': 'Protocols, file formats and integration', 'Requirement': 'Monitoring Integration', 'Description': 'The product must integrate with standard monitoring systems.'}\n",
      "Row 56: {'Area': 'Protocols, file formats and integration', 'Requirement': 'Kafka', 'Description': 'Kafka support for messaqging'}\n",
      "Row 57: {'Area': 'Protocols, file formats and integration', 'Requirement': 'Hascicorp', 'Description': 'Hasicorp support for provider credential management'}\n",
      "Row 58: {'Area': 'Protocols, file formats and integration', 'Requirement': 'Centralized Access Gateway', 'Description': 'The product must provide a single access point for all platform services.'}\n",
      "Row 59: {'Area': 'Protocols, file formats and integration', 'Requirement': 'Multi-Version Support', 'Description': 'The product must support multiple versions of the same service for gradual transitions.'}\n",
      "Row 60: {'Area': 'Protocols, file formats and integration', 'Requirement': 'Shared Platform Functions', 'Description': 'The product must expose common functions as platform services through the gateway.'}\n",
      "Row 61: {'Area': 'Protocols, file formats and integration', 'Requirement': 'Pay-as-you-go Support', 'Description': 'The product must support pay-as-you-go resource allocation with usage-based cost attribution.'}\n",
      "Row 62: {'Area': 'Protocols, file formats and integration', 'Requirement': 'Premium Resource Support', 'Description': 'The product must support premium resource allocation with monthly usage fees (like Azure PTU).'}\n",
      "Row 63: {'Area': 'Protocols, file formats and integration', 'Requirement': 'Automatic Resource Switching', 'Description': 'The product must support automatic switching between premium and pay-as-you-go resources based on availability.'}\n",
      "Row 64: {'Area': 'Protocols, file formats and integration', 'Requirement': 'Usage Tracking', 'Description': 'The product must track resource usage for accurate cost attribution.'}\n",
      "Row 65: {'Area': 'Protocols, file formats and integration', 'Requirement': 'Unified Development Framework', 'Description': 'The product must provide a unified framework for adding new services (called provider APIs or internal company APIs)'}\n",
      "Row 66: {'Area': 'Protocols, file formats and integration', 'Requirement': 'Service Orchestration', 'Description': 'The product must support service orchestration and composition for creating higher-level functionalities.'}\n",
      "Row 67: {'Area': 'Protocols, file formats and integration', 'Requirement': 'On-Premise Integration', 'Description': 'The product must support integration with on-premise AI services.'}\n",
      "Row 68: {'Area': 'Protocols, file formats and integration', 'Requirement': 'On-Premise Monitoring', 'Description': 'The product must provide monitoring capabilities for integrated on-premise services.'}\n",
      "Row 69: {'Area': 'Protocols, file formats and integration', 'Requirement': 'Internal Service Security', 'Description': 'The product must implement authentication and authorization for on-premise services.'}\n",
      "Row 70: {'Area': 'Protocols, file formats and integration', 'Requirement': 'Interface Standardization', 'Description': 'The product must standardize call methods and message formats across all services.'}\n",
      "Row 71: {'Area': 'Protocols, file formats and integration', 'Requirement': 'Batch Processing Support', 'Description': 'The product must support batch processing capabilities for integrated services.'}\n",
      "Row 72: {'Area': 'Protocols, file formats and integration', 'Requirement': 'Azure - LLM Generation', 'Description': 'The product must integrate with Azure OpenAI Service to provide text generation capabilities, supporting models like GPT-4 and GPT-3.5, with configurable parameters for temperature, max tokens, and streaming responses.'}\n",
      "Row 73: {'Area': 'Protocols, file formats and integration', 'Requirement': 'Google - LLM Generation', 'Description': \"The product must integrate with Google's Vertex AI PaLM/Gemini API for text generation, supporting various model versions with configurable generation parameters and streaming capabilities.\"}\n",
      "Row 74: {'Area': 'Protocols, file formats and integration', 'Requirement': 'Azure - LLM Embedding', 'Description': 'The product must use Azure OpenAI embeddings models to generate vector representations of text, supporting different model dimensions optimized for various use cases.'}\n",
      "Row 75: {'Area': 'Protocols, file formats and integration', 'Requirement': 'Google - LLM Embedding', 'Description': \"The product must integrate with Google's Vertex AI embedding models to generate text embeddings, supporting various dimension sizes and optimizations.\"}\n",
      "Row 76: {'Area': 'Protocols, file formats and integration', 'Requirement': 'Azure - Translation', 'Description': 'The product must utilize Azure Translator service for text translation between multiple languages, supporting batch translation and custom dictionaries.'}\n",
      "Row 77: {'Area': 'Protocols, file formats and integration', 'Requirement': 'Google - Translation', 'Description': 'The product must integrate with Google Cloud Translation API for multi-language translation support, including language detection and glossary customization.'}\n",
      "Row 78: {'Area': 'Protocols, file formats and integration', 'Requirement': 'Azure - Sentiment Analysis', 'Description': 'The product must use Azure Text Analytics to analyze text sentiment, providing sentiment scores and confidence levels.'}\n",
      "Row 79: {'Area': 'Protocols, file formats and integration', 'Requirement': 'Google - Sentiment Analysis', 'Description': 'The product must integrate with Google Cloud Natural Language API for sentiment analysis, providing document and sentence-level sentiment scores.'}\n",
      "Row 80: {'Area': 'Protocols, file formats and integration', 'Requirement': 'Azure - Entity Extraction', 'Description': 'The product must leverage Azure Text Analytics for named entity recognition, identifying standard and custom entity types.'}\n",
      "Row 81: {'Area': 'Protocols, file formats and integration', 'Requirement': 'Google - Entity Extraction', 'Description': 'The product must use Google Cloud Natural Language API for entity extraction, supporting both standard and custom entity types.'}\n",
      "Row 82: {'Area': 'Protocols, file formats and integration', 'Requirement': 'Azure - Document OCR', 'Description': 'The product must integrate with Azure Document Intelligence (formerly Form Recognizer) for text extraction from documents, supporting various document types and layouts.'}\n",
      "Row 83: {'Area': 'Protocols, file formats and integration', 'Requirement': 'Google - Document OCR', 'Description': 'The product must utilize Google Cloud Document AI for document processing and text extraction, supporting multiple document types and languages.'}\n",
      "Row 84: {'Area': 'Protocols, file formats and integration', 'Requirement': 'Azure - Document Classification', 'Description': 'The product must use Azure Document Intelligence for document classification, supporting custom trained models and confidence scoring.'}\n",
      "Row 85: {'Area': 'Protocols, file formats and integration', 'Requirement': 'Google - Document Classification', 'Description': 'The product must integrate with Google Cloud Document AI for document classification, supporting both pre-built and custom classification models.'}\n",
      "Row 86: {'Area': 'Protocols, file formats and integration', 'Requirement': 'Azure - Vector DB - Create Index', 'Description': 'The product must create Azure AI Search indexes with vector search capabilities, configuring vector dimensions and similarity metrics.'}\n",
      "Row 87: {'Area': 'Protocols, file formats and integration', 'Requirement': 'Google - Vector DB - Create Index', 'Description': 'The product must create Vector Search indexes in Google Cloud, defining vector dimensions and search configurations.'}\n",
      "Row 88: {'Area': 'Protocols, file formats and integration', 'Requirement': 'Azure - Vector DB - Update Structure', 'Description': 'The product must modify Azure AI Search index schemas, supporting field additions and modifications without data loss.'}\n",
      "Row 89: {'Area': 'Protocols, file formats and integration', 'Requirement': 'Google - Vector DB - Update Structure', 'Description': 'The product must update Google Vector Search index structures, maintaining data integrity during schema changes.'}\n",
      "Row 90: {'Area': 'Protocols, file formats and integration', 'Requirement': 'Azure - Vector DB - Delete Index', 'Description': 'The product must delete Azure AI Search indexes and associated resources.'}\n",
      "Row 91: {'Area': 'Protocols, file formats and integration', 'Requirement': 'Google - Vector DB - Delete Index', 'Description': 'The product must remove Google Vector Search indexes and related data.'}\n",
      "Row 92: {'Area': 'Protocols, file formats and integration', 'Requirement': 'Azure - Vector DB - Add Content', 'Description': 'The product must index documents and their embeddings in Azure AI Search, supporting batch operations.'}\n",
      "Row 93: {'Area': 'Protocols, file formats and integration', 'Requirement': 'Google - Vector DB - Add Content', 'Description': 'The product must add documents and vectors to Google Vector Search indexes, with batch processing support.'}\n",
      "Row 94: {'Area': 'Protocols, file formats and integration', 'Requirement': 'Azure - Vector DB - Update Content', 'Description': 'The product must update existing documents and vectors in Azure AI Search indexes.'}\n",
      "Row 95: {'Area': 'Protocols, file formats and integration', 'Requirement': 'Google - Vector DB - Update Content', 'Description': 'The product must modify existing entries in Google Vector Search indexes.'}\n",
      "Row 96: {'Area': 'Protocols, file formats and integration', 'Requirement': 'Azure - Vector DB - Delete Content', 'Description': 'The product must remove documents and vectors from Azure AI Search indexes.'}\n",
      "Row 97: {'Area': 'Protocols, file formats and integration', 'Requirement': 'Google - Vector DB - Delete Content', 'Description': 'The product must delete entries from Google Vector Search indexes.'}\n",
      "Row 98: {'Area': 'Protocols, file formats and integration', 'Requirement': 'Azure - Vector DB - Text Search', 'Description': 'The product must perform text search in Azure AI Search using full-text and semantic capabilities.'}\n",
      "Row 99: {'Area': 'Protocols, file formats and integration', 'Requirement': 'Google - Vector DB - Text Search', 'Description': 'The product must execute text searches in Google Vector Search with keyword and semantic support.'}\n",
      "Row 100: {'Area': 'Protocols, file formats and integration', 'Requirement': 'Azure - Vector DB - Vector Search', 'Description': 'The product must perform vector similarity search in Azure AI Search using nearest neighbor algorithms.'}\n",
      "Row 101: {'Area': 'Protocols, file formats and integration', 'Requirement': 'Google - Vector DB - Vector Search', 'Description': 'The product must execute vector similarity searches in Google Vector Search.'}\n",
      "Row 102: {'Area': 'Protocols, file formats and integration', 'Requirement': 'Azure - Vector DB - Hybrid Search', 'Description': 'The product must combine text and vector search in Azure AI Search with configurable weights.'}\n",
      "Row 103: {'Area': 'Protocols, file formats and integration', 'Requirement': 'Google - Vector DB - Hybrid Search', 'Description': 'The product must perform hybrid text and vector searches in Google Vector Search with customizable relevance scoring.'}\n",
      "Row 104: {'Area': 'Protocols, file formats and integration', 'Requirement': 'Azure - Text-to-Speech Sync', 'Description': 'The product must integrate with Azure Cognitive Speech Services for synchronous text-to-speech conversion.'}\n",
      "Row 105: {'Area': 'Protocols, file formats and integration', 'Requirement': 'Azure - Text-to-Speech Stream', 'Description': 'The product must support streaming text-to-speech using Azure Cognitive Speech Services.'}\n",
      "Row 106: {'Area': 'Protocols, file formats and integration', 'Requirement': 'Azure - Text-to-Speech Real-time', 'Description': 'The product must provide real-time text-to-speech conversion through Azure Cognitive Speech Services.'}\n",
      "Row 107: {'Area': 'Protocols, file formats and integration', 'Requirement': 'Azure - Speech-to-Text Sync', 'Description': 'The product must use Azure Cognitive Speech Services for synchronous speech-to-text conversion.'}\n",
      "Row 108: {'Area': 'Protocols, file formats and integration', 'Requirement': 'Azure - Speech-to-Text Stream', 'Description': 'The product must support streaming speech-to-text through Azure Cognitive Speech Services.'}\n",
      "Row 109: {'Area': 'Protocols, file formats and integration', 'Requirement': 'Azure - Speech-to-Text Real-time', 'Description': 'The product must provide real-time speech-to-text using Azure Cognitive Speech Services.'}\n",
      "Row 110: {'Area': 'Protocols, file formats and integration', 'Requirement': 'Google - Text-to-Speech Sync', 'Description': 'The product must integrate with Google Cloud Text-to-Speech for synchronous conversion.'}\n",
      "Row 111: {'Area': 'Protocols, file formats and integration', 'Requirement': 'Google - Text-to-Speech Stream', 'Description': 'The product must support streaming text-to-speech using Google Cloud Text-to-Speech.'}\n",
      "Row 112: {'Area': 'Protocols, file formats and integration', 'Requirement': 'Google - Text-to-Speech Real-time', 'Description': 'The product must provide real-time text-to-speech through Google Cloud Text-to-Speech.'}\n",
      "Row 113: {'Area': 'Protocols, file formats and integration', 'Requirement': 'Google - Speech-to-Text Sync', 'Description': 'The product must use Google Cloud Speech-to-Text for synchronous conversion.'}\n",
      "Row 114: {'Area': 'Protocols, file formats and integration', 'Requirement': 'Google - Speech-to-Text Stream', 'Description': 'The product must support streaming speech-to-text through Google Cloud Speech-to-Text.'}\n",
      "Row 115: {'Area': 'Protocols, file formats and integration', 'Requirement': 'Google - Speech-to-Text Real-time', 'Description': 'The product must provide real-time speech-to-text using Google Cloud Speech-to-Text.'}\n",
      "Row 116: {'Area': 'Protocols, file formats and integration', 'Requirement': 'Google - Checks Guardrails API', 'Description': \"Is the product suitable to be integrated with Google Checks Guardrails API? Is it possible to customize in which part of the GenAI system the guard should be integrated? Is it possible to train the guardrail system on custom policies? Is it possible to integrate a check on generated text's accuracy and hallucinations? Is it possible to integrate functionalities to prevent prompt injection and improve model safety?\"}\n",
      "Row 117: {'Area': 'Protocols, file formats and integration', 'Requirement': 'Azure - AI Content Safety', 'Description': \"Is the product suitable to be integrated with Azure AI Content Safety? Is it possible to customize in which part of the GenAI system the guard should be integrated? Is it possible to train the guardrail system on custom policies? Is it possible to integrate a check on generated text's accuracy and hallucinations? Is it possible to integrate functionalities to prevent prompt injection and improve model safety?\"}\n",
      "Row 118: {'Area': 'Protocols, file formats and integration', 'Requirement': 'Other Guardrailing solutions', 'Description': \"Is the product suitable to be integrated with any guardrailing solution? Is it possible to customize in which part of the GenAI system the guard should be integrated? Is it possible to train the guardrail system on custom policies? Is it possible to integrate a check on generated text's accuracy and hallucinations? Is it possible to integrate functionalities to prevent prompt injection and improve model safety?\"}\n",
      "Row 119: {'Area': 'Protocols, file formats and integration', 'Requirement': 'LLM Explainability', 'Description': 'Is there the possibility of integrating an explainability solution on the output produced by the LLM model? If yes, which type of explainability?'}\n",
      "Row 120: {'Area': 'Protocols, file formats and integration', 'Requirement': 'LLM Bias Evaluation', 'Description': 'Is there the possibility of integrating a system for testing the level of bias of a generated content with respect to certain protected attributes?'}\n",
      "Row 121: {'Area': 'Protocols, file formats and integration', 'Requirement': 'LLM Performances', 'Description': 'Is there the possibility of integrating a system for testing LLM accuracy?'}\n",
      "Row 122: {'Area': 'Protocols, file formats and integration', 'Requirement': 'LLM Latency', 'Description': 'Is there the possibility of integrating a system to monitor LLM latency?'}\n",
      "Row 123: {'Area': 'Protocols, file formats and integration', 'Requirement': 'Data quality solutions', 'Description': 'Are there any modules available for performing data quality checks, such as anomaly detection, or for monitoring metrics to evaluate performance?'}\n",
      "Row 124: {'Area': 'Protocols, file formats and integration', 'Requirement': 'ESG Modules', 'Description': 'Are there any modules that measure, analyze, and report environmental impact and CO2 emissions, ensuring sustainability and compliance with global ESG standards?'}\n",
      "Row 125: {'Area': 'Protocols, file formats and integration', 'Requirement': 'Monitoring Integration - Stateless metrics', 'Description': 'Integration with monitoring tools to compute stateless metrics for GenAI (e.g. number of tokens in input, output and response time on the provider-side)'}\n",
      "Row 126: {'Area': 'Protocols, file formats and integration', 'Requirement': 'Monitoring Integration - History metrics', 'Description': 'Integration with monitoring tools to compute metrics for GenAI that require a HISTORY  (e.g. number of call for single chat session, number of active users in a time range, percentage of users that made a call at least 3 times, total number of messages per conversations and average, percentage of coversations made of 1 message only) '}\n",
      "Row 127: {'Area': 'Protocols, file formats and integration', 'Requirement': 'Monitoring Integration - Qualitative metrics', 'Description': 'Integration with monitoring tools to compute qualitative metrics for GenAI (Match GPT Similarity score, average retrieving score, match score, recall score, model uncertainity, context precision )'}\n",
      "Row 128: {'Area': 'Protocols, file formats and integration', 'Requirement': 'periodic update and integration of new services, libraries, sdk', 'Description': 'Ensure periodic updates to the releases and updates of the various CSPs'}\n",
      "Row 129: {'Area': 'Protocols, file formats and integration', 'Requirement': 'update times and support for new versions', 'Description': 'Ensure rapid adaptation to new services and libraries released in stable versions'}\n"
     ]
    }
   ],
   "source": [
    "# Open the user messages\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Read the JSON file into a DataFrame\n",
    "questions_df = pd.read_json('isp_user_messages.json')\n",
    "\n",
    "# Display the DataFrame\n",
    "# Iterate through rows and print each row\n",
    "for index, row in df.iterrows():\n",
    "    print(f\"Row {index}: {row.to_dict()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e64c4bd5-32b4-4ba2-b1f0-b6a5159ea964",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'system',\n",
       "  'content': 'As a Microsoft employee I have to formally fill a form where a Customer of ours is asking a series of questions to compare multiple cloud vendors\\' (such as Microsoft, Google, AWS and others) AI Platforms.\\nEach question consists of three points: 1) Area 2) Requirements 3) Description.\\nThe answer must include three points (A-B-C) to be filled as follows: \\nA) Supported, which can be **EXCLUSIVELY** \\n- Fully supported \\n- Partially supported\\n- Not supported (to be) \\n- Not supported (never)\\n\\nB) How integration occurs, that must be a brief explanation of max 30 words\\nC) Notes, that is a comment to A and B, mainly if A is not \"fully supported\"\\n\\nAs said, my answer must specifically cover the Microsoft offer of the Azure AI Data Platform, which today consists of AI Foundry and all the Agents / Multi-Agents offering.\\n**IMPORTANT** the answers will have to maximize Microsoft chance of winning this tender. You don\\'t have to lie, of course, but please be **VERY** optimistic.\\n\\nI will now pass you the question in json format, on at a time. Please provide the answers in json format too. Thanks for your help, I really count on you!'},\n",
       " {'role': 'assistant',\n",
       "  'content': \"I'm ready to receive your first JSON formatted question.\"},\n",
       " {'role': 'user',\n",
       "  'content': {'Area': 'Support for synchronous and asynchronous services',\n",
       "   'Requirement': 'Synchronous Service Support',\n",
       "   'Description': 'The product must support synchronous service invocation with appropriate timeout handling.'}}]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Iterate through rows and print each row\n",
    "\n",
    "max_index = 5\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    # print(f\"Row {index}: {row.to_dict()}\")\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": system_message\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"assistant\",\n",
    "            \"content\": \"I'm ready to receive your first JSON formatted question.\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": row.to_dict()\n",
    "        }\n",
    "    ]\n",
    "    if index == max_index:\n",
    "        break\n",
    "\n",
    "messages"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openai",
   "language": "python",
   "name": "openai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
