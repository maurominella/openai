{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c014eb9b",
   "metadata": {},
   "source": [
    "## [How does Python SK compare to the C# version of Semantic Kernel?](https://github.com/microsoft/semantic-kernel/blob/main/python/README.md)\n",
    "- The two SDKs are compatible and at the core they follow the same design principles.\n",
    "- Some features are still available only in the C# version, and being ported.\n",
    "- Refer to the [FEATURE MATRIX](https://learn.microsoft.com/en-us/semantic-kernel/get-started/supported-languages) doc to see where things stand in matching the features and functionality of the main SK branch.\n",
    "- Over time there will be some features available only in the Python version, and others only in the C# version, for example adapters to external services, scientific libraries, etc.\n",
    "<br/>\n",
    "- Documentation\n",
    " - [Get Started with Semantic Kernel](https://github.com/microsoft/semantic-kernel/blob/main/python/README.md)\n",
    "\n",
    "Inspired to\n",
    " - https://github.com/microsoft/semantic-kernel/blob/main/dotnet/samples/KernelSyntaxExamples/Example59_OpenAIFunctionCalling.cs\n",
    " - https://github.com/microsoft/semantic-kernel/blob/main/python/samples/kernel-syntax-examples/openai_function_calling.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c097f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the kernel\n",
    "\n",
    "import semantic_kernel as sk\n",
    "kernel = sk.Kernel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ff4600c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is my AzureChatCompletion connector:\n",
      "ai_model_id='gpt4-1106-128k' client=<openai.lib.azure.AsyncAzureOpenAI object at 0x7f3e48f1e540> ai_model_type=<OpenAIModelTypes.CHAT: 'chat'> prompt_tokens=0 completion_tokens=0 total_tokens=0\n"
     ]
    }
   ],
   "source": [
    "# create the SK \"chat completion connector\" to the Azure OpenAI service\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(\"credentials_my.env\")\n",
    "\n",
    "import semantic_kernel.connectors.ai.open_ai as sk_oai\n",
    "\n",
    "completion_connector = sk_oai.AzureChatCompletion(\n",
    "    api_key          = os.environ['AZURE_OPENAI_API_KEY'],\n",
    "    api_version      = os.environ['AZURE_OPENAI_API_VERSION'],\n",
    "    deployment_name  = os.environ['GPT4-1106-128k'], # ['GPT4-1106-128k'],\n",
    "    endpoint=os.environ['AZURE_OPENAI_ENDPOINT']\n",
    ")\n",
    "print(f\"This is my AzureChatCompletion connector:\\n{completion_connector}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b128dbb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are all chat services registered with this kernel: ['mauromi_chatgpt']\n"
     ]
    }
   ],
   "source": [
    "# add the openAI completion connector to the kernel, choosing a name to identify it within the kernel\n",
    "\n",
    "kernel.add_chat_service(\n",
    "    \"mauromi_chatgpt\", # unique name to be registered with the kernel\n",
    "    completion_connector\n",
    ")\n",
    "print(f\"Here are all chat services registered with this kernel: {kernel.all_chat_services()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a30fa449",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are my plugins imported into the kernel:\n",
      "plugins={'mauromi_calculator': KernelPlugin(name='mauromi_calculator', description=None, functions={'Add': KernelFunction(plugin_name='mauromi_calculator', description='Adds value to a value', name='Add', is_semantic=False, stream_function=<bound method MathPlugin.add of MathPlugin()>, parameters=[ParameterView(name='input', description='The value to add', default_value='', type_='string', required=False), ParameterView(name='Amount', description='Amount to add', default_value='', type_='number', required=True)], delegate_type=<DelegateTypes.InStringAndContextOutString: 12>, function=<bound method MathPlugin.add of MathPlugin()>, plugins=KernelPluginCollection(plugins={...}), ai_service=None, prompt_execution_settings=PromptExecutionSettings(service_id=None, extension_data={}), chat_prompt_template=None), 'Subtract': KernelFunction(plugin_name='mauromi_calculator', description='Subtracts value to a value', name='Subtract', is_semantic=False, stream_function=<bound method MathPlugin.subtract of MathPlugin()>, parameters=[ParameterView(name='input', description='The value to subtract', default_value='', type_='string', required=False), ParameterView(name='Amount', description='Amount to subtract', default_value='', type_='number', required=True)], delegate_type=<DelegateTypes.InStringAndContextOutString: 12>, function=<bound method MathPlugin.subtract of MathPlugin()>, plugins=KernelPluginCollection(plugins={...}), ai_service=None, prompt_execution_settings=PromptExecutionSettings(service_id=None, extension_data={}), chat_prompt_template=None)})}\n"
     ]
    }
   ],
   "source": [
    "# Import a built-in plugin\n",
    "\n",
    "from semantic_kernel.core_plugins import MathPlugin\n",
    "kernel.import_plugin(MathPlugin(), plugin_name=\"mauromi_calculator\")\n",
    "\n",
    "print(f\"Here are my plugins imported into the kernel:\\n{kernel.plugins}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0368d143",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import custom semantic plugin\n",
    "# the joke plugin in the FunPlugins is a semantic plugin and has the function calling disabled.\n",
    "\n",
    "import os\n",
    "plugins_directory = os.path.join(os.getcwd(), \"./Plugins\")\n",
    "kernel.import_semantic_plugin_from_directory(plugins_directory, \"FunPlugin\")\n",
    "\n",
    "print(f\"Here are my plugins imported into the kernel:\\n{kernel.plugins}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf76590b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom function that can be used with Function Calling\n",
    "tools = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"search_hotels\",\n",
    "            \"description\": \"Retrieves hotels from the search index based on the parameters provided\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"location\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"The location of the hotel (i.e. Seattle, WA)\",\n",
    "                    },\n",
    "                    \"max_price\": {\n",
    "                        \"type\": \"number\",\n",
    "                        \"description\": \"The maximum price for the hotel\",\n",
    "                    },\n",
    "                    \"features\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"A comma separated list of features (i.e. beachfront, free wifi, etc.)\",\n",
    "                    },\n",
    "                },\n",
    "                \"required\": [\"location\"],\n",
    "            },\n",
    "        },\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "399807b5",
   "metadata": {},
   "source": [
    "Enabling or disabling function calling is done by setting the `function_call` parameter for the completion.<br/>\n",
    "When the function_call parameter is set to \"auto\" the model will decide which function to use, if any.<br/>\n",
    "If you only want to use a specific function, set the name of that function in this parameter, the format for that is 'PluginName-FunctionName', (i.e. 'math-Add').<br/>\n",
    "If the model or api version do not support this you will get an error.<br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66202de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt template config that contains the definition and description of each function\n",
    "\n",
    "prompt_config = sk.PromptTemplateConfig.from_execution_settings(\n",
    "    max_tokens=2000,\n",
    "    temperature=0.7,\n",
    "    top_p=0.8,\n",
    "    tool_choice=\"auto\",\n",
    "    tools=tools,\n",
    ")\n",
    "prompt_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1faf851d",
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel.get_text_completion_service_service_id()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42fe4890",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we bind the \n",
    "\n",
    "prompt_template = sk.ChatPromptTemplate[sk_oai.models.chat.open_ai_chat_message.OpenAIChatMessage](\n",
    "    \"{{$user_input}}\", kernel.prompt_template_engine, prompt_config\n",
    ")\n",
    "prompt_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c78b8666",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = \"\"\"\n",
    "You are a chat bot. Your name is Mosscap and\n",
    "you have one goal: figure out what people need.\n",
    "Your full name, should you need to know it, is\n",
    "Splendid Speckled Mosscap. You communicate\n",
    "effectively, but you tend to answer with long\n",
    "flowery prose. You are also a math wizard, \n",
    "especially for adding and subtracting.\n",
    "You also excel at joke telling, where your tone is often sarcastic.\n",
    "Once you have the answer I am looking for, \n",
    "you will return a full answer to me as soon as possible.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3069deaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template.add_system_message(system_message)\n",
    "prompt_template.add_user_message(\"Hi there, who are you?\")\n",
    "prompt_template.add_assistant_message(\"I am Mosscap, a chat bot. I'm trying to figure out what people need.\")\n",
    "prompt_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94814d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template.messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9c3d7a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "function_config = sk.SemanticFunctionConfig(prompt_template=prompt_template, prompt_template_config=prompt_config)\n",
    "function_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22ebe053",
   "metadata": {},
   "outputs": [],
   "source": [
    "function_config.prompt_template_config.execution_settings.extension_data[\"tools\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed5eb2ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_function = kernel.register_semantic_function (\n",
    "    plugin_name=\"ChatBot\", \n",
    "    function_name=\"Chat\", \n",
    "    function_config= function_config)\n",
    "\n",
    "chat_function.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d30efc53",
   "metadata": {},
   "outputs": [],
   "source": [
    "context = kernel.create_new_context()\n",
    "context.variables[\"user_input\"] = \"I want to find a hotel in Seattle with free wifi and a pool.\"\n",
    "response = chat_function.invoke(context=context)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48c570d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for message in response:\n",
    "    print(f\"message: {message}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a4d10d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = []\n",
    "tool_call = None\n",
    "\n",
    "for message in response:\n",
    "    print(f\"message: {message}\")\n",
    "    current = message[0]\n",
    "    messages.append(current)\n",
    "    if current.tool_calls:\n",
    "        if tool_call is None:\n",
    "            tool_call = current.tool_calls[0]\n",
    "        else:\n",
    "            tool_call += current.tool_calls[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec860e36",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "semantic_kernel",
   "language": "python",
   "name": "semantic_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
